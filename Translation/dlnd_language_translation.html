<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, youre going to take a peek into the realm of neural network machine translation.  Youll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les tats-unis est gnralement froid en juillet , et il gle habituellement en novembre .
california est gnralement calme en mars , et il est gnralement chaud en juin .
les tats-unis est parfois lgre en juin , et il fait froid en septembre .
votre moins aim fruit est le raisin , mais mon moins aim est la pomme .
son fruit prfr est l&#39;orange , mais mon prfr est le raisin .
paris est relaxant en dcembre , mais il est gnralement froid en juillet .
new jersey est occup au printemps , et il est jamais chaude en mars .
notre fruit est moins aim le citron , mais mon moins aim est le raisin .
les tats-unis est parfois occup en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">lookup</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">):</span>
            <span class="n">converted</span> <span class="o">=</span> <span class="p">[</span><span class="n">lookup</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
            <span class="k">if</span> <span class="n">marker</span><span class="p">:</span>
                <span class="n">converted</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">marker</span><span class="p">)</span>
            <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">converted</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="n">marker</span> <span class="o">=</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">parse</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">),</span> <span class="n">parse</span><span class="p">(</span><span class="n">target_text</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.3.0
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/bmoscon/envs/tf/lib/python3.6/site-packages/ipykernel/__main__.py:15: UserWarning: No GPU found. Please use a GPU to train your neural network.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;targets&#39;</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
    <span class="n">target_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;target_sequence_length&#39;</span><span class="p">)</span>
    <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_seq_len</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;max_target_len&#39;</span><span class="p">)</span>
    <span class="n">source_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;source_sequence_length&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inpt</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_seq_len</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">source_seq_len</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]),</span> <span class="n">x</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span>
                                             <span class="n">vocab_size</span><span class="o">=</span><span class="n">source_vocab_size</span><span class="p">,</span>
                                             <span class="n">embed_dim</span><span class="o">=</span><span class="n">encoding_embedding_size</span><span class="p">)</span>
    <span class="n">cells</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">),</span> <span class="n">keep_prob</span><span class="p">)</span> 
             <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>
    <span class="n">stacked</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">cells</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">stacked</span><span class="p">,</span>
                             <span class="n">embed</span><span class="p">,</span>
                             <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                             <span class="n">sequence_length</span><span class="o">=</span><span class="n">source_sequence_length</span><span class="p">)</span>
    
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">training_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">dec_embed_input</span><span class="p">,</span>
                                                        <span class="n">sequence_length</span><span class="o">=</span><span class="n">target_sequence_length</span><span class="p">)</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">cell</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">),</span>
                                                    <span class="n">helper</span><span class="o">=</span><span class="n">training_helper</span><span class="p">,</span>
                                                    <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span>
                                                    <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">decoder</span><span class="o">=</span><span class="n">basic_decoder</span><span class="p">,</span>
                                             <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;tokens&#39;</span><span class="p">)</span>
    <span class="n">helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">embedding</span><span class="o">=</span><span class="n">dec_embeddings</span><span class="p">,</span> 
                                                      <span class="n">start_tokens</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> 
                                                      <span class="n">end_token</span><span class="o">=</span><span class="n">end_of_sequence_id</span><span class="p">)</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">cell</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">),</span> 
                                              <span class="n">helper</span><span class="o">=</span><span class="n">helper</span><span class="p">,</span> 
                                              <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span> 
                                              <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> 
                                             <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                             <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Embed target sequences</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>

    <span class="c1"># Construct decoder LSTM</span>
    <span class="n">cells</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                           <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)),</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
             <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>

    <span class="n">decoder_cells</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">cells</span><span class="p">)</span>
     
    <span class="c1"># Create output layer</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span>
                         <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    
    <span class="n">train</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">infer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decoder_cells&quot;</span><span class="p">):</span>
        <span class="n">train</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span>
                                     <span class="n">decoder_cells</span><span class="p">,</span>
                                     <span class="n">embed_input</span><span class="p">,</span>
                                     <span class="n">target_sequence_length</span><span class="p">,</span>
                                     <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                     <span class="n">output_layer</span><span class="p">,</span>
                                     <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;decoder_cells&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">infer</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span>
                                     <span class="n">decoder_cells</span><span class="p">,</span>
                                     <span class="n">embed</span><span class="p">,</span>
                                     <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span>
                                     <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span>
                                     <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                     <span class="n">target_vocab_size</span><span class="p">,</span>
                                     <span class="n">output_layer</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="p">,</span>
                                     <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train</span><span class="p">,</span> <span class="n">infer</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">encoded</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> 
                                <span class="n">rnn_size</span><span class="p">,</span> 
                                <span class="n">num_layers</span><span class="p">,</span> 
                                <span class="n">keep_prob</span><span class="p">,</span> 
                                <span class="n">source_sequence_length</span><span class="p">,</span> 
                                <span class="n">source_vocab_size</span><span class="p">,</span> 
                                <span class="n">enc_embedding_size</span><span class="p">)</span>
    
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> 
                                    <span class="n">target_vocab_to_int</span><span class="p">,</span> 
                                    <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">decoded</span><span class="p">,</span> 
                          <span class="n">encoded</span><span class="p">,</span> 
                          <span class="n">target_sequence_length</span><span class="p">,</span> 
                          <span class="n">max_target_sentence_length</span><span class="p">,</span> 
                          <span class="n">rnn_size</span><span class="p">,</span> 
                          <span class="n">num_layers</span><span class="p">,</span> 
                          <span class="n">target_vocab_to_int</span><span class="p">,</span> 
                          <span class="n">target_vocab_size</span><span class="p">,</span> 
                          <span class="n">batch_size</span><span class="p">,</span> 
                          <span class="n">keep_prob</span><span class="p">,</span> 
                          <span class="n">dec_embedding_size</span><span class="p">)</span>
    


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    1/1077 - Train Accuracy: 0.2215, Validation Accuracy: 0.3050, Loss: 5.1517
Epoch   0 Batch    2/1077 - Train Accuracy: 0.2463, Validation Accuracy: 0.3366, Loss: 4.5796
Epoch   0 Batch    3/1077 - Train Accuracy: 0.2707, Validation Accuracy: 0.3356, Loss: 4.0546
Epoch   0 Batch    4/1077 - Train Accuracy: 0.2586, Validation Accuracy: 0.3349, Loss: 3.7987
Epoch   0 Batch    5/1077 - Train Accuracy: 0.2961, Validation Accuracy: 0.3366, Loss: 3.6428
Epoch   0 Batch    6/1077 - Train Accuracy: 0.2793, Validation Accuracy: 0.3366, Loss: 3.6298
Epoch   0 Batch    7/1077 - Train Accuracy: 0.2801, Validation Accuracy: 0.3551, Loss: 3.5535
Epoch   0 Batch    8/1077 - Train Accuracy: 0.3125, Validation Accuracy: 0.3718, Loss: 3.6596
Epoch   0 Batch    9/1077 - Train Accuracy: 0.3180, Validation Accuracy: 0.3704, Loss: 3.4006
Epoch   0 Batch   10/1077 - Train Accuracy: 0.2866, Validation Accuracy: 0.3743, Loss: 3.5005
Epoch   0 Batch   11/1077 - Train Accuracy: 0.3326, Validation Accuracy: 0.3672, Loss: 3.2211
Epoch   0 Batch   12/1077 - Train Accuracy: 0.2898, Validation Accuracy: 0.3537, Loss: 3.2275
Epoch   0 Batch   13/1077 - Train Accuracy: 0.3519, Validation Accuracy: 0.3675, Loss: 3.0765
Epoch   0 Batch   14/1077 - Train Accuracy: 0.3304, Validation Accuracy: 0.3697, Loss: 3.0868
Epoch   0 Batch   15/1077 - Train Accuracy: 0.3469, Validation Accuracy: 0.3999, Loss: 3.0878
Epoch   0 Batch   16/1077 - Train Accuracy: 0.3391, Validation Accuracy: 0.3782, Loss: 3.0293
Epoch   0 Batch   17/1077 - Train Accuracy: 0.3477, Validation Accuracy: 0.3903, Loss: 3.0435
Epoch   0 Batch   18/1077 - Train Accuracy: 0.3438, Validation Accuracy: 0.4023, Loss: 3.0225
Epoch   0 Batch   19/1077 - Train Accuracy: 0.3672, Validation Accuracy: 0.4109, Loss: 2.9227
Epoch   0 Batch   20/1077 - Train Accuracy: 0.3398, Validation Accuracy: 0.3995, Loss: 2.8770
Epoch   0 Batch   21/1077 - Train Accuracy: 0.3273, Validation Accuracy: 0.4119, Loss: 2.9613
Epoch   0 Batch   22/1077 - Train Accuracy: 0.3531, Validation Accuracy: 0.4219, Loss: 2.8811
Epoch   0 Batch   23/1077 - Train Accuracy: 0.3598, Validation Accuracy: 0.4180, Loss: 2.8771
Epoch   0 Batch   24/1077 - Train Accuracy: 0.3637, Validation Accuracy: 0.4226, Loss: 2.7633
Epoch   0 Batch   25/1077 - Train Accuracy: 0.3797, Validation Accuracy: 0.4219, Loss: 2.8699
Epoch   0 Batch   26/1077 - Train Accuracy: 0.3566, Validation Accuracy: 0.4208, Loss: 2.8101
Epoch   0 Batch   27/1077 - Train Accuracy: 0.4204, Validation Accuracy: 0.4361, Loss: 2.5242
Epoch   0 Batch   28/1077 - Train Accuracy: 0.4000, Validation Accuracy: 0.4375, Loss: 2.6649
Epoch   0 Batch   29/1077 - Train Accuracy: 0.3816, Validation Accuracy: 0.4347, Loss: 2.6224
Epoch   0 Batch   30/1077 - Train Accuracy: 0.3637, Validation Accuracy: 0.4318, Loss: 2.6191
Epoch   0 Batch   31/1077 - Train Accuracy: 0.3961, Validation Accuracy: 0.4588, Loss: 2.6394
Epoch   0 Batch   32/1077 - Train Accuracy: 0.4282, Validation Accuracy: 0.4435, Loss: 2.3906
Epoch   0 Batch   33/1077 - Train Accuracy: 0.4204, Validation Accuracy: 0.4602, Loss: 2.4540
Epoch   0 Batch   34/1077 - Train Accuracy: 0.4176, Validation Accuracy: 0.4641, Loss: 2.5071
Epoch   0 Batch   35/1077 - Train Accuracy: 0.4105, Validation Accuracy: 0.4595, Loss: 2.5194
Epoch   0 Batch   36/1077 - Train Accuracy: 0.4223, Validation Accuracy: 0.4616, Loss: 2.4467
Epoch   0 Batch   37/1077 - Train Accuracy: 0.3809, Validation Accuracy: 0.4386, Loss: 2.4803
Epoch   0 Batch   38/1077 - Train Accuracy: 0.3795, Validation Accuracy: 0.4680, Loss: 2.6373
Epoch   0 Batch   39/1077 - Train Accuracy: 0.4102, Validation Accuracy: 0.4698, Loss: 2.4811
Epoch   0 Batch   40/1077 - Train Accuracy: 0.3918, Validation Accuracy: 0.4446, Loss: 2.4194
Epoch   0 Batch   41/1077 - Train Accuracy: 0.4405, Validation Accuracy: 0.4648, Loss: 2.3583
Epoch   0 Batch   42/1077 - Train Accuracy: 0.4180, Validation Accuracy: 0.4716, Loss: 2.3426
Epoch   0 Batch   43/1077 - Train Accuracy: 0.4034, Validation Accuracy: 0.4673, Loss: 2.3828
Epoch   0 Batch   44/1077 - Train Accuracy: 0.3487, Validation Accuracy: 0.4350, Loss: 2.4935
Epoch   0 Batch   45/1077 - Train Accuracy: 0.3977, Validation Accuracy: 0.4581, Loss: 2.3546
Epoch   0 Batch   46/1077 - Train Accuracy: 0.3993, Validation Accuracy: 0.4570, Loss: 2.3778
Epoch   0 Batch   47/1077 - Train Accuracy: 0.4297, Validation Accuracy: 0.4592, Loss: 2.2742
Epoch   0 Batch   48/1077 - Train Accuracy: 0.3875, Validation Accuracy: 0.4308, Loss: 2.2895
Epoch   0 Batch   49/1077 - Train Accuracy: 0.4055, Validation Accuracy: 0.4542, Loss: 2.2517
Epoch   0 Batch   50/1077 - Train Accuracy: 0.4305, Validation Accuracy: 0.4954, Loss: 2.3109
Epoch   0 Batch   51/1077 - Train Accuracy: 0.4813, Validation Accuracy: 0.4989, Loss: 2.1748
Epoch   0 Batch   52/1077 - Train Accuracy: 0.4043, Validation Accuracy: 0.4613, Loss: 2.2299
Epoch   0 Batch   53/1077 - Train Accuracy: 0.4465, Validation Accuracy: 0.4915, Loss: 2.2224
Epoch   0 Batch   54/1077 - Train Accuracy: 0.4195, Validation Accuracy: 0.4950, Loss: 2.3445
Epoch   0 Batch   55/1077 - Train Accuracy: 0.4223, Validation Accuracy: 0.4567, Loss: 2.0818
Epoch   0 Batch   56/1077 - Train Accuracy: 0.4305, Validation Accuracy: 0.4762, Loss: 2.1375
Epoch   0 Batch   57/1077 - Train Accuracy: 0.5156, Validation Accuracy: 0.5075, Loss: 1.8788
Epoch   0 Batch   58/1077 - Train Accuracy: 0.4594, Validation Accuracy: 0.5089, Loss: 2.1014
Epoch   0 Batch   59/1077 - Train Accuracy: 0.4268, Validation Accuracy: 0.5142, Loss: 2.1924
Epoch   0 Batch   60/1077 - Train Accuracy: 0.4725, Validation Accuracy: 0.5146, Loss: 2.0115
Epoch   0 Batch   61/1077 - Train Accuracy: 0.4633, Validation Accuracy: 0.5192, Loss: 1.9898
Epoch   0 Batch   62/1077 - Train Accuracy: 0.4433, Validation Accuracy: 0.4968, Loss: 2.1012
Epoch   0 Batch   63/1077 - Train Accuracy: 0.4870, Validation Accuracy: 0.5075, Loss: 1.8767
Epoch   0 Batch   64/1077 - Train Accuracy: 0.4508, Validation Accuracy: 0.5210, Loss: 1.9392
Epoch   0 Batch   65/1077 - Train Accuracy: 0.4256, Validation Accuracy: 0.5107, Loss: 2.0623
Epoch   0 Batch   66/1077 - Train Accuracy: 0.4524, Validation Accuracy: 0.5071, Loss: 1.8746
Epoch   0 Batch   67/1077 - Train Accuracy: 0.4978, Validation Accuracy: 0.5195, Loss: 1.8169
Epoch   0 Batch   68/1077 - Train Accuracy: 0.4406, Validation Accuracy: 0.5046, Loss: 1.8501
Epoch   0 Batch   69/1077 - Train Accuracy: 0.4813, Validation Accuracy: 0.5007, Loss: 1.8198
Epoch   0 Batch   70/1077 - Train Accuracy: 0.4141, Validation Accuracy: 0.5011, Loss: 1.8570
Epoch   0 Batch   71/1077 - Train Accuracy: 0.4566, Validation Accuracy: 0.5075, Loss: 1.7257
Epoch   0 Batch   72/1077 - Train Accuracy: 0.4660, Validation Accuracy: 0.4968, Loss: 1.7263
Epoch   0 Batch   73/1077 - Train Accuracy: 0.4613, Validation Accuracy: 0.4833, Loss: 1.7000
Epoch   0 Batch   74/1077 - Train Accuracy: 0.4691, Validation Accuracy: 0.4862, Loss: 1.5934
Epoch   0 Batch   75/1077 - Train Accuracy: 0.4938, Validation Accuracy: 0.4982, Loss: 1.5868
Epoch   0 Batch   76/1077 - Train Accuracy: 0.4660, Validation Accuracy: 0.4886, Loss: 1.5901
Epoch   0 Batch   77/1077 - Train Accuracy: 0.4582, Validation Accuracy: 0.5185, Loss: 1.6123
Epoch   0 Batch   78/1077 - Train Accuracy: 0.4412, Validation Accuracy: 0.5110, Loss: 1.6402
Epoch   0 Batch   79/1077 - Train Accuracy: 0.4453, Validation Accuracy: 0.4993, Loss: 1.5781
Epoch   0 Batch   80/1077 - Train Accuracy: 0.4340, Validation Accuracy: 0.4680, Loss: 1.4873
Epoch   0 Batch   81/1077 - Train Accuracy: 0.4441, Validation Accuracy: 0.4730, Loss: 1.4973
Epoch   0 Batch   82/1077 - Train Accuracy: 0.4798, Validation Accuracy: 0.4751, Loss: 1.3313
Epoch   0 Batch   83/1077 - Train Accuracy: 0.4190, Validation Accuracy: 0.4613, Loss: 1.5236
Epoch   0 Batch   84/1077 - Train Accuracy: 0.3664, Validation Accuracy: 0.4190, Loss: 1.4275
Epoch   0 Batch   85/1077 - Train Accuracy: 0.3809, Validation Accuracy: 0.4176, Loss: 1.3297
Epoch   0 Batch   86/1077 - Train Accuracy: 0.3812, Validation Accuracy: 0.4134, Loss: 1.4282
Epoch   0 Batch   87/1077 - Train Accuracy: 0.3777, Validation Accuracy: 0.4137, Loss: 1.4317
Epoch   0 Batch   88/1077 - Train Accuracy: 0.3465, Validation Accuracy: 0.4031, Loss: 1.3896
Epoch   0 Batch   89/1077 - Train Accuracy: 0.3402, Validation Accuracy: 0.4283, Loss: 1.3526
Epoch   0 Batch   90/1077 - Train Accuracy: 0.3582, Validation Accuracy: 0.4247, Loss: 1.3930
Epoch   0 Batch   91/1077 - Train Accuracy: 0.4185, Validation Accuracy: 0.4190, Loss: 1.1933
Epoch   0 Batch   92/1077 - Train Accuracy: 0.4036, Validation Accuracy: 0.4197, Loss: 1.2927
Epoch   0 Batch   93/1077 - Train Accuracy: 0.3758, Validation Accuracy: 0.4233, Loss: 1.3112
Epoch   0 Batch   94/1077 - Train Accuracy: 0.3742, Validation Accuracy: 0.4244, Loss: 1.2353
Epoch   0 Batch   95/1077 - Train Accuracy: 0.3984, Validation Accuracy: 0.4240, Loss: 1.2667
Epoch   0 Batch   96/1077 - Train Accuracy: 0.4195, Validation Accuracy: 0.4357, Loss: 1.2257
Epoch   0 Batch   97/1077 - Train Accuracy: 0.3930, Validation Accuracy: 0.4201, Loss: 1.2308
Epoch   0 Batch   98/1077 - Train Accuracy: 0.4423, Validation Accuracy: 0.4432, Loss: 1.1745
Epoch   0 Batch   99/1077 - Train Accuracy: 0.3469, Validation Accuracy: 0.4354, Loss: 1.2579
Epoch   0 Batch  100/1077 - Train Accuracy: 0.3684, Validation Accuracy: 0.4357, Loss: 1.1935
Epoch   0 Batch  101/1077 - Train Accuracy: 0.3715, Validation Accuracy: 0.4407, Loss: 1.1509
Epoch   0 Batch  102/1077 - Train Accuracy: 0.4121, Validation Accuracy: 0.4339, Loss: 1.1597
Epoch   0 Batch  103/1077 - Train Accuracy: 0.3606, Validation Accuracy: 0.4329, Loss: 1.2360
Epoch   0 Batch  104/1077 - Train Accuracy: 0.3873, Validation Accuracy: 0.4336, Loss: 1.2031
Epoch   0 Batch  105/1077 - Train Accuracy: 0.4086, Validation Accuracy: 0.4393, Loss: 1.1304
Epoch   0 Batch  106/1077 - Train Accuracy: 0.3869, Validation Accuracy: 0.4421, Loss: 1.2589
Epoch   0 Batch  107/1077 - Train Accuracy: 0.4252, Validation Accuracy: 0.4336, Loss: 1.0852
Epoch   0 Batch  108/1077 - Train Accuracy: 0.4645, Validation Accuracy: 0.4421, Loss: 1.0089
Epoch   0 Batch  109/1077 - Train Accuracy: 0.4223, Validation Accuracy: 0.4439, Loss: 1.1153
Epoch   0 Batch  110/1077 - Train Accuracy: 0.4172, Validation Accuracy: 0.4521, Loss: 1.0424
Epoch   0 Batch  111/1077 - Train Accuracy: 0.3840, Validation Accuracy: 0.4478, Loss: 1.1102
Epoch   0 Batch  112/1077 - Train Accuracy: 0.4031, Validation Accuracy: 0.4357, Loss: 1.0960
Epoch   0 Batch  113/1077 - Train Accuracy: 0.4301, Validation Accuracy: 0.5231, Loss: 1.0852
Epoch   0 Batch  114/1077 - Train Accuracy: 0.4929, Validation Accuracy: 0.5178, Loss: 1.0383
Epoch   0 Batch  115/1077 - Train Accuracy: 0.4539, Validation Accuracy: 0.5064, Loss: 1.1097
Epoch   0 Batch  116/1077 - Train Accuracy: 0.3871, Validation Accuracy: 0.4467, Loss: 1.0835
Epoch   0 Batch  117/1077 - Train Accuracy: 0.3785, Validation Accuracy: 0.4343, Loss: 1.0917
Epoch   0 Batch  118/1077 - Train Accuracy: 0.3746, Validation Accuracy: 0.4403, Loss: 1.0895
Epoch   0 Batch  119/1077 - Train Accuracy: 0.3984, Validation Accuracy: 0.4524, Loss: 1.0077
Epoch   0 Batch  120/1077 - Train Accuracy: 0.4668, Validation Accuracy: 0.5291, Loss: 1.0417
Epoch   0 Batch  121/1077 - Train Accuracy: 0.5055, Validation Accuracy: 0.5320, Loss: 1.0075
Epoch   0 Batch  122/1077 - Train Accuracy: 0.4969, Validation Accuracy: 0.5270, Loss: 0.9885
Epoch   0 Batch  123/1077 - Train Accuracy: 0.4941, Validation Accuracy: 0.5266, Loss: 0.9761
Epoch   0 Batch  124/1077 - Train Accuracy: 0.4793, Validation Accuracy: 0.5266, Loss: 0.9913
Epoch   0 Batch  125/1077 - Train Accuracy: 0.5104, Validation Accuracy: 0.5241, Loss: 0.9737
Epoch   0 Batch  126/1077 - Train Accuracy: 0.5190, Validation Accuracy: 0.5419, Loss: 0.9177
Epoch   0 Batch  127/1077 - Train Accuracy: 0.5078, Validation Accuracy: 0.5401, Loss: 0.9696
Epoch   0 Batch  128/1077 - Train Accuracy: 0.5402, Validation Accuracy: 0.5394, Loss: 0.9376
Epoch   0 Batch  129/1077 - Train Accuracy: 0.5359, Validation Accuracy: 0.5511, Loss: 0.9959
Epoch   0 Batch  130/1077 - Train Accuracy: 0.5205, Validation Accuracy: 0.5298, Loss: 0.8917
Epoch   0 Batch  131/1077 - Train Accuracy: 0.4965, Validation Accuracy: 0.5394, Loss: 0.9721
Epoch   0 Batch  132/1077 - Train Accuracy: 0.4656, Validation Accuracy: 0.5423, Loss: 1.0107
Epoch   0 Batch  133/1077 - Train Accuracy: 0.4741, Validation Accuracy: 0.5469, Loss: 0.9735
Epoch   0 Batch  134/1077 - Train Accuracy: 0.5305, Validation Accuracy: 0.5469, Loss: 0.9195
Epoch   0 Batch  135/1077 - Train Accuracy: 0.5012, Validation Accuracy: 0.5465, Loss: 0.9890
Epoch   0 Batch  136/1077 - Train Accuracy: 0.4938, Validation Accuracy: 0.5426, Loss: 0.9368
Epoch   0 Batch  137/1077 - Train Accuracy: 0.5580, Validation Accuracy: 0.5433, Loss: 0.8404
Epoch   0 Batch  138/1077 - Train Accuracy: 0.5078, Validation Accuracy: 0.5376, Loss: 0.9160
Epoch   0 Batch  139/1077 - Train Accuracy: 0.5281, Validation Accuracy: 0.5483, Loss: 0.9430
Epoch   0 Batch  140/1077 - Train Accuracy: 0.4692, Validation Accuracy: 0.5479, Loss: 0.9767
Epoch   0 Batch  141/1077 - Train Accuracy: 0.4684, Validation Accuracy: 0.5391, Loss: 0.9792
Epoch   0 Batch  142/1077 - Train Accuracy: 0.5130, Validation Accuracy: 0.5323, Loss: 0.8600
Epoch   0 Batch  143/1077 - Train Accuracy: 0.5129, Validation Accuracy: 0.5398, Loss: 0.9335
Epoch   0 Batch  144/1077 - Train Accuracy: 0.4441, Validation Accuracy: 0.5387, Loss: 0.9772
Epoch   0 Batch  145/1077 - Train Accuracy: 0.5719, Validation Accuracy: 0.5415, Loss: 0.9298
Epoch   0 Batch  146/1077 - Train Accuracy: 0.5443, Validation Accuracy: 0.5458, Loss: 0.9176
Epoch   0 Batch  147/1077 - Train Accuracy: 0.4859, Validation Accuracy: 0.5415, Loss: 0.9482
Epoch   0 Batch  148/1077 - Train Accuracy: 0.5254, Validation Accuracy: 0.5437, Loss: 0.8936
Epoch   0 Batch  149/1077 - Train Accuracy: 0.5043, Validation Accuracy: 0.5419, Loss: 0.9267
Epoch   0 Batch  150/1077 - Train Accuracy: 0.5536, Validation Accuracy: 0.5572, Loss: 0.8601
Epoch   0 Batch  151/1077 - Train Accuracy: 0.5279, Validation Accuracy: 0.5579, Loss: 0.8402
Epoch   0 Batch  152/1077 - Train Accuracy: 0.5391, Validation Accuracy: 0.5394, Loss: 0.9139
Epoch   0 Batch  153/1077 - Train Accuracy: 0.4848, Validation Accuracy: 0.5391, Loss: 0.9185
Epoch   0 Batch  154/1077 - Train Accuracy: 0.4971, Validation Accuracy: 0.5490, Loss: 0.9337
Epoch   0 Batch  155/1077 - Train Accuracy: 0.4953, Validation Accuracy: 0.5366, Loss: 0.8882
Epoch   0 Batch  156/1077 - Train Accuracy: 0.4805, Validation Accuracy: 0.5391, Loss: 0.8583
Epoch   0 Batch  157/1077 - Train Accuracy: 0.5145, Validation Accuracy: 0.5415, Loss: 0.8768
Epoch   0 Batch  158/1077 - Train Accuracy: 0.5126, Validation Accuracy: 0.5458, Loss: 0.8935
Epoch   0 Batch  159/1077 - Train Accuracy: 0.5234, Validation Accuracy: 0.5561, Loss: 0.7891
Epoch   0 Batch  160/1077 - Train Accuracy: 0.5012, Validation Accuracy: 0.5575, Loss: 0.8483
Epoch   0 Batch  161/1077 - Train Accuracy: 0.5148, Validation Accuracy: 0.5558, Loss: 0.8693
Epoch   0 Batch  162/1077 - Train Accuracy: 0.4961, Validation Accuracy: 0.5597, Loss: 0.9085
Epoch   0 Batch  163/1077 - Train Accuracy: 0.4910, Validation Accuracy: 0.5408, Loss: 0.9077
Epoch   0 Batch  164/1077 - Train Accuracy: 0.5039, Validation Accuracy: 0.5479, Loss: 0.8612
Epoch   0 Batch  165/1077 - Train Accuracy: 0.4641, Validation Accuracy: 0.5497, Loss: 0.8473
Epoch   0 Batch  166/1077 - Train Accuracy: 0.5410, Validation Accuracy: 0.5572, Loss: 0.8531
Epoch   0 Batch  167/1077 - Train Accuracy: 0.5281, Validation Accuracy: 0.5629, Loss: 0.8806
Epoch   0 Batch  168/1077 - Train Accuracy: 0.5185, Validation Accuracy: 0.5700, Loss: 0.8806
Epoch   0 Batch  169/1077 - Train Accuracy: 0.5614, Validation Accuracy: 0.5778, Loss: 0.8153
Epoch   0 Batch  170/1077 - Train Accuracy: 0.5055, Validation Accuracy: 0.5781, Loss: 0.8619
Epoch   0 Batch  171/1077 - Train Accuracy: 0.5668, Validation Accuracy: 0.5760, Loss: 0.7839
Epoch   0 Batch  172/1077 - Train Accuracy: 0.5606, Validation Accuracy: 0.5678, Loss: 0.7697
Epoch   0 Batch  173/1077 - Train Accuracy: 0.5062, Validation Accuracy: 0.5742, Loss: 0.8916
Epoch   0 Batch  174/1077 - Train Accuracy: 0.5781, Validation Accuracy: 0.5753, Loss: 0.8112
Epoch   0 Batch  175/1077 - Train Accuracy: 0.5687, Validation Accuracy: 0.5749, Loss: 0.8072
Epoch   0 Batch  176/1077 - Train Accuracy: 0.5355, Validation Accuracy: 0.5643, Loss: 0.8186
Epoch   0 Batch  177/1077 - Train Accuracy: 0.5070, Validation Accuracy: 0.5611, Loss: 0.8873
Epoch   0 Batch  178/1077 - Train Accuracy: 0.5168, Validation Accuracy: 0.5579, Loss: 0.8138
Epoch   0 Batch  179/1077 - Train Accuracy: 0.5744, Validation Accuracy: 0.5646, Loss: 0.8499
Epoch   0 Batch  180/1077 - Train Accuracy: 0.5297, Validation Accuracy: 0.5639, Loss: 0.8179
Epoch   0 Batch  181/1077 - Train Accuracy: 0.5238, Validation Accuracy: 0.5597, Loss: 0.8452
Epoch   0 Batch  182/1077 - Train Accuracy: 0.5610, Validation Accuracy: 0.5543, Loss: 0.7755
Epoch   0 Batch  183/1077 - Train Accuracy: 0.5191, Validation Accuracy: 0.5565, Loss: 0.8154
Epoch   0 Batch  184/1077 - Train Accuracy: 0.5406, Validation Accuracy: 0.5536, Loss: 0.7772
Epoch   0 Batch  185/1077 - Train Accuracy: 0.5145, Validation Accuracy: 0.5540, Loss: 0.8033
Epoch   0 Batch  186/1077 - Train Accuracy: 0.5333, Validation Accuracy: 0.5692, Loss: 0.8329
Epoch   0 Batch  187/1077 - Train Accuracy: 0.5422, Validation Accuracy: 0.5643, Loss: 0.7974
Epoch   0 Batch  188/1077 - Train Accuracy: 0.5445, Validation Accuracy: 0.5639, Loss: 0.8081
Epoch   0 Batch  189/1077 - Train Accuracy: 0.5469, Validation Accuracy: 0.5685, Loss: 0.7978
Epoch   0 Batch  190/1077 - Train Accuracy: 0.5836, Validation Accuracy: 0.5643, Loss: 0.7737
Epoch   0 Batch  191/1077 - Train Accuracy: 0.6090, Validation Accuracy: 0.5582, Loss: 0.7083
Epoch   0 Batch  192/1077 - Train Accuracy: 0.5707, Validation Accuracy: 0.5568, Loss: 0.8035
Epoch   0 Batch  193/1077 - Train Accuracy: 0.5602, Validation Accuracy: 0.5618, Loss: 0.7668
Epoch   0 Batch  194/1077 - Train Accuracy: 0.5818, Validation Accuracy: 0.5639, Loss: 0.7312
Epoch   0 Batch  195/1077 - Train Accuracy: 0.5484, Validation Accuracy: 0.5753, Loss: 0.7730
Epoch   0 Batch  196/1077 - Train Accuracy: 0.5961, Validation Accuracy: 0.5870, Loss: 0.7578
Epoch   0 Batch  197/1077 - Train Accuracy: 0.5645, Validation Accuracy: 0.5863, Loss: 0.7747
Epoch   0 Batch  198/1077 - Train Accuracy: 0.5990, Validation Accuracy: 0.5874, Loss: 0.7090
Epoch   0 Batch  199/1077 - Train Accuracy: 0.5477, Validation Accuracy: 0.5852, Loss: 0.7720
Epoch   0 Batch  200/1077 - Train Accuracy: 0.5332, Validation Accuracy: 0.5721, Loss: 0.7869
Epoch   0 Batch  201/1077 - Train Accuracy: 0.5453, Validation Accuracy: 0.5870, Loss: 0.7386
Epoch   0 Batch  202/1077 - Train Accuracy: 0.6051, Validation Accuracy: 0.5870, Loss: 0.7676
Epoch   0 Batch  203/1077 - Train Accuracy: 0.5516, Validation Accuracy: 0.5746, Loss: 0.7496
Epoch   0 Batch  204/1077 - Train Accuracy: 0.5742, Validation Accuracy: 0.5795, Loss: 0.7927
Epoch   0 Batch  205/1077 - Train Accuracy: 0.5922, Validation Accuracy: 0.5703, Loss: 0.7594
Epoch   0 Batch  206/1077 - Train Accuracy: 0.5598, Validation Accuracy: 0.5618, Loss: 0.7585
Epoch   0 Batch  207/1077 - Train Accuracy: 0.5098, Validation Accuracy: 0.5625, Loss: 0.7570
Epoch   0 Batch  208/1077 - Train Accuracy: 0.5696, Validation Accuracy: 0.5849, Loss: 0.7353
Epoch   0 Batch  209/1077 - Train Accuracy: 0.5833, Validation Accuracy: 0.5895, Loss: 0.7012
Epoch   0 Batch  210/1077 - Train Accuracy: 0.6034, Validation Accuracy: 0.5934, Loss: 0.7510
Epoch   0 Batch  211/1077 - Train Accuracy: 0.5316, Validation Accuracy: 0.5795, Loss: 0.7491
Epoch   0 Batch  212/1077 - Train Accuracy: 0.5766, Validation Accuracy: 0.5746, Loss: 0.7195
Epoch   0 Batch  213/1077 - Train Accuracy: 0.5637, Validation Accuracy: 0.5806, Loss: 0.6990
Epoch   0 Batch  214/1077 - Train Accuracy: 0.5750, Validation Accuracy: 0.5948, Loss: 0.7385
Epoch   0 Batch  215/1077 - Train Accuracy: 0.5598, Validation Accuracy: 0.6055, Loss: 0.7608
Epoch   0 Batch  216/1077 - Train Accuracy: 0.5492, Validation Accuracy: 0.5927, Loss: 0.7688
Epoch   0 Batch  217/1077 - Train Accuracy: 0.5816, Validation Accuracy: 0.5781, Loss: 0.7253
Epoch   0 Batch  218/1077 - Train Accuracy: 0.5502, Validation Accuracy: 0.5721, Loss: 0.8340
Epoch   0 Batch  219/1077 - Train Accuracy: 0.6125, Validation Accuracy: 0.5902, Loss: 0.7370
Epoch   0 Batch  220/1077 - Train Accuracy: 0.5720, Validation Accuracy: 0.6026, Loss: 0.7383
Epoch   0 Batch  221/1077 - Train Accuracy: 0.6049, Validation Accuracy: 0.6108, Loss: 0.7659
Epoch   0 Batch  222/1077 - Train Accuracy: 0.5465, Validation Accuracy: 0.5938, Loss: 0.7853
Epoch   0 Batch  223/1077 - Train Accuracy: 0.5636, Validation Accuracy: 0.5813, Loss: 0.6986
Epoch   0 Batch  224/1077 - Train Accuracy: 0.5758, Validation Accuracy: 0.5799, Loss: 0.7623
Epoch   0 Batch  225/1077 - Train Accuracy: 0.5789, Validation Accuracy: 0.6033, Loss: 0.7567
Epoch   0 Batch  226/1077 - Train Accuracy: 0.6074, Validation Accuracy: 0.6115, Loss: 0.7384
Epoch   0 Batch  227/1077 - Train Accuracy: 0.5508, Validation Accuracy: 0.6151, Loss: 0.7853
Epoch   0 Batch  228/1077 - Train Accuracy: 0.6066, Validation Accuracy: 0.6058, Loss: 0.7007
Epoch   0 Batch  229/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.5930, Loss: 0.7084
Epoch   0 Batch  230/1077 - Train Accuracy: 0.5856, Validation Accuracy: 0.5909, Loss: 0.7303
Epoch   0 Batch  231/1077 - Train Accuracy: 0.5703, Validation Accuracy: 0.6065, Loss: 0.7346
Epoch   0 Batch  232/1077 - Train Accuracy: 0.5724, Validation Accuracy: 0.6058, Loss: 0.7604
Epoch   0 Batch  233/1077 - Train Accuracy: 0.5695, Validation Accuracy: 0.6005, Loss: 0.7748
Epoch   0 Batch  234/1077 - Train Accuracy: 0.6064, Validation Accuracy: 0.5994, Loss: 0.7094
Epoch   0 Batch  235/1077 - Train Accuracy: 0.6265, Validation Accuracy: 0.6037, Loss: 0.6543
Epoch   0 Batch  236/1077 - Train Accuracy: 0.5605, Validation Accuracy: 0.6005, Loss: 0.7446
Epoch   0 Batch  237/1077 - Train Accuracy: 0.6079, Validation Accuracy: 0.6037, Loss: 0.6738
Epoch   0 Batch  238/1077 - Train Accuracy: 0.6000, Validation Accuracy: 0.6037, Loss: 0.7207
Epoch   0 Batch  239/1077 - Train Accuracy: 0.5978, Validation Accuracy: 0.6030, Loss: 0.6526
Epoch   0 Batch  240/1077 - Train Accuracy: 0.6094, Validation Accuracy: 0.6044, Loss: 0.7055
Epoch   0 Batch  241/1077 - Train Accuracy: 0.6289, Validation Accuracy: 0.5973, Loss: 0.6641
Epoch   0 Batch  242/1077 - Train Accuracy: 0.5609, Validation Accuracy: 0.5980, Loss: 0.6982
Epoch   0 Batch  243/1077 - Train Accuracy: 0.5340, Validation Accuracy: 0.6016, Loss: 0.7428
Epoch   0 Batch  244/1077 - Train Accuracy: 0.6200, Validation Accuracy: 0.5888, Loss: 0.6740
Epoch   0 Batch  245/1077 - Train Accuracy: 0.5796, Validation Accuracy: 0.5888, Loss: 0.6729
Epoch   0 Batch  246/1077 - Train Accuracy: 0.5891, Validation Accuracy: 0.5849, Loss: 0.7217
Epoch   0 Batch  247/1077 - Train Accuracy: 0.6157, Validation Accuracy: 0.5969, Loss: 0.6676
Epoch   0 Batch  248/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.5969, Loss: 0.6874
Epoch   0 Batch  249/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.5820, Loss: 0.6800
Epoch   0 Batch  250/1077 - Train Accuracy: 0.5732, Validation Accuracy: 0.5810, Loss: 0.6543
Epoch   0 Batch  251/1077 - Train Accuracy: 0.5945, Validation Accuracy: 0.5849, Loss: 0.7107
Epoch   0 Batch  252/1077 - Train Accuracy: 0.5637, Validation Accuracy: 0.5923, Loss: 0.7000
Epoch   0 Batch  253/1077 - Train Accuracy: 0.6151, Validation Accuracy: 0.5888, Loss: 0.6647
Epoch   0 Batch  254/1077 - Train Accuracy: 0.5789, Validation Accuracy: 0.5863, Loss: 0.6961
Epoch   0 Batch  255/1077 - Train Accuracy: 0.5723, Validation Accuracy: 0.5884, Loss: 0.6983
Epoch   0 Batch  256/1077 - Train Accuracy: 0.5660, Validation Accuracy: 0.5906, Loss: 0.7343
Epoch   0 Batch  257/1077 - Train Accuracy: 0.6213, Validation Accuracy: 0.5980, Loss: 0.6882
Epoch   0 Batch  258/1077 - Train Accuracy: 0.6131, Validation Accuracy: 0.5906, Loss: 0.6616
Epoch   0 Batch  259/1077 - Train Accuracy: 0.5621, Validation Accuracy: 0.5984, Loss: 0.6963
Epoch   0 Batch  260/1077 - Train Accuracy: 0.6131, Validation Accuracy: 0.5991, Loss: 0.6533
Epoch   0 Batch  261/1077 - Train Accuracy: 0.5774, Validation Accuracy: 0.5962, Loss: 0.6787
Epoch   0 Batch  262/1077 - Train Accuracy: 0.5906, Validation Accuracy: 0.6037, Loss: 0.6885
Epoch   0 Batch  263/1077 - Train Accuracy: 0.6195, Validation Accuracy: 0.5863, Loss: 0.6724
Epoch   0 Batch  264/1077 - Train Accuracy: 0.5730, Validation Accuracy: 0.5906, Loss: 0.6887
Epoch   0 Batch  265/1077 - Train Accuracy: 0.5680, Validation Accuracy: 0.5977, Loss: 0.7077
Epoch   0 Batch  266/1077 - Train Accuracy: 0.6168, Validation Accuracy: 0.6072, Loss: 0.6570
Epoch   0 Batch  267/1077 - Train Accuracy: 0.5909, Validation Accuracy: 0.6172, Loss: 0.6492
Epoch   0 Batch  268/1077 - Train Accuracy: 0.6156, Validation Accuracy: 0.6143, Loss: 0.6859
Epoch   0 Batch  269/1077 - Train Accuracy: 0.5592, Validation Accuracy: 0.6140, Loss: 0.7303
Epoch   0 Batch  270/1077 - Train Accuracy: 0.5621, Validation Accuracy: 0.6133, Loss: 0.6994
Epoch   0 Batch  271/1077 - Train Accuracy: 0.6113, Validation Accuracy: 0.6101, Loss: 0.6658
Epoch   0 Batch  272/1077 - Train Accuracy: 0.6049, Validation Accuracy: 0.6080, Loss: 0.7100
Epoch   0 Batch  273/1077 - Train Accuracy: 0.5930, Validation Accuracy: 0.6065, Loss: 0.6618
Epoch   0 Batch  274/1077 - Train Accuracy: 0.6068, Validation Accuracy: 0.5991, Loss: 0.6440
Epoch   0 Batch  275/1077 - Train Accuracy: 0.5911, Validation Accuracy: 0.5994, Loss: 0.6373
Epoch   0 Batch  276/1077 - Train Accuracy: 0.5602, Validation Accuracy: 0.5998, Loss: 0.7161
Epoch   0 Batch  277/1077 - Train Accuracy: 0.6004, Validation Accuracy: 0.6019, Loss: 0.6249
Epoch   0 Batch  278/1077 - Train Accuracy: 0.5953, Validation Accuracy: 0.6040, Loss: 0.7200
Epoch   0 Batch  279/1077 - Train Accuracy: 0.5965, Validation Accuracy: 0.6090, Loss: 0.7342
Epoch   0 Batch  280/1077 - Train Accuracy: 0.6203, Validation Accuracy: 0.6087, Loss: 0.7016
Epoch   0 Batch  281/1077 - Train Accuracy: 0.5953, Validation Accuracy: 0.6161, Loss: 0.7157
Epoch   0 Batch  282/1077 - Train Accuracy: 0.5582, Validation Accuracy: 0.6204, Loss: 0.6988
Epoch   0 Batch  283/1077 - Train Accuracy: 0.6230, Validation Accuracy: 0.6087, Loss: 0.6817
Epoch   0 Batch  284/1077 - Train Accuracy: 0.6027, Validation Accuracy: 0.6140, Loss: 0.7028
Epoch   0 Batch  285/1077 - Train Accuracy: 0.6224, Validation Accuracy: 0.6094, Loss: 0.6356
Epoch   0 Batch  286/1077 - Train Accuracy: 0.6399, Validation Accuracy: 0.6104, Loss: 0.6288
Epoch   0 Batch  287/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6108, Loss: 0.6400
Epoch   0 Batch  288/1077 - Train Accuracy: 0.5918, Validation Accuracy: 0.6097, Loss: 0.6924
Epoch   0 Batch  289/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6069, Loss: 0.6519
Epoch   0 Batch  290/1077 - Train Accuracy: 0.5898, Validation Accuracy: 0.6083, Loss: 0.6845
Epoch   0 Batch  291/1077 - Train Accuracy: 0.5796, Validation Accuracy: 0.6072, Loss: 0.6869
Epoch   0 Batch  292/1077 - Train Accuracy: 0.6447, Validation Accuracy: 0.6080, Loss: 0.6538
Epoch   0 Batch  293/1077 - Train Accuracy: 0.5766, Validation Accuracy: 0.6126, Loss: 0.7012
Epoch   0 Batch  294/1077 - Train Accuracy: 0.6357, Validation Accuracy: 0.6168, Loss: 0.6085
Epoch   0 Batch  295/1077 - Train Accuracy: 0.6192, Validation Accuracy: 0.6168, Loss: 0.6809
Epoch   0 Batch  296/1077 - Train Accuracy: 0.6291, Validation Accuracy: 0.6136, Loss: 0.6202
Epoch   0 Batch  297/1077 - Train Accuracy: 0.5855, Validation Accuracy: 0.6211, Loss: 0.6974
Epoch   0 Batch  298/1077 - Train Accuracy: 0.5891, Validation Accuracy: 0.6158, Loss: 0.7125
Epoch   0 Batch  299/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6193, Loss: 0.6492
Epoch   0 Batch  300/1077 - Train Accuracy: 0.6135, Validation Accuracy: 0.6190, Loss: 0.6494
Epoch   0 Batch  301/1077 - Train Accuracy: 0.6082, Validation Accuracy: 0.6151, Loss: 0.6478
Epoch   0 Batch  302/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6062, Loss: 0.6543
Epoch   0 Batch  303/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6016, Loss: 0.6588
Epoch   0 Batch  304/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.6044, Loss: 0.6174
Epoch   0 Batch  305/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6069, Loss: 0.6459
Epoch   0 Batch  306/1077 - Train Accuracy: 0.6168, Validation Accuracy: 0.6147, Loss: 0.6276
Epoch   0 Batch  307/1077 - Train Accuracy: 0.5945, Validation Accuracy: 0.6158, Loss: 0.6499
Epoch   0 Batch  308/1077 - Train Accuracy: 0.5852, Validation Accuracy: 0.6122, Loss: 0.7063
Epoch   0 Batch  309/1077 - Train Accuracy: 0.6231, Validation Accuracy: 0.6197, Loss: 0.6193
Epoch   0 Batch  310/1077 - Train Accuracy: 0.5898, Validation Accuracy: 0.6140, Loss: 0.6711
Epoch   0 Batch  311/1077 - Train Accuracy: 0.6503, Validation Accuracy: 0.6307, Loss: 0.6266
Epoch   0 Batch  312/1077 - Train Accuracy: 0.6211, Validation Accuracy: 0.6232, Loss: 0.6886
Epoch   0 Batch  313/1077 - Train Accuracy: 0.5930, Validation Accuracy: 0.6232, Loss: 0.6412
Epoch   0 Batch  314/1077 - Train Accuracy: 0.6332, Validation Accuracy: 0.6236, Loss: 0.6420
Epoch   0 Batch  315/1077 - Train Accuracy: 0.6429, Validation Accuracy: 0.6314, Loss: 0.5998
Epoch   0 Batch  316/1077 - Train Accuracy: 0.6243, Validation Accuracy: 0.6101, Loss: 0.6136
Epoch   0 Batch  317/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6026, Loss: 0.6728
Epoch   0 Batch  318/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.5945, Loss: 0.6604
Epoch   0 Batch  319/1077 - Train Accuracy: 0.6176, Validation Accuracy: 0.6044, Loss: 0.6435
Epoch   0 Batch  320/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6257, Loss: 0.6478
Epoch   0 Batch  321/1077 - Train Accuracy: 0.6066, Validation Accuracy: 0.6271, Loss: 0.6328
Epoch   0 Batch  322/1077 - Train Accuracy: 0.5856, Validation Accuracy: 0.6186, Loss: 0.6166
Epoch   0 Batch  323/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.5980, Loss: 0.6420
Epoch   0 Batch  324/1077 - Train Accuracy: 0.6164, Validation Accuracy: 0.5955, Loss: 0.6380
Epoch   0 Batch  325/1077 - Train Accuracy: 0.6607, Validation Accuracy: 0.5969, Loss: 0.6159
Epoch   0 Batch  326/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6069, Loss: 0.6309
Epoch   0 Batch  327/1077 - Train Accuracy: 0.6004, Validation Accuracy: 0.6097, Loss: 0.6421
Epoch   0 Batch  328/1077 - Train Accuracy: 0.6496, Validation Accuracy: 0.6037, Loss: 0.6443
Epoch   0 Batch  329/1077 - Train Accuracy: 0.5707, Validation Accuracy: 0.5973, Loss: 0.6650
Epoch   0 Batch  330/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6122, Loss: 0.6418
Epoch   0 Batch  331/1077 - Train Accuracy: 0.6172, Validation Accuracy: 0.6126, Loss: 0.6722
Epoch   0 Batch  332/1077 - Train Accuracy: 0.6105, Validation Accuracy: 0.6126, Loss: 0.5722
Epoch   0 Batch  333/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6058, Loss: 0.6457
Epoch   0 Batch  334/1077 - Train Accuracy: 0.6055, Validation Accuracy: 0.6072, Loss: 0.6313
Epoch   0 Batch  335/1077 - Train Accuracy: 0.6533, Validation Accuracy: 0.6072, Loss: 0.6183
Epoch   0 Batch  336/1077 - Train Accuracy: 0.6039, Validation Accuracy: 0.6040, Loss: 0.6457
Epoch   0 Batch  337/1077 - Train Accuracy: 0.5750, Validation Accuracy: 0.5980, Loss: 0.6592
Epoch   0 Batch  338/1077 - Train Accuracy: 0.6270, Validation Accuracy: 0.5934, Loss: 0.6646
Epoch   0 Batch  339/1077 - Train Accuracy: 0.6172, Validation Accuracy: 0.5969, Loss: 0.6012
Epoch   0 Batch  340/1077 - Train Accuracy: 0.5925, Validation Accuracy: 0.6076, Loss: 0.6452
Epoch   0 Batch  341/1077 - Train Accuracy: 0.6461, Validation Accuracy: 0.6012, Loss: 0.6687
Epoch   0 Batch  342/1077 - Train Accuracy: 0.6131, Validation Accuracy: 0.6097, Loss: 0.6022
Epoch   0 Batch  343/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.6165, Loss: 0.6499
Epoch   0 Batch  344/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.6179, Loss: 0.6405
Epoch   0 Batch  345/1077 - Train Accuracy: 0.6425, Validation Accuracy: 0.6268, Loss: 0.5911
Epoch   0 Batch  346/1077 - Train Accuracy: 0.5961, Validation Accuracy: 0.6300, Loss: 0.6265
Epoch   0 Batch  347/1077 - Train Accuracy: 0.6269, Validation Accuracy: 0.6300, Loss: 0.5637
Epoch   0 Batch  348/1077 - Train Accuracy: 0.5844, Validation Accuracy: 0.5863, Loss: 0.5907
Epoch   0 Batch  349/1077 - Train Accuracy: 0.5410, Validation Accuracy: 0.5668, Loss: 0.6117
Epoch   0 Batch  350/1077 - Train Accuracy: 0.5879, Validation Accuracy: 0.5810, Loss: 0.6141
Epoch   0 Batch  351/1077 - Train Accuracy: 0.5789, Validation Accuracy: 0.6175, Loss: 0.6586
Epoch   0 Batch  352/1077 - Train Accuracy: 0.6062, Validation Accuracy: 0.6154, Loss: 0.6094
Epoch   0 Batch  353/1077 - Train Accuracy: 0.6036, Validation Accuracy: 0.6154, Loss: 0.6810
Epoch   0 Batch  354/1077 - Train Accuracy: 0.6027, Validation Accuracy: 0.6122, Loss: 0.6597
Epoch   0 Batch  355/1077 - Train Accuracy: 0.6112, Validation Accuracy: 0.6115, Loss: 0.6029
Epoch   0 Batch  356/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6172, Loss: 0.6080
Epoch   0 Batch  357/1077 - Train Accuracy: 0.6514, Validation Accuracy: 0.6325, Loss: 0.5821
Epoch   0 Batch  358/1077 - Train Accuracy: 0.6073, Validation Accuracy: 0.6197, Loss: 0.6542
Epoch   0 Batch  359/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6314, Loss: 0.6213
Epoch   0 Batch  360/1077 - Train Accuracy: 0.6293, Validation Accuracy: 0.6264, Loss: 0.6033
Epoch   0 Batch  361/1077 - Train Accuracy: 0.6332, Validation Accuracy: 0.6282, Loss: 0.6488
Epoch   0 Batch  362/1077 - Train Accuracy: 0.6425, Validation Accuracy: 0.6307, Loss: 0.5852
Epoch   0 Batch  363/1077 - Train Accuracy: 0.5828, Validation Accuracy: 0.6357, Loss: 0.6211
Epoch   0 Batch  364/1077 - Train Accuracy: 0.6324, Validation Accuracy: 0.6342, Loss: 0.6319
Epoch   0 Batch  365/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.6296, Loss: 0.6034
Epoch   0 Batch  366/1077 - Train Accuracy: 0.5816, Validation Accuracy: 0.5991, Loss: 0.6111
Epoch   0 Batch  367/1077 - Train Accuracy: 0.6507, Validation Accuracy: 0.6186, Loss: 0.5431
Epoch   0 Batch  368/1077 - Train Accuracy: 0.6289, Validation Accuracy: 0.6250, Loss: 0.6027
Epoch   0 Batch  369/1077 - Train Accuracy: 0.6328, Validation Accuracy: 0.6197, Loss: 0.5603
Epoch   0 Batch  370/1077 - Train Accuracy: 0.6187, Validation Accuracy: 0.6161, Loss: 0.5905
Epoch   0 Batch  371/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6168, Loss: 0.5815
Epoch   0 Batch  372/1077 - Train Accuracy: 0.6230, Validation Accuracy: 0.6229, Loss: 0.5818
Epoch   0 Batch  373/1077 - Train Accuracy: 0.6585, Validation Accuracy: 0.6254, Loss: 0.5642
Epoch   0 Batch  374/1077 - Train Accuracy: 0.5848, Validation Accuracy: 0.6207, Loss: 0.6472
Epoch   0 Batch  375/1077 - Train Accuracy: 0.6644, Validation Accuracy: 0.6207, Loss: 0.5628
Epoch   0 Batch  376/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.6183, Loss: 0.5682
Epoch   0 Batch  377/1077 - Train Accuracy: 0.6266, Validation Accuracy: 0.6225, Loss: 0.5990
Epoch   0 Batch  378/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6222, Loss: 0.5844
Epoch   0 Batch  379/1077 - Train Accuracy: 0.6398, Validation Accuracy: 0.6282, Loss: 0.6083
Epoch   0 Batch  380/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6300, Loss: 0.5761
Epoch   0 Batch  381/1077 - Train Accuracy: 0.6297, Validation Accuracy: 0.6236, Loss: 0.5976
Epoch   0 Batch  382/1077 - Train Accuracy: 0.6217, Validation Accuracy: 0.6207, Loss: 0.6063
Epoch   0 Batch  383/1077 - Train Accuracy: 0.6362, Validation Accuracy: 0.6161, Loss: 0.5618
Epoch   0 Batch  384/1077 - Train Accuracy: 0.6266, Validation Accuracy: 0.6282, Loss: 0.5873
Epoch   0 Batch  385/1077 - Train Accuracy: 0.5973, Validation Accuracy: 0.6154, Loss: 0.5980
Epoch   0 Batch  386/1077 - Train Accuracy: 0.6231, Validation Accuracy: 0.6161, Loss: 0.5732
Epoch   0 Batch  387/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.6303, Loss: 0.5654
Epoch   0 Batch  388/1077 - Train Accuracy: 0.6469, Validation Accuracy: 0.6357, Loss: 0.5850
Epoch   0 Batch  389/1077 - Train Accuracy: 0.6344, Validation Accuracy: 0.6353, Loss: 0.5942
Epoch   0 Batch  390/1077 - Train Accuracy: 0.6055, Validation Accuracy: 0.6257, Loss: 0.6077
Epoch   0 Batch  391/1077 - Train Accuracy: 0.6276, Validation Accuracy: 0.6229, Loss: 0.5910
Epoch   0 Batch  392/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6200, Loss: 0.5721
Epoch   0 Batch  393/1077 - Train Accuracy: 0.6436, Validation Accuracy: 0.6268, Loss: 0.5429
Epoch   0 Batch  394/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6307, Loss: 0.5946
Epoch   0 Batch  395/1077 - Train Accuracy: 0.6384, Validation Accuracy: 0.6264, Loss: 0.5482
Epoch   0 Batch  396/1077 - Train Accuracy: 0.5980, Validation Accuracy: 0.6204, Loss: 0.5900
Epoch   0 Batch  397/1077 - Train Accuracy: 0.6670, Validation Accuracy: 0.6286, Loss: 0.5699
Epoch   0 Batch  398/1077 - Train Accuracy: 0.6225, Validation Accuracy: 0.6332, Loss: 0.6066
Epoch   0 Batch  399/1077 - Train Accuracy: 0.5962, Validation Accuracy: 0.6420, Loss: 0.6043
Epoch   0 Batch  400/1077 - Train Accuracy: 0.6680, Validation Accuracy: 0.6392, Loss: 0.5761
Epoch   0 Batch  401/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6261, Loss: 0.5690
Epoch   0 Batch  402/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.6211, Loss: 0.5444
Epoch   0 Batch  403/1077 - Train Accuracy: 0.6066, Validation Accuracy: 0.6183, Loss: 0.5927
Epoch   0 Batch  404/1077 - Train Accuracy: 0.6488, Validation Accuracy: 0.6214, Loss: 0.5473
Epoch   0 Batch  405/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6332, Loss: 0.6152
Epoch   0 Batch  406/1077 - Train Accuracy: 0.6665, Validation Accuracy: 0.6360, Loss: 0.5556
Epoch   0 Batch  407/1077 - Train Accuracy: 0.6188, Validation Accuracy: 0.6403, Loss: 0.5932
Epoch   0 Batch  408/1077 - Train Accuracy: 0.6125, Validation Accuracy: 0.6349, Loss: 0.5798
Epoch   0 Batch  409/1077 - Train Accuracy: 0.6191, Validation Accuracy: 0.6413, Loss: 0.5874
Epoch   0 Batch  410/1077 - Train Accuracy: 0.6143, Validation Accuracy: 0.6438, Loss: 0.5834
Epoch   0 Batch  411/1077 - Train Accuracy: 0.6492, Validation Accuracy: 0.6268, Loss: 0.5396
Epoch   0 Batch  412/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6417, Loss: 0.5474
Epoch   0 Batch  413/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6438, Loss: 0.5691
Epoch   0 Batch  414/1077 - Train Accuracy: 0.6074, Validation Accuracy: 0.6442, Loss: 0.6050
Epoch   0 Batch  415/1077 - Train Accuracy: 0.6536, Validation Accuracy: 0.6435, Loss: 0.5279
Epoch   0 Batch  416/1077 - Train Accuracy: 0.6254, Validation Accuracy: 0.6435, Loss: 0.5738
Epoch   0 Batch  417/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6367, Loss: 0.5863
Epoch   0 Batch  418/1077 - Train Accuracy: 0.6293, Validation Accuracy: 0.6396, Loss: 0.5580
Epoch   0 Batch  419/1077 - Train Accuracy: 0.6398, Validation Accuracy: 0.6413, Loss: 0.5698
Epoch   0 Batch  420/1077 - Train Accuracy: 0.6500, Validation Accuracy: 0.6598, Loss: 0.5284
Epoch   0 Batch  421/1077 - Train Accuracy: 0.6324, Validation Accuracy: 0.6562, Loss: 0.5840
Epoch   0 Batch  422/1077 - Train Accuracy: 0.6202, Validation Accuracy: 0.6513, Loss: 0.5535
Epoch   0 Batch  423/1077 - Train Accuracy: 0.6535, Validation Accuracy: 0.6435, Loss: 0.5733
Epoch   0 Batch  424/1077 - Train Accuracy: 0.5754, Validation Accuracy: 0.6413, Loss: 0.5561
Epoch   0 Batch  425/1077 - Train Accuracy: 0.6510, Validation Accuracy: 0.6428, Loss: 0.5399
Epoch   0 Batch  426/1077 - Train Accuracy: 0.6234, Validation Accuracy: 0.6349, Loss: 0.5679
Epoch   0 Batch  427/1077 - Train Accuracy: 0.6094, Validation Accuracy: 0.6417, Loss: 0.5555
Epoch   0 Batch  428/1077 - Train Accuracy: 0.6693, Validation Accuracy: 0.6342, Loss: 0.4961
Epoch   0 Batch  429/1077 - Train Accuracy: 0.6500, Validation Accuracy: 0.6296, Loss: 0.5405
Epoch   0 Batch  430/1077 - Train Accuracy: 0.6305, Validation Accuracy: 0.6360, Loss: 0.5523
Epoch   0 Batch  431/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6392, Loss: 0.5527
Epoch   0 Batch  432/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6559, Loss: 0.5532
Epoch   0 Batch  433/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6538, Loss: 0.5451
Epoch   0 Batch  434/1077 - Train Accuracy: 0.5984, Validation Accuracy: 0.6456, Loss: 0.5662
Epoch   0 Batch  435/1077 - Train Accuracy: 0.6303, Validation Accuracy: 0.6232, Loss: 0.5632
Epoch   0 Batch  436/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6222, Loss: 0.5296
Epoch   0 Batch  437/1077 - Train Accuracy: 0.6086, Validation Accuracy: 0.6211, Loss: 0.5546
Epoch   0 Batch  438/1077 - Train Accuracy: 0.6043, Validation Accuracy: 0.6353, Loss: 0.5600
Epoch   0 Batch  439/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6325, Loss: 0.5528
Epoch   0 Batch  440/1077 - Train Accuracy: 0.6148, Validation Accuracy: 0.6392, Loss: 0.5768
Epoch   0 Batch  441/1077 - Train Accuracy: 0.6027, Validation Accuracy: 0.6523, Loss: 0.5232
Epoch   0 Batch  442/1077 - Train Accuracy: 0.6109, Validation Accuracy: 0.6420, Loss: 0.5326
Epoch   0 Batch  443/1077 - Train Accuracy: 0.6295, Validation Accuracy: 0.5994, Loss: 0.5335
Epoch   0 Batch  444/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6154, Loss: 0.5261
Epoch   0 Batch  445/1077 - Train Accuracy: 0.6020, Validation Accuracy: 0.6328, Loss: 0.5550
Epoch   0 Batch  446/1077 - Train Accuracy: 0.6358, Validation Accuracy: 0.6396, Loss: 0.5068
Epoch   0 Batch  447/1077 - Train Accuracy: 0.6391, Validation Accuracy: 0.6310, Loss: 0.5403
Epoch   0 Batch  448/1077 - Train Accuracy: 0.6422, Validation Accuracy: 0.6314, Loss: 0.5574
Epoch   0 Batch  449/1077 - Train Accuracy: 0.6035, Validation Accuracy: 0.6335, Loss: 0.5599
Epoch   0 Batch  450/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.6342, Loss: 0.5292
Epoch   0 Batch  451/1077 - Train Accuracy: 0.6615, Validation Accuracy: 0.6342, Loss: 0.5009
Epoch   0 Batch  452/1077 - Train Accuracy: 0.6441, Validation Accuracy: 0.6392, Loss: 0.5375
Epoch   0 Batch  453/1077 - Train Accuracy: 0.6804, Validation Accuracy: 0.6349, Loss: 0.5173
Epoch   0 Batch  454/1077 - Train Accuracy: 0.6461, Validation Accuracy: 0.6335, Loss: 0.5371
Epoch   0 Batch  455/1077 - Train Accuracy: 0.6431, Validation Accuracy: 0.6438, Loss: 0.5155
Epoch   0 Batch  456/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6463, Loss: 0.5447
Epoch   0 Batch  457/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6527, Loss: 0.4985
Epoch   0 Batch  458/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6523, Loss: 0.5396
Epoch   0 Batch  459/1077 - Train Accuracy: 0.6845, Validation Accuracy: 0.6552, Loss: 0.5020
Epoch   0 Batch  460/1077 - Train Accuracy: 0.6469, Validation Accuracy: 0.6665, Loss: 0.5477
Epoch   0 Batch  461/1077 - Train Accuracy: 0.6547, Validation Accuracy: 0.6658, Loss: 0.5248
Epoch   0 Batch  462/1077 - Train Accuracy: 0.6320, Validation Accuracy: 0.6655, Loss: 0.5257
Epoch   0 Batch  463/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6697, Loss: 0.5343
Epoch   0 Batch  464/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6616, Loss: 0.5313
Epoch   0 Batch  465/1077 - Train Accuracy: 0.6443, Validation Accuracy: 0.6577, Loss: 0.5834
Epoch   0 Batch  466/1077 - Train Accuracy: 0.6438, Validation Accuracy: 0.6552, Loss: 0.5185
Epoch   0 Batch  467/1077 - Train Accuracy: 0.7135, Validation Accuracy: 0.6488, Loss: 0.5125
Epoch   0 Batch  468/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.6502, Loss: 0.5117
Epoch   0 Batch  469/1077 - Train Accuracy: 0.6027, Validation Accuracy: 0.6506, Loss: 0.5353
Epoch   0 Batch  470/1077 - Train Accuracy: 0.6258, Validation Accuracy: 0.6513, Loss: 0.5427
Epoch   0 Batch  471/1077 - Train Accuracy: 0.6742, Validation Accuracy: 0.6577, Loss: 0.5074
Epoch   0 Batch  472/1077 - Train Accuracy: 0.6496, Validation Accuracy: 0.6584, Loss: 0.5002
Epoch   0 Batch  473/1077 - Train Accuracy: 0.6359, Validation Accuracy: 0.6460, Loss: 0.5303
Epoch   0 Batch  474/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6435, Loss: 0.5274
Epoch   0 Batch  475/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6520, Loss: 0.4932
Epoch   0 Batch  476/1077 - Train Accuracy: 0.6678, Validation Accuracy: 0.6456, Loss: 0.5060
Epoch   0 Batch  477/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.6474, Loss: 0.4894
Epoch   0 Batch  478/1077 - Train Accuracy: 0.6743, Validation Accuracy: 0.6559, Loss: 0.5517
Epoch   0 Batch  479/1077 - Train Accuracy: 0.6484, Validation Accuracy: 0.6584, Loss: 0.5267
Epoch   0 Batch  480/1077 - Train Accuracy: 0.6842, Validation Accuracy: 0.6534, Loss: 0.5192
Epoch   0 Batch  481/1077 - Train Accuracy: 0.6352, Validation Accuracy: 0.6602, Loss: 0.5179
Epoch   0 Batch  482/1077 - Train Accuracy: 0.6550, Validation Accuracy: 0.6577, Loss: 0.5342
Epoch   0 Batch  483/1077 - Train Accuracy: 0.6285, Validation Accuracy: 0.6594, Loss: 0.5068
Epoch   0 Batch  484/1077 - Train Accuracy: 0.6895, Validation Accuracy: 0.6612, Loss: 0.5002
Epoch   0 Batch  485/1077 - Train Accuracy: 0.6973, Validation Accuracy: 0.6665, Loss: 0.5218
Epoch   0 Batch  486/1077 - Train Accuracy: 0.6690, Validation Accuracy: 0.6676, Loss: 0.5132
Epoch   0 Batch  487/1077 - Train Accuracy: 0.6530, Validation Accuracy: 0.6690, Loss: 0.5261
Epoch   0 Batch  488/1077 - Train Accuracy: 0.6591, Validation Accuracy: 0.6665, Loss: 0.5265
Epoch   0 Batch  489/1077 - Train Accuracy: 0.6689, Validation Accuracy: 0.6722, Loss: 0.4789
Epoch   0 Batch  490/1077 - Train Accuracy: 0.6684, Validation Accuracy: 0.6701, Loss: 0.5144
Epoch   0 Batch  491/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6683, Loss: 0.4955
Epoch   0 Batch  492/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.6673, Loss: 0.5171
Epoch   0 Batch  493/1077 - Train Accuracy: 0.6842, Validation Accuracy: 0.6609, Loss: 0.4755
Epoch   0 Batch  494/1077 - Train Accuracy: 0.6625, Validation Accuracy: 0.6612, Loss: 0.4964
Epoch   0 Batch  495/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6648, Loss: 0.4812
Epoch   0 Batch  496/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6786, Loss: 0.5235
Epoch   0 Batch  497/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6776, Loss: 0.5424
Epoch   0 Batch  498/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.6733, Loss: 0.4977
Epoch   0 Batch  499/1077 - Train Accuracy: 0.6324, Validation Accuracy: 0.6690, Loss: 0.4861
Epoch   0 Batch  500/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6765, Loss: 0.4998
Epoch   0 Batch  501/1077 - Train Accuracy: 0.6465, Validation Accuracy: 0.6722, Loss: 0.4957
Epoch   0 Batch  502/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6680, Loss: 0.5007
Epoch   0 Batch  503/1077 - Train Accuracy: 0.6832, Validation Accuracy: 0.6705, Loss: 0.4975
Epoch   0 Batch  504/1077 - Train Accuracy: 0.6430, Validation Accuracy: 0.6744, Loss: 0.5354
Epoch   0 Batch  505/1077 - Train Accuracy: 0.7028, Validation Accuracy: 0.6697, Loss: 0.4480
Epoch   0 Batch  506/1077 - Train Accuracy: 0.6504, Validation Accuracy: 0.6673, Loss: 0.5163
Epoch   0 Batch  507/1077 - Train Accuracy: 0.6387, Validation Accuracy: 0.6697, Loss: 0.4956
Epoch   0 Batch  508/1077 - Train Accuracy: 0.6689, Validation Accuracy: 0.6697, Loss: 0.4775
Epoch   0 Batch  509/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6662, Loss: 0.5111
Epoch   0 Batch  510/1077 - Train Accuracy: 0.6664, Validation Accuracy: 0.6676, Loss: 0.4769
Epoch   0 Batch  511/1077 - Train Accuracy: 0.6427, Validation Accuracy: 0.6683, Loss: 0.4946
Epoch   0 Batch  512/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.6722, Loss: 0.4854
Epoch   0 Batch  513/1077 - Train Accuracy: 0.6625, Validation Accuracy: 0.6719, Loss: 0.4930
Epoch   0 Batch  514/1077 - Train Accuracy: 0.6082, Validation Accuracy: 0.6737, Loss: 0.4934
Epoch   0 Batch  515/1077 - Train Accuracy: 0.6402, Validation Accuracy: 0.6697, Loss: 0.5088
Epoch   0 Batch  516/1077 - Train Accuracy: 0.7024, Validation Accuracy: 0.6761, Loss: 0.4623
Epoch   0 Batch  517/1077 - Train Accuracy: 0.7050, Validation Accuracy: 0.6715, Loss: 0.4829
Epoch   0 Batch  518/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.6726, Loss: 0.4833
Epoch   0 Batch  519/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.6708, Loss: 0.4884
Epoch   0 Batch  520/1077 - Train Accuracy: 0.7020, Validation Accuracy: 0.6726, Loss: 0.4656
Epoch   0 Batch  521/1077 - Train Accuracy: 0.6756, Validation Accuracy: 0.6722, Loss: 0.4506
Epoch   0 Batch  522/1077 - Train Accuracy: 0.6418, Validation Accuracy: 0.6779, Loss: 0.5043
Epoch   0 Batch  523/1077 - Train Accuracy: 0.6371, Validation Accuracy: 0.6729, Loss: 0.5048
Epoch   0 Batch  524/1077 - Train Accuracy: 0.6488, Validation Accuracy: 0.6747, Loss: 0.4921
Epoch   0 Batch  525/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6740, Loss: 0.4763
Epoch   0 Batch  526/1077 - Train Accuracy: 0.6672, Validation Accuracy: 0.6708, Loss: 0.4818
Epoch   0 Batch  527/1077 - Train Accuracy: 0.6550, Validation Accuracy: 0.6783, Loss: 0.5000
Epoch   0 Batch  528/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.6747, Loss: 0.4807
Epoch   0 Batch  529/1077 - Train Accuracy: 0.6641, Validation Accuracy: 0.6690, Loss: 0.4822
Epoch   0 Batch  530/1077 - Train Accuracy: 0.6531, Validation Accuracy: 0.6630, Loss: 0.5012
Epoch   0 Batch  531/1077 - Train Accuracy: 0.6477, Validation Accuracy: 0.6594, Loss: 0.4757
Epoch   0 Batch  532/1077 - Train Accuracy: 0.6070, Validation Accuracy: 0.6641, Loss: 0.5237
Epoch   0 Batch  533/1077 - Train Accuracy: 0.6469, Validation Accuracy: 0.6577, Loss: 0.4990
Epoch   0 Batch  534/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6602, Loss: 0.4831
Epoch   0 Batch  535/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6584, Loss: 0.4681
Epoch   0 Batch  536/1077 - Train Accuracy: 0.6492, Validation Accuracy: 0.6680, Loss: 0.4647
Epoch   0 Batch  537/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6722, Loss: 0.4774
Epoch   0 Batch  538/1077 - Train Accuracy: 0.6845, Validation Accuracy: 0.6804, Loss: 0.4437
Epoch   0 Batch  539/1077 - Train Accuracy: 0.6855, Validation Accuracy: 0.6886, Loss: 0.4925
Epoch   0 Batch  540/1077 - Train Accuracy: 0.6785, Validation Accuracy: 0.6861, Loss: 0.4405
Epoch   0 Batch  541/1077 - Train Accuracy: 0.6699, Validation Accuracy: 0.6861, Loss: 0.4721
Epoch   0 Batch  542/1077 - Train Accuracy: 0.6832, Validation Accuracy: 0.6850, Loss: 0.4650
Epoch   0 Batch  543/1077 - Train Accuracy: 0.6652, Validation Accuracy: 0.6879, Loss: 0.4773
Epoch   0 Batch  544/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.6832, Loss: 0.4537
Epoch   0 Batch  545/1077 - Train Accuracy: 0.6758, Validation Accuracy: 0.6818, Loss: 0.4853
Epoch   0 Batch  546/1077 - Train Accuracy: 0.6496, Validation Accuracy: 0.6832, Loss: 0.4921
Epoch   0 Batch  547/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.6847, Loss: 0.4692
Epoch   0 Batch  548/1077 - Train Accuracy: 0.6613, Validation Accuracy: 0.6882, Loss: 0.4910
Epoch   0 Batch  549/1077 - Train Accuracy: 0.6324, Validation Accuracy: 0.6871, Loss: 0.4962
Epoch   0 Batch  550/1077 - Train Accuracy: 0.6617, Validation Accuracy: 0.6861, Loss: 0.4884
Epoch   0 Batch  551/1077 - Train Accuracy: 0.6668, Validation Accuracy: 0.6960, Loss: 0.4809
Epoch   0 Batch  552/1077 - Train Accuracy: 0.6738, Validation Accuracy: 0.6918, Loss: 0.4818
Epoch   0 Batch  553/1077 - Train Accuracy: 0.6980, Validation Accuracy: 0.6861, Loss: 0.4747
Epoch   0 Batch  554/1077 - Train Accuracy: 0.6914, Validation Accuracy: 0.6896, Loss: 0.4616
Epoch   0 Batch  555/1077 - Train Accuracy: 0.6973, Validation Accuracy: 0.6889, Loss: 0.4733
Epoch   0 Batch  556/1077 - Train Accuracy: 0.6824, Validation Accuracy: 0.6797, Loss: 0.4614
Epoch   0 Batch  557/1077 - Train Accuracy: 0.6934, Validation Accuracy: 0.6722, Loss: 0.4663
Epoch   0 Batch  558/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6697, Loss: 0.4496
Epoch   0 Batch  559/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.6722, Loss: 0.4699
Epoch   0 Batch  560/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6687, Loss: 0.4577
Epoch   0 Batch  561/1077 - Train Accuracy: 0.7251, Validation Accuracy: 0.6705, Loss: 0.4411
Epoch   0 Batch  562/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.6712, Loss: 0.4256
Epoch   0 Batch  563/1077 - Train Accuracy: 0.6512, Validation Accuracy: 0.6694, Loss: 0.4751
Epoch   0 Batch  564/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.6779, Loss: 0.4941
Epoch   0 Batch  565/1077 - Train Accuracy: 0.6882, Validation Accuracy: 0.6797, Loss: 0.4627
Epoch   0 Batch  566/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6715, Loss: 0.4847
Epoch   0 Batch  567/1077 - Train Accuracy: 0.6660, Validation Accuracy: 0.6676, Loss: 0.4767
Epoch   0 Batch  568/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.6726, Loss: 0.4597
Epoch   0 Batch  569/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.6751, Loss: 0.4499
Epoch   0 Batch  570/1077 - Train Accuracy: 0.6690, Validation Accuracy: 0.6832, Loss: 0.4924
Epoch   0 Batch  571/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.6804, Loss: 0.4360
Epoch   0 Batch  572/1077 - Train Accuracy: 0.7117, Validation Accuracy: 0.6854, Loss: 0.4248
Epoch   0 Batch  573/1077 - Train Accuracy: 0.6648, Validation Accuracy: 0.6829, Loss: 0.4814
Epoch   0 Batch  574/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.6896, Loss: 0.4983
Epoch   0 Batch  575/1077 - Train Accuracy: 0.6830, Validation Accuracy: 0.6903, Loss: 0.4657
Epoch   0 Batch  576/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6896, Loss: 0.4713
Epoch   0 Batch  577/1077 - Train Accuracy: 0.6678, Validation Accuracy: 0.6900, Loss: 0.4796
Epoch   0 Batch  578/1077 - Train Accuracy: 0.6645, Validation Accuracy: 0.6832, Loss: 0.4744
Epoch   0 Batch  579/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.6825, Loss: 0.4540
Epoch   0 Batch  580/1077 - Train Accuracy: 0.7247, Validation Accuracy: 0.6832, Loss: 0.4181
Epoch   0 Batch  581/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6882, Loss: 0.4438
Epoch   0 Batch  582/1077 - Train Accuracy: 0.6746, Validation Accuracy: 0.6868, Loss: 0.4568
Epoch   0 Batch  583/1077 - Train Accuracy: 0.6739, Validation Accuracy: 0.6896, Loss: 0.4757
Epoch   0 Batch  584/1077 - Train Accuracy: 0.6897, Validation Accuracy: 0.6886, Loss: 0.4511
Epoch   0 Batch  585/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.6889, Loss: 0.4249
Epoch   0 Batch  586/1077 - Train Accuracy: 0.6624, Validation Accuracy: 0.6971, Loss: 0.4806
Epoch   0 Batch  587/1077 - Train Accuracy: 0.6905, Validation Accuracy: 0.6332, Loss: 0.4268
Epoch   0 Batch  588/1077 - Train Accuracy: 0.6094, Validation Accuracy: 0.6005, Loss: 0.4650
Epoch   0 Batch  589/1077 - Train Accuracy: 0.6147, Validation Accuracy: 0.6051, Loss: 0.4826
Epoch   0 Batch  590/1077 - Train Accuracy: 0.6546, Validation Accuracy: 0.6381, Loss: 0.4878
Epoch   0 Batch  591/1077 - Train Accuracy: 0.7021, Validation Accuracy: 0.6882, Loss: 0.4238
Epoch   0 Batch  592/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.6879, Loss: 0.4701
Epoch   0 Batch  593/1077 - Train Accuracy: 0.6864, Validation Accuracy: 0.6839, Loss: 0.4362
Epoch   0 Batch  594/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.6864, Loss: 0.4777
Epoch   0 Batch  595/1077 - Train Accuracy: 0.6871, Validation Accuracy: 0.6871, Loss: 0.4565
Epoch   0 Batch  596/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.6896, Loss: 0.4749
Epoch   0 Batch  597/1077 - Train Accuracy: 0.6742, Validation Accuracy: 0.6946, Loss: 0.4590
Epoch   0 Batch  598/1077 - Train Accuracy: 0.7046, Validation Accuracy: 0.6967, Loss: 0.4255
Epoch   0 Batch  599/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6928, Loss: 0.4922
Epoch   0 Batch  600/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.6925, Loss: 0.4164
Epoch   0 Batch  601/1077 - Train Accuracy: 0.6894, Validation Accuracy: 0.6911, Loss: 0.4536
Epoch   0 Batch  602/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.6921, Loss: 0.4594
Epoch   0 Batch  603/1077 - Train Accuracy: 0.6868, Validation Accuracy: 0.6871, Loss: 0.4286
Epoch   0 Batch  604/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6903, Loss: 0.4583
Epoch   0 Batch  605/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.6925, Loss: 0.4873
Epoch   0 Batch  606/1077 - Train Accuracy: 0.7210, Validation Accuracy: 0.6935, Loss: 0.4225
Epoch   0 Batch  607/1077 - Train Accuracy: 0.7603, Validation Accuracy: 0.6900, Loss: 0.4301
Epoch   0 Batch  608/1077 - Train Accuracy: 0.6719, Validation Accuracy: 0.6925, Loss: 0.4722
Epoch   0 Batch  609/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.6946, Loss: 0.4517
Epoch   0 Batch  610/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6935, Loss: 0.4666
Epoch   0 Batch  611/1077 - Train Accuracy: 0.6781, Validation Accuracy: 0.6918, Loss: 0.4430
Epoch   0 Batch  612/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.6914, Loss: 0.4240
Epoch   0 Batch  613/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.6857, Loss: 0.4564
Epoch   0 Batch  614/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.6935, Loss: 0.4236
Epoch   0 Batch  615/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.6921, Loss: 0.4506
Epoch   0 Batch  616/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6946, Loss: 0.4831
Epoch   0 Batch  617/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.6942, Loss: 0.4460
Epoch   0 Batch  618/1077 - Train Accuracy: 0.6883, Validation Accuracy: 0.6896, Loss: 0.4535
Epoch   0 Batch  619/1077 - Train Accuracy: 0.6702, Validation Accuracy: 0.6882, Loss: 0.4414
Epoch   0 Batch  620/1077 - Train Accuracy: 0.7078, Validation Accuracy: 0.6893, Loss: 0.4315
Epoch   0 Batch  621/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.6967, Loss: 0.4359
Epoch   0 Batch  622/1077 - Train Accuracy: 0.6945, Validation Accuracy: 0.6989, Loss: 0.4850
Epoch   0 Batch  623/1077 - Train Accuracy: 0.6805, Validation Accuracy: 0.6992, Loss: 0.4402
Epoch   0 Batch  624/1077 - Train Accuracy: 0.7173, Validation Accuracy: 0.6946, Loss: 0.4268
Epoch   0 Batch  625/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.7010, Loss: 0.4469
Epoch   0 Batch  626/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.6989, Loss: 0.4014
Epoch   0 Batch  627/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.7013, Loss: 0.4391
Epoch   0 Batch  628/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6974, Loss: 0.4545
Epoch   0 Batch  629/1077 - Train Accuracy: 0.6756, Validation Accuracy: 0.6925, Loss: 0.4658
Epoch   0 Batch  630/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.6967, Loss: 0.4503
Epoch   0 Batch  631/1077 - Train Accuracy: 0.6778, Validation Accuracy: 0.6967, Loss: 0.4159
Epoch   0 Batch  632/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.6982, Loss: 0.4415
Epoch   0 Batch  633/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.6967, Loss: 0.4488
Epoch   0 Batch  634/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6960, Loss: 0.4028
Epoch   0 Batch  635/1077 - Train Accuracy: 0.6394, Validation Accuracy: 0.6925, Loss: 0.4843
Epoch   0 Batch  636/1077 - Train Accuracy: 0.7129, Validation Accuracy: 0.6907, Loss: 0.4276
Epoch   0 Batch  637/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.6978, Loss: 0.4447
Epoch   0 Batch  638/1077 - Train Accuracy: 0.6656, Validation Accuracy: 0.7003, Loss: 0.4330
Epoch   0 Batch  639/1077 - Train Accuracy: 0.7281, Validation Accuracy: 0.6974, Loss: 0.4486
Epoch   0 Batch  640/1077 - Train Accuracy: 0.6670, Validation Accuracy: 0.6989, Loss: 0.4289
Epoch   0 Batch  641/1077 - Train Accuracy: 0.6828, Validation Accuracy: 0.6946, Loss: 0.4154
Epoch   0 Batch  642/1077 - Train Accuracy: 0.6864, Validation Accuracy: 0.6925, Loss: 0.4327
Epoch   0 Batch  643/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6918, Loss: 0.3966
Epoch   0 Batch  644/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.6939, Loss: 0.4424
Epoch   0 Batch  645/1077 - Train Accuracy: 0.7303, Validation Accuracy: 0.7095, Loss: 0.4013
Epoch   0 Batch  646/1077 - Train Accuracy: 0.7307, Validation Accuracy: 0.7038, Loss: 0.4160
Epoch   0 Batch  647/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.6985, Loss: 0.4263
Epoch   0 Batch  648/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.6985, Loss: 0.4039
Epoch   0 Batch  649/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.6694, Loss: 0.4422
Epoch   0 Batch  650/1077 - Train Accuracy: 0.6555, Validation Accuracy: 0.6566, Loss: 0.4250
Epoch   0 Batch  651/1077 - Train Accuracy: 0.6674, Validation Accuracy: 0.6431, Loss: 0.4171
Epoch   0 Batch  652/1077 - Train Accuracy: 0.6842, Validation Accuracy: 0.6495, Loss: 0.4693
Epoch   0 Batch  653/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.6623, Loss: 0.4153
Epoch   0 Batch  654/1077 - Train Accuracy: 0.6707, Validation Accuracy: 0.6839, Loss: 0.4260
Epoch   0 Batch  655/1077 - Train Accuracy: 0.6953, Validation Accuracy: 0.6772, Loss: 0.4384
Epoch   0 Batch  656/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.6857, Loss: 0.4187
Epoch   0 Batch  657/1077 - Train Accuracy: 0.7142, Validation Accuracy: 0.6861, Loss: 0.4373
Epoch   0 Batch  658/1077 - Train Accuracy: 0.6927, Validation Accuracy: 0.6896, Loss: 0.4020
Epoch   0 Batch  659/1077 - Train Accuracy: 0.7236, Validation Accuracy: 0.6911, Loss: 0.3988
Epoch   0 Batch  660/1077 - Train Accuracy: 0.6836, Validation Accuracy: 0.6847, Loss: 0.4449
Epoch   0 Batch  661/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.6914, Loss: 0.3902
Epoch   0 Batch  662/1077 - Train Accuracy: 0.6987, Validation Accuracy: 0.6825, Loss: 0.4178
Epoch   0 Batch  663/1077 - Train Accuracy: 0.6656, Validation Accuracy: 0.6030, Loss: 0.3976
Epoch   0 Batch  664/1077 - Train Accuracy: 0.6039, Validation Accuracy: 0.5817, Loss: 0.4359
Epoch   0 Batch  665/1077 - Train Accuracy: 0.5723, Validation Accuracy: 0.5735, Loss: 0.4339
Epoch   0 Batch  666/1077 - Train Accuracy: 0.5938, Validation Accuracy: 0.6005, Loss: 0.4503
Epoch   0 Batch  667/1077 - Train Accuracy: 0.6287, Validation Accuracy: 0.6133, Loss: 0.4642
Epoch   0 Batch  668/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.6964, Loss: 0.4129
Epoch   0 Batch  669/1077 - Train Accuracy: 0.7039, Validation Accuracy: 0.6957, Loss: 0.4099
Epoch   0 Batch  670/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.6964, Loss: 0.4155
Epoch   0 Batch  671/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.7010, Loss: 0.4423
Epoch   0 Batch  672/1077 - Train Accuracy: 0.7303, Validation Accuracy: 0.6999, Loss: 0.4123
Epoch   0 Batch  673/1077 - Train Accuracy: 0.7135, Validation Accuracy: 0.6942, Loss: 0.3894
Epoch   0 Batch  674/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.6978, Loss: 0.4375
Epoch   0 Batch  675/1077 - Train Accuracy: 0.7005, Validation Accuracy: 0.7017, Loss: 0.4273
Epoch   0 Batch  676/1077 - Train Accuracy: 0.7196, Validation Accuracy: 0.7042, Loss: 0.4305
Epoch   0 Batch  677/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.6935, Loss: 0.4482
Epoch   0 Batch  678/1077 - Train Accuracy: 0.6696, Validation Accuracy: 0.6999, Loss: 0.4049
Epoch   0 Batch  679/1077 - Train Accuracy: 0.6665, Validation Accuracy: 0.6974, Loss: 0.4252
Epoch   0 Batch  680/1077 - Train Accuracy: 0.6778, Validation Accuracy: 0.6825, Loss: 0.4030
Epoch   0 Batch  681/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.6733, Loss: 0.4166
Epoch   0 Batch  682/1077 - Train Accuracy: 0.6434, Validation Accuracy: 0.6602, Loss: 0.4319
Epoch   0 Batch  683/1077 - Train Accuracy: 0.6445, Validation Accuracy: 0.6484, Loss: 0.4047
Epoch   0 Batch  684/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6364, Loss: 0.4150
Epoch   0 Batch  685/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.6673, Loss: 0.4367
Epoch   0 Batch  686/1077 - Train Accuracy: 0.7210, Validation Accuracy: 0.6793, Loss: 0.3897
Epoch   0 Batch  687/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.6868, Loss: 0.4432
Epoch   0 Batch  688/1077 - Train Accuracy: 0.6977, Validation Accuracy: 0.6868, Loss: 0.4214
Epoch   0 Batch  689/1077 - Train Accuracy: 0.6750, Validation Accuracy: 0.6857, Loss: 0.4157
Epoch   0 Batch  690/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.6879, Loss: 0.4119
Epoch   0 Batch  691/1077 - Train Accuracy: 0.6822, Validation Accuracy: 0.6836, Loss: 0.4442
Epoch   0 Batch  692/1077 - Train Accuracy: 0.7061, Validation Accuracy: 0.6964, Loss: 0.3884
Epoch   0 Batch  693/1077 - Train Accuracy: 0.6513, Validation Accuracy: 0.7024, Loss: 0.4854
Epoch   0 Batch  694/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7003, Loss: 0.4100
Epoch   0 Batch  695/1077 - Train Accuracy: 0.7203, Validation Accuracy: 0.6996, Loss: 0.3925
Epoch   0 Batch  696/1077 - Train Accuracy: 0.6690, Validation Accuracy: 0.6982, Loss: 0.4460
Epoch   0 Batch  697/1077 - Train Accuracy: 0.6984, Validation Accuracy: 0.7035, Loss: 0.4107
Epoch   0 Batch  698/1077 - Train Accuracy: 0.6938, Validation Accuracy: 0.7088, Loss: 0.3957
Epoch   0 Batch  699/1077 - Train Accuracy: 0.6579, Validation Accuracy: 0.7138, Loss: 0.4173
Epoch   0 Batch  700/1077 - Train Accuracy: 0.6652, Validation Accuracy: 0.7145, Loss: 0.3772
Epoch   0 Batch  701/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7138, Loss: 0.4289
Epoch   0 Batch  702/1077 - Train Accuracy: 0.6949, Validation Accuracy: 0.7099, Loss: 0.4136
Epoch   0 Batch  703/1077 - Train Accuracy: 0.7156, Validation Accuracy: 0.7028, Loss: 0.4253
Epoch   0 Batch  704/1077 - Train Accuracy: 0.6824, Validation Accuracy: 0.7031, Loss: 0.4317
Epoch   0 Batch  705/1077 - Train Accuracy: 0.7068, Validation Accuracy: 0.6967, Loss: 0.4489
Epoch   0 Batch  706/1077 - Train Accuracy: 0.6804, Validation Accuracy: 0.6914, Loss: 0.4286
Epoch   0 Batch  707/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.6921, Loss: 0.4099
Epoch   0 Batch  708/1077 - Train Accuracy: 0.6875, Validation Accuracy: 0.6868, Loss: 0.4284
Epoch   0 Batch  709/1077 - Train Accuracy: 0.7070, Validation Accuracy: 0.6836, Loss: 0.4035
Epoch   0 Batch  710/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6857, Loss: 0.3949
Epoch   0 Batch  711/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6971, Loss: 0.4343
Epoch   0 Batch  712/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.6928, Loss: 0.4002
Epoch   0 Batch  713/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.6960, Loss: 0.3836
Epoch   0 Batch  714/1077 - Train Accuracy: 0.6990, Validation Accuracy: 0.6864, Loss: 0.3890
Epoch   0 Batch  715/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.6900, Loss: 0.4033
Epoch   0 Batch  716/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.6967, Loss: 0.3902
Epoch   0 Batch  717/1077 - Train Accuracy: 0.6933, Validation Accuracy: 0.6907, Loss: 0.4194
Epoch   0 Batch  718/1077 - Train Accuracy: 0.6891, Validation Accuracy: 0.7013, Loss: 0.4062
Epoch   0 Batch  719/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.7070, Loss: 0.4191
Epoch   0 Batch  720/1077 - Train Accuracy: 0.7159, Validation Accuracy: 0.6992, Loss: 0.4253
Epoch   0 Batch  721/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.6953, Loss: 0.4067
Epoch   0 Batch  722/1077 - Train Accuracy: 0.6793, Validation Accuracy: 0.6925, Loss: 0.3817
Epoch   0 Batch  723/1077 - Train Accuracy: 0.7299, Validation Accuracy: 0.7013, Loss: 0.4105
Epoch   0 Batch  724/1077 - Train Accuracy: 0.6920, Validation Accuracy: 0.7042, Loss: 0.4110
Epoch   0 Batch  725/1077 - Train Accuracy: 0.7065, Validation Accuracy: 0.7116, Loss: 0.3658
Epoch   0 Batch  726/1077 - Train Accuracy: 0.7156, Validation Accuracy: 0.7120, Loss: 0.3997
Epoch   0 Batch  727/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7010, Loss: 0.3749
Epoch   0 Batch  728/1077 - Train Accuracy: 0.6737, Validation Accuracy: 0.6648, Loss: 0.3997
Epoch   0 Batch  729/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.6669, Loss: 0.4262
Epoch   0 Batch  730/1077 - Train Accuracy: 0.6930, Validation Accuracy: 0.6722, Loss: 0.4065
Epoch   0 Batch  731/1077 - Train Accuracy: 0.6804, Validation Accuracy: 0.6662, Loss: 0.3791
Epoch   0 Batch  732/1077 - Train Accuracy: 0.6912, Validation Accuracy: 0.6658, Loss: 0.4206
Epoch   0 Batch  733/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.6662, Loss: 0.4192
Epoch   0 Batch  734/1077 - Train Accuracy: 0.7142, Validation Accuracy: 0.6964, Loss: 0.4281
Epoch   0 Batch  735/1077 - Train Accuracy: 0.6988, Validation Accuracy: 0.6985, Loss: 0.3957
Epoch   0 Batch  736/1077 - Train Accuracy: 0.7167, Validation Accuracy: 0.6964, Loss: 0.3828
Epoch   0 Batch  737/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.6907, Loss: 0.4241
Epoch   0 Batch  738/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7053, Loss: 0.3400
Epoch   0 Batch  739/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.6925, Loss: 0.3726
Epoch   0 Batch  740/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.6804, Loss: 0.3852
Epoch   0 Batch  741/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.6829, Loss: 0.4020
Epoch   0 Batch  742/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6825, Loss: 0.3946
Epoch   0 Batch  743/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.6950, Loss: 0.4051
Epoch   0 Batch  744/1077 - Train Accuracy: 0.7139, Validation Accuracy: 0.6847, Loss: 0.3810
Epoch   0 Batch  745/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.6896, Loss: 0.4079
Epoch   0 Batch  746/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.6989, Loss: 0.3911
Epoch   0 Batch  747/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.6967, Loss: 0.3638
Epoch   0 Batch  748/1077 - Train Accuracy: 0.7234, Validation Accuracy: 0.6896, Loss: 0.3825
Epoch   0 Batch  749/1077 - Train Accuracy: 0.7063, Validation Accuracy: 0.6907, Loss: 0.3954
Epoch   0 Batch  750/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.6825, Loss: 0.3849
Epoch   0 Batch  751/1077 - Train Accuracy: 0.7324, Validation Accuracy: 0.6854, Loss: 0.3799
Epoch   0 Batch  752/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.6868, Loss: 0.3627
Epoch   0 Batch  753/1077 - Train Accuracy: 0.7012, Validation Accuracy: 0.6808, Loss: 0.3781
Epoch   0 Batch  754/1077 - Train Accuracy: 0.7090, Validation Accuracy: 0.6946, Loss: 0.3891
Epoch   0 Batch  755/1077 - Train Accuracy: 0.6977, Validation Accuracy: 0.6911, Loss: 0.3865
Epoch   0 Batch  756/1077 - Train Accuracy: 0.7133, Validation Accuracy: 0.6971, Loss: 0.3810
Epoch   0 Batch  757/1077 - Train Accuracy: 0.6928, Validation Accuracy: 0.6875, Loss: 0.3883
Epoch   0 Batch  758/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.6889, Loss: 0.3542
Epoch   0 Batch  759/1077 - Train Accuracy: 0.7307, Validation Accuracy: 0.6871, Loss: 0.3535
Epoch   0 Batch  760/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.6886, Loss: 0.3855
Epoch   0 Batch  761/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.6886, Loss: 0.3895
Epoch   0 Batch  762/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.6903, Loss: 0.3549
Epoch   0 Batch  763/1077 - Train Accuracy: 0.7169, Validation Accuracy: 0.6850, Loss: 0.3536
Epoch   0 Batch  764/1077 - Train Accuracy: 0.7401, Validation Accuracy: 0.6857, Loss: 0.3777
Epoch   0 Batch  765/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.6900, Loss: 0.3550
Epoch   0 Batch  766/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.7035, Loss: 0.3768
Epoch   0 Batch  767/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7131, Loss: 0.3893
Epoch   0 Batch  768/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.7156, Loss: 0.3810
Epoch   0 Batch  769/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7077, Loss: 0.3721
Epoch   0 Batch  770/1077 - Train Accuracy: 0.7310, Validation Accuracy: 0.6992, Loss: 0.3514
Epoch   0 Batch  771/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.6971, Loss: 0.3839
Epoch   0 Batch  772/1077 - Train Accuracy: 0.6897, Validation Accuracy: 0.6832, Loss: 0.3457
Epoch   0 Batch  773/1077 - Train Accuracy: 0.7324, Validation Accuracy: 0.6811, Loss: 0.3754
Epoch   0 Batch  774/1077 - Train Accuracy: 0.7258, Validation Accuracy: 0.6825, Loss: 0.3862
Epoch   0 Batch  775/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.6783, Loss: 0.3695
Epoch   0 Batch  776/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.6790, Loss: 0.3676
Epoch   0 Batch  777/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.6793, Loss: 0.3931
Epoch   0 Batch  778/1077 - Train Accuracy: 0.7448, Validation Accuracy: 0.6726, Loss: 0.3601
Epoch   0 Batch  779/1077 - Train Accuracy: 0.7059, Validation Accuracy: 0.6779, Loss: 0.3708
Epoch   0 Batch  780/1077 - Train Accuracy: 0.6934, Validation Accuracy: 0.6790, Loss: 0.3852
Epoch   0 Batch  781/1077 - Train Accuracy: 0.7853, Validation Accuracy: 0.6928, Loss: 0.3487
Epoch   0 Batch  782/1077 - Train Accuracy: 0.7448, Validation Accuracy: 0.6960, Loss: 0.3609
Epoch   0 Batch  783/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6914, Loss: 0.3574
Epoch   0 Batch  784/1077 - Train Accuracy: 0.7398, Validation Accuracy: 0.6871, Loss: 0.3508
Epoch   0 Batch  785/1077 - Train Accuracy: 0.7493, Validation Accuracy: 0.6911, Loss: 0.3514
Epoch   0 Batch  786/1077 - Train Accuracy: 0.6973, Validation Accuracy: 0.6971, Loss: 0.3695
Epoch   0 Batch  787/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.6893, Loss: 0.3491
Epoch   0 Batch  788/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7085, Loss: 0.3661
Epoch   0 Batch  789/1077 - Train Accuracy: 0.6780, Validation Accuracy: 0.7141, Loss: 0.3808
Epoch   0 Batch  790/1077 - Train Accuracy: 0.6574, Validation Accuracy: 0.6985, Loss: 0.3892
Epoch   0 Batch  791/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.6896, Loss: 0.3710
Epoch   0 Batch  792/1077 - Train Accuracy: 0.6781, Validation Accuracy: 0.6911, Loss: 0.3833
Epoch   0 Batch  793/1077 - Train Accuracy: 0.7406, Validation Accuracy: 0.6918, Loss: 0.3625
Epoch   0 Batch  794/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.7028, Loss: 0.3698
Epoch   0 Batch  795/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.7113, Loss: 0.3782
Epoch   0 Batch  796/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7127, Loss: 0.3588
Epoch   0 Batch  797/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7085, Loss: 0.3673
Epoch   0 Batch  798/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7074, Loss: 0.3792
Epoch   0 Batch  799/1077 - Train Accuracy: 0.6844, Validation Accuracy: 0.6889, Loss: 0.4156
Epoch   0 Batch  800/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6871, Loss: 0.3782
Epoch   0 Batch  801/1077 - Train Accuracy: 0.7086, Validation Accuracy: 0.6733, Loss: 0.3731
Epoch   0 Batch  802/1077 - Train Accuracy: 0.7329, Validation Accuracy: 0.6719, Loss: 0.3513
Epoch   0 Batch  803/1077 - Train Accuracy: 0.7332, Validation Accuracy: 0.6811, Loss: 0.3955
Epoch   0 Batch  804/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.6822, Loss: 0.3541
Epoch   0 Batch  805/1077 - Train Accuracy: 0.7164, Validation Accuracy: 0.6868, Loss: 0.3627
Epoch   0 Batch  806/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7198, Loss: 0.3604
Epoch   0 Batch  807/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.7205, Loss: 0.3418
Epoch   0 Batch  808/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.7109, Loss: 0.3625
Epoch   0 Batch  809/1077 - Train Accuracy: 0.6863, Validation Accuracy: 0.7088, Loss: 0.3979
Epoch   0 Batch  810/1077 - Train Accuracy: 0.7161, Validation Accuracy: 0.7067, Loss: 0.3333
Epoch   0 Batch  811/1077 - Train Accuracy: 0.7321, Validation Accuracy: 0.6985, Loss: 0.3417
Epoch   0 Batch  812/1077 - Train Accuracy: 0.6816, Validation Accuracy: 0.6832, Loss: 0.3752
Epoch   0 Batch  813/1077 - Train Accuracy: 0.7307, Validation Accuracy: 0.6857, Loss: 0.3529
Epoch   0 Batch  814/1077 - Train Accuracy: 0.7254, Validation Accuracy: 0.6843, Loss: 0.3625
Epoch   0 Batch  815/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.6815, Loss: 0.3653
Epoch   0 Batch  816/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.6932, Loss: 0.3800
Epoch   0 Batch  817/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.6893, Loss: 0.3772
Epoch   0 Batch  818/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.6935, Loss: 0.3668
Epoch   0 Batch  819/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.6879, Loss: 0.3498
Epoch   0 Batch  820/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.7017, Loss: 0.3673
Epoch   0 Batch  821/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7156, Loss: 0.3622
Epoch   0 Batch  822/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7134, Loss: 0.3653
Epoch   0 Batch  823/1077 - Train Accuracy: 0.7305, Validation Accuracy: 0.7173, Loss: 0.3455
Epoch   0 Batch  824/1077 - Train Accuracy: 0.6916, Validation Accuracy: 0.7180, Loss: 0.3421
Epoch   0 Batch  825/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7195, Loss: 0.3504
Epoch   0 Batch  826/1077 - Train Accuracy: 0.6987, Validation Accuracy: 0.7013, Loss: 0.3327
Epoch   0 Batch  827/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.6971, Loss: 0.3460
Epoch   0 Batch  828/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.6896, Loss: 0.3551
Epoch   0 Batch  829/1077 - Train Accuracy: 0.7359, Validation Accuracy: 0.6896, Loss: 0.3837
Epoch   0 Batch  830/1077 - Train Accuracy: 0.6953, Validation Accuracy: 0.6903, Loss: 0.3499
Epoch   0 Batch  831/1077 - Train Accuracy: 0.7055, Validation Accuracy: 0.6914, Loss: 0.3561
Epoch   0 Batch  832/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.6850, Loss: 0.3537
Epoch   0 Batch  833/1077 - Train Accuracy: 0.7043, Validation Accuracy: 0.6882, Loss: 0.3651
Epoch   0 Batch  834/1077 - Train Accuracy: 0.7532, Validation Accuracy: 0.6864, Loss: 0.3361
Epoch   0 Batch  835/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.6836, Loss: 0.3327
Epoch   0 Batch  836/1077 - Train Accuracy: 0.7138, Validation Accuracy: 0.6868, Loss: 0.3739
Epoch   0 Batch  837/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.6953, Loss: 0.3695
Epoch   0 Batch  838/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7010, Loss: 0.3405
Epoch   0 Batch  839/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7028, Loss: 0.3371
Epoch   0 Batch  840/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7024, Loss: 0.3328
Epoch   0 Batch  841/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7081, Loss: 0.3579
Epoch   0 Batch  842/1077 - Train Accuracy: 0.7379, Validation Accuracy: 0.7035, Loss: 0.3388
Epoch   0 Batch  843/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.7038, Loss: 0.3240
Epoch   0 Batch  844/1077 - Train Accuracy: 0.7295, Validation Accuracy: 0.6896, Loss: 0.3285
Epoch   0 Batch  845/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7134, Loss: 0.3384
Epoch   0 Batch  846/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7195, Loss: 0.3590
Epoch   0 Batch  847/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7209, Loss: 0.3621
Epoch   0 Batch  848/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7219, Loss: 0.3547
Epoch   0 Batch  849/1077 - Train Accuracy: 0.7336, Validation Accuracy: 0.7060, Loss: 0.3258
Epoch   0 Batch  850/1077 - Train Accuracy: 0.7236, Validation Accuracy: 0.7095, Loss: 0.3654
Epoch   0 Batch  851/1077 - Train Accuracy: 0.7519, Validation Accuracy: 0.7113, Loss: 0.3316
Epoch   0 Batch  852/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7099, Loss: 0.3426
Epoch   0 Batch  853/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.6911, Loss: 0.3347
Epoch   0 Batch  854/1077 - Train Accuracy: 0.7203, Validation Accuracy: 0.6868, Loss: 0.3439
Epoch   0 Batch  855/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6982, Loss: 0.3472
Epoch   0 Batch  856/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7013, Loss: 0.3570
Epoch   0 Batch  857/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.6992, Loss: 0.3336
Epoch   0 Batch  858/1077 - Train Accuracy: 0.7176, Validation Accuracy: 0.6978, Loss: 0.3334
Epoch   0 Batch  859/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.6982, Loss: 0.3775
Epoch   0 Batch  860/1077 - Train Accuracy: 0.7299, Validation Accuracy: 0.6960, Loss: 0.3462
Epoch   0 Batch  861/1077 - Train Accuracy: 0.7297, Validation Accuracy: 0.7085, Loss: 0.3250
Epoch   0 Batch  862/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7148, Loss: 0.3382
Epoch   0 Batch  863/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7152, Loss: 0.3332
Epoch   0 Batch  864/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7170, Loss: 0.3386
Epoch   0 Batch  865/1077 - Train Accuracy: 0.7631, Validation Accuracy: 0.7188, Loss: 0.3113
Epoch   0 Batch  866/1077 - Train Accuracy: 0.7292, Validation Accuracy: 0.7085, Loss: 0.3430
Epoch   0 Batch  867/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.7042, Loss: 0.3864
Epoch   0 Batch  868/1077 - Train Accuracy: 0.7461, Validation Accuracy: 0.6896, Loss: 0.3485
Epoch   0 Batch  869/1077 - Train Accuracy: 0.7141, Validation Accuracy: 0.6889, Loss: 0.3383
Epoch   0 Batch  870/1077 - Train Accuracy: 0.6711, Validation Accuracy: 0.6893, Loss: 0.3483
Epoch   0 Batch  871/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.7028, Loss: 0.3411
Epoch   0 Batch  872/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7088, Loss: 0.3339
Epoch   0 Batch  873/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.7070, Loss: 0.3508
Epoch   0 Batch  874/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7017, Loss: 0.3440
Epoch   0 Batch  875/1077 - Train Accuracy: 0.7195, Validation Accuracy: 0.7017, Loss: 0.3436
Epoch   0 Batch  876/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7095, Loss: 0.3312
Epoch   0 Batch  877/1077 - Train Accuracy: 0.7348, Validation Accuracy: 0.7156, Loss: 0.3210
Epoch   0 Batch  878/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7330, Loss: 0.3274
Epoch   0 Batch  879/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7365, Loss: 0.3179
Epoch   0 Batch  880/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7358, Loss: 0.3301
Epoch   0 Batch  881/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.7344, Loss: 0.3491
Epoch   0 Batch  882/1077 - Train Accuracy: 0.7297, Validation Accuracy: 0.7351, Loss: 0.3635
Epoch   0 Batch  883/1077 - Train Accuracy: 0.6879, Validation Accuracy: 0.7383, Loss: 0.3756
Epoch   0 Batch  884/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7177, Loss: 0.3207
Epoch   0 Batch  885/1077 - Train Accuracy: 0.7525, Validation Accuracy: 0.7088, Loss: 0.2917
Epoch   0 Batch  886/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.7035, Loss: 0.3378
Epoch   0 Batch  887/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.6974, Loss: 0.3576
Epoch   0 Batch  888/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7035, Loss: 0.2941
Epoch   0 Batch  889/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.7031, Loss: 0.3362
Epoch   0 Batch  890/1077 - Train Accuracy: 0.7612, Validation Accuracy: 0.7109, Loss: 0.3219
Epoch   0 Batch  891/1077 - Train Accuracy: 0.8002, Validation Accuracy: 0.7219, Loss: 0.3385
Epoch   0 Batch  892/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7301, Loss: 0.3089
Epoch   0 Batch  893/1077 - Train Accuracy: 0.7398, Validation Accuracy: 0.7376, Loss: 0.3288
Epoch   0 Batch  894/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7376, Loss: 0.3167
Epoch   0 Batch  895/1077 - Train Accuracy: 0.7527, Validation Accuracy: 0.7404, Loss: 0.3302
Epoch   0 Batch  896/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7422, Loss: 0.3607
Epoch   0 Batch  897/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7337, Loss: 0.3006
Epoch   0 Batch  898/1077 - Train Accuracy: 0.7388, Validation Accuracy: 0.7308, Loss: 0.2999
Epoch   0 Batch  899/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7287, Loss: 0.3432
Epoch   0 Batch  900/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7188, Loss: 0.3439
Epoch   0 Batch  901/1077 - Train Accuracy: 0.7764, Validation Accuracy: 0.7116, Loss: 0.3436
Epoch   0 Batch  902/1077 - Train Accuracy: 0.7385, Validation Accuracy: 0.7173, Loss: 0.3207
Epoch   0 Batch  903/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7049, Loss: 0.3248
Epoch   0 Batch  904/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.7120, Loss: 0.3272
Epoch   0 Batch  905/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7102, Loss: 0.3014
Epoch   0 Batch  906/1077 - Train Accuracy: 0.7422, Validation Accuracy: 0.7106, Loss: 0.3230
Epoch   0 Batch  907/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7205, Loss: 0.3199
Epoch   0 Batch  908/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7227, Loss: 0.3502
Epoch   0 Batch  909/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7283, Loss: 0.3372
Epoch   0 Batch  910/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7326, Loss: 0.3176
Epoch   0 Batch  911/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7251, Loss: 0.3051
Epoch   0 Batch  912/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7365, Loss: 0.3368
Epoch   0 Batch  913/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7315, Loss: 0.3600
Epoch   0 Batch  914/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7280, Loss: 0.3034
Epoch   0 Batch  915/1077 - Train Accuracy: 0.7451, Validation Accuracy: 0.7326, Loss: 0.3356
Epoch   0 Batch  916/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7362, Loss: 0.3634
Epoch   0 Batch  917/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7308, Loss: 0.3076
Epoch   0 Batch  918/1077 - Train Accuracy: 0.7310, Validation Accuracy: 0.7287, Loss: 0.3031
Epoch   0 Batch  919/1077 - Train Accuracy: 0.7878, Validation Accuracy: 0.7262, Loss: 0.3162
Epoch   0 Batch  920/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7319, Loss: 0.3126
Epoch   0 Batch  921/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7248, Loss: 0.3141
Epoch   0 Batch  922/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.7095, Loss: 0.3161
Epoch   0 Batch  923/1077 - Train Accuracy: 0.7253, Validation Accuracy: 0.7088, Loss: 0.3227
Epoch   0 Batch  924/1077 - Train Accuracy: 0.7558, Validation Accuracy: 0.6996, Loss: 0.3460
Epoch   0 Batch  925/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.6900, Loss: 0.2944
Epoch   0 Batch  926/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.6918, Loss: 0.3390
Epoch   0 Batch  927/1077 - Train Accuracy: 0.7023, Validation Accuracy: 0.6882, Loss: 0.3318
Epoch   0 Batch  928/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.6847, Loss: 0.3152
Epoch   0 Batch  929/1077 - Train Accuracy: 0.7371, Validation Accuracy: 0.6758, Loss: 0.3324
Epoch   0 Batch  930/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.6751, Loss: 0.3104
Epoch   0 Batch  931/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.6978, Loss: 0.2859
Epoch   0 Batch  932/1077 - Train Accuracy: 0.7172, Validation Accuracy: 0.7127, Loss: 0.3263
Epoch   0 Batch  933/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7283, Loss: 0.3116
Epoch   0 Batch  934/1077 - Train Accuracy: 0.7375, Validation Accuracy: 0.7344, Loss: 0.3139
Epoch   0 Batch  935/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7319, Loss: 0.3149
Epoch   0 Batch  936/1077 - Train Accuracy: 0.7377, Validation Accuracy: 0.7305, Loss: 0.3333
Epoch   0 Batch  937/1077 - Train Accuracy: 0.7632, Validation Accuracy: 0.7255, Loss: 0.3337
Epoch   0 Batch  938/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7212, Loss: 0.3255
Epoch   0 Batch  939/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7202, Loss: 0.3161
Epoch   0 Batch  940/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7152, Loss: 0.3067
Epoch   0 Batch  941/1077 - Train Accuracy: 0.7459, Validation Accuracy: 0.7177, Loss: 0.3012
Epoch   0 Batch  942/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7219, Loss: 0.2940
Epoch   0 Batch  943/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7021, Loss: 0.3155
Epoch   0 Batch  944/1077 - Train Accuracy: 0.7121, Validation Accuracy: 0.6950, Loss: 0.3154
Epoch   0 Batch  945/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.6989, Loss: 0.2835
Epoch   0 Batch  946/1077 - Train Accuracy: 0.7558, Validation Accuracy: 0.6985, Loss: 0.2997
Epoch   0 Batch  947/1077 - Train Accuracy: 0.6850, Validation Accuracy: 0.6935, Loss: 0.3305
Epoch   0 Batch  948/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7085, Loss: 0.3130
Epoch   0 Batch  949/1077 - Train Accuracy: 0.7790, Validation Accuracy: 0.7067, Loss: 0.2802
Epoch   0 Batch  950/1077 - Train Accuracy: 0.7548, Validation Accuracy: 0.7095, Loss: 0.2863
Epoch   0 Batch  951/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7088, Loss: 0.3162
Epoch   0 Batch  952/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7163, Loss: 0.3122
Epoch   0 Batch  953/1077 - Train Accuracy: 0.7743, Validation Accuracy: 0.7106, Loss: 0.2912
Epoch   0 Batch  954/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.6985, Loss: 0.3167
Epoch   0 Batch  955/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7223, Loss: 0.3187
Epoch   0 Batch  956/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7255, Loss: 0.3320
Epoch   0 Batch  957/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7276, Loss: 0.2841
Epoch   0 Batch  958/1077 - Train Accuracy: 0.7426, Validation Accuracy: 0.7308, Loss: 0.3075
Epoch   0 Batch  959/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7205, Loss: 0.3001
Epoch   0 Batch  960/1077 - Train Accuracy: 0.7690, Validation Accuracy: 0.7085, Loss: 0.2898
Epoch   0 Batch  961/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.6971, Loss: 0.3237
Epoch   0 Batch  962/1077 - Train Accuracy: 0.7560, Validation Accuracy: 0.6982, Loss: 0.2969
Epoch   0 Batch  963/1077 - Train Accuracy: 0.7752, Validation Accuracy: 0.7006, Loss: 0.3606
Epoch   0 Batch  964/1077 - Train Accuracy: 0.7478, Validation Accuracy: 0.7003, Loss: 0.2844
Epoch   0 Batch  965/1077 - Train Accuracy: 0.7212, Validation Accuracy: 0.6928, Loss: 0.3204
Epoch   0 Batch  966/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.6999, Loss: 0.2714
Epoch   0 Batch  967/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.6992, Loss: 0.3106
Epoch   0 Batch  968/1077 - Train Accuracy: 0.7211, Validation Accuracy: 0.6978, Loss: 0.3175
Epoch   0 Batch  969/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7074, Loss: 0.3331
Epoch   0 Batch  970/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.7127, Loss: 0.3169
Epoch   0 Batch  971/1077 - Train Accuracy: 0.7894, Validation Accuracy: 0.7145, Loss: 0.3106
Epoch   0 Batch  972/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7131, Loss: 0.2992
Epoch   0 Batch  973/1077 - Train Accuracy: 0.8017, Validation Accuracy: 0.7156, Loss: 0.2709
Epoch   0 Batch  974/1077 - Train Accuracy: 0.7230, Validation Accuracy: 0.7159, Loss: 0.2917
Epoch   0 Batch  975/1077 - Train Accuracy: 0.7530, Validation Accuracy: 0.7212, Loss: 0.2750
Epoch   0 Batch  976/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7188, Loss: 0.2850
Epoch   0 Batch  977/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7227, Loss: 0.2911
Epoch   0 Batch  978/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7262, Loss: 0.3224
Epoch   0 Batch  979/1077 - Train Accuracy: 0.7627, Validation Accuracy: 0.7425, Loss: 0.3309
Epoch   0 Batch  980/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7514, Loss: 0.2991
Epoch   0 Batch  981/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7635, Loss: 0.2991
Epoch   0 Batch  982/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7610, Loss: 0.2990
Epoch   0 Batch  983/1077 - Train Accuracy: 0.7364, Validation Accuracy: 0.7599, Loss: 0.3268
Epoch   0 Batch  984/1077 - Train Accuracy: 0.7391, Validation Accuracy: 0.7599, Loss: 0.3204
Epoch   0 Batch  985/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7404, Loss: 0.2882
Epoch   0 Batch  986/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7216, Loss: 0.3100
Epoch   0 Batch  987/1077 - Train Accuracy: 0.7295, Validation Accuracy: 0.7259, Loss: 0.2849
Epoch   0 Batch  988/1077 - Train Accuracy: 0.7402, Validation Accuracy: 0.7305, Loss: 0.3022
Epoch   0 Batch  989/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7333, Loss: 0.3229
Epoch   0 Batch  990/1077 - Train Accuracy: 0.7085, Validation Accuracy: 0.7401, Loss: 0.3234
Epoch   0 Batch  991/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7496, Loss: 0.3123
Epoch   0 Batch  992/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7507, Loss: 0.2999
Epoch   0 Batch  993/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7539, Loss: 0.2805
Epoch   0 Batch  994/1077 - Train Accuracy: 0.7551, Validation Accuracy: 0.7582, Loss: 0.2978
Epoch   0 Batch  995/1077 - Train Accuracy: 0.8077, Validation Accuracy: 0.7681, Loss: 0.2930
Epoch   0 Batch  996/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7525, Loss: 0.2927
Epoch   0 Batch  997/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7610, Loss: 0.3061
Epoch   0 Batch  998/1077 - Train Accuracy: 0.7266, Validation Accuracy: 0.7550, Loss: 0.2842
Epoch   0 Batch  999/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7514, Loss: 0.3020
Epoch   0 Batch 1000/1077 - Train Accuracy: 0.7708, Validation Accuracy: 0.7450, Loss: 0.2819
Epoch   0 Batch 1001/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7376, Loss: 0.2809
Epoch   0 Batch 1002/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.7397, Loss: 0.2771
Epoch   0 Batch 1003/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7354, Loss: 0.3077
Epoch   0 Batch 1004/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7305, Loss: 0.3021
Epoch   0 Batch 1005/1077 - Train Accuracy: 0.7766, Validation Accuracy: 0.7188, Loss: 0.2818
Epoch   0 Batch 1006/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7259, Loss: 0.2750
Epoch   0 Batch 1007/1077 - Train Accuracy: 0.7798, Validation Accuracy: 0.7283, Loss: 0.2607
Epoch   0 Batch 1008/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.7234, Loss: 0.3062
Epoch   0 Batch 1009/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7347, Loss: 0.2784
Epoch   0 Batch 1010/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7333, Loss: 0.2881
Epoch   0 Batch 1011/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7472, Loss: 0.2836
Epoch   0 Batch 1012/1077 - Train Accuracy: 0.7638, Validation Accuracy: 0.7525, Loss: 0.2469
Epoch   0 Batch 1013/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7525, Loss: 0.2690
Epoch   0 Batch 1014/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7507, Loss: 0.2933
Epoch   0 Batch 1015/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7472, Loss: 0.3099
Epoch   0 Batch 1016/1077 - Train Accuracy: 0.7106, Validation Accuracy: 0.7468, Loss: 0.2991
Epoch   0 Batch 1017/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7464, Loss: 0.3029
Epoch   0 Batch 1018/1077 - Train Accuracy: 0.7251, Validation Accuracy: 0.7461, Loss: 0.2756
Epoch   0 Batch 1019/1077 - Train Accuracy: 0.7529, Validation Accuracy: 0.7212, Loss: 0.3190
Epoch   0 Batch 1020/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7262, Loss: 0.2748
Epoch   0 Batch 1021/1077 - Train Accuracy: 0.7526, Validation Accuracy: 0.7173, Loss: 0.2820
Epoch   0 Batch 1022/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7102, Loss: 0.2744
Epoch   0 Batch 1023/1077 - Train Accuracy: 0.7528, Validation Accuracy: 0.7205, Loss: 0.2710
Epoch   0 Batch 1024/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7134, Loss: 0.3048
Epoch   0 Batch 1025/1077 - Train Accuracy: 0.7374, Validation Accuracy: 0.7241, Loss: 0.2801
Epoch   0 Batch 1026/1077 - Train Accuracy: 0.8095, Validation Accuracy: 0.7259, Loss: 0.2916
Epoch   0 Batch 1027/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7216, Loss: 0.2800
Epoch   0 Batch 1028/1077 - Train Accuracy: 0.7202, Validation Accuracy: 0.7184, Loss: 0.2765
Epoch   0 Batch 1029/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7180, Loss: 0.2610
Epoch   0 Batch 1030/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7188, Loss: 0.2913
Epoch   0 Batch 1031/1077 - Train Accuracy: 0.7459, Validation Accuracy: 0.7276, Loss: 0.3106
Epoch   0 Batch 1032/1077 - Train Accuracy: 0.7288, Validation Accuracy: 0.7440, Loss: 0.3072
Epoch   0 Batch 1033/1077 - Train Accuracy: 0.7671, Validation Accuracy: 0.7379, Loss: 0.2801
Epoch   0 Batch 1034/1077 - Train Accuracy: 0.7480, Validation Accuracy: 0.7390, Loss: 0.2904
Epoch   0 Batch 1035/1077 - Train Accuracy: 0.8073, Validation Accuracy: 0.7401, Loss: 0.2492
Epoch   0 Batch 1036/1077 - Train Accuracy: 0.7433, Validation Accuracy: 0.7351, Loss: 0.2935
Epoch   0 Batch 1037/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7401, Loss: 0.2924
Epoch   0 Batch 1038/1077 - Train Accuracy: 0.7949, Validation Accuracy: 0.7347, Loss: 0.3010
Epoch   0 Batch 1039/1077 - Train Accuracy: 0.7682, Validation Accuracy: 0.7347, Loss: 0.2733
Epoch   0 Batch 1040/1077 - Train Accuracy: 0.7459, Validation Accuracy: 0.7273, Loss: 0.3020
Epoch   0 Batch 1041/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7262, Loss: 0.2891
Epoch   0 Batch 1042/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7404, Loss: 0.2911
Epoch   0 Batch 1043/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7638, Loss: 0.3048
Epoch   0 Batch 1044/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7575, Loss: 0.3126
Epoch   0 Batch 1045/1077 - Train Accuracy: 0.7328, Validation Accuracy: 0.7472, Loss: 0.2779
Epoch   0 Batch 1046/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7500, Loss: 0.2676
Epoch   0 Batch 1047/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7560, Loss: 0.2695
Epoch   0 Batch 1048/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7496, Loss: 0.2830
Epoch   0 Batch 1049/1077 - Train Accuracy: 0.7672, Validation Accuracy: 0.7383, Loss: 0.2760
Epoch   0 Batch 1050/1077 - Train Accuracy: 0.7445, Validation Accuracy: 0.7234, Loss: 0.2641
Epoch   0 Batch 1051/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.7163, Loss: 0.2660
Epoch   0 Batch 1052/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7163, Loss: 0.2638
Epoch   0 Batch 1053/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7152, Loss: 0.2822
Epoch   0 Batch 1054/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.7056, Loss: 0.2844
Epoch   0 Batch 1055/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7053, Loss: 0.2823
Epoch   0 Batch 1056/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7049, Loss: 0.2703
Epoch   0 Batch 1057/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7156, Loss: 0.2935
Epoch   0 Batch 1058/1077 - Train Accuracy: 0.7607, Validation Accuracy: 0.7077, Loss: 0.3117
Epoch   0 Batch 1059/1077 - Train Accuracy: 0.7294, Validation Accuracy: 0.7156, Loss: 0.3132
Epoch   0 Batch 1060/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7180, Loss: 0.2653
Epoch   0 Batch 1061/1077 - Train Accuracy: 0.7531, Validation Accuracy: 0.7266, Loss: 0.2958
Epoch   0 Batch 1062/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7376, Loss: 0.2803
Epoch   0 Batch 1063/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7514, Loss: 0.2778
Epoch   0 Batch 1064/1077 - Train Accuracy: 0.7949, Validation Accuracy: 0.7855, Loss: 0.2744
Epoch   0 Batch 1065/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7944, Loss: 0.2629
Epoch   0 Batch 1066/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7678, Loss: 0.2670
Epoch   0 Batch 1067/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7504, Loss: 0.2937
Epoch   0 Batch 1068/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7372, Loss: 0.2497
Epoch   0 Batch 1069/1077 - Train Accuracy: 0.7924, Validation Accuracy: 0.7447, Loss: 0.2423
Epoch   0 Batch 1070/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7429, Loss: 0.2669
Epoch   0 Batch 1071/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7358, Loss: 0.2683
Epoch   0 Batch 1072/1077 - Train Accuracy: 0.7407, Validation Accuracy: 0.7383, Loss: 0.2667
Epoch   0 Batch 1073/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7319, Loss: 0.2897
Epoch   0 Batch 1074/1077 - Train Accuracy: 0.7935, Validation Accuracy: 0.7365, Loss: 0.2817
Epoch   0 Batch 1075/1077 - Train Accuracy: 0.7562, Validation Accuracy: 0.7330, Loss: 0.3027
Epoch   1 Batch    1/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7337, Loss: 0.2466
Epoch   1 Batch    2/1077 - Train Accuracy: 0.7381, Validation Accuracy: 0.7276, Loss: 0.2925
Epoch   1 Batch    3/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7266, Loss: 0.2869
Epoch   1 Batch    4/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7237, Loss: 0.2681
Epoch   1 Batch    5/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7244, Loss: 0.2921
Epoch   1 Batch    6/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.7223, Loss: 0.2814
Epoch   1 Batch    7/1077 - Train Accuracy: 0.7523, Validation Accuracy: 0.7191, Loss: 0.2630
Epoch   1 Batch    8/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7280, Loss: 0.2859
Epoch   1 Batch    9/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7283, Loss: 0.2657
Epoch   1 Batch   10/1077 - Train Accuracy: 0.7915, Validation Accuracy: 0.7319, Loss: 0.2672
Epoch   1 Batch   11/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7290, Loss: 0.2665
Epoch   1 Batch   12/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7280, Loss: 0.2920
Epoch   1 Batch   13/1077 - Train Accuracy: 0.7597, Validation Accuracy: 0.7266, Loss: 0.2731
Epoch   1 Batch   14/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7468, Loss: 0.2321
Epoch   1 Batch   15/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7649, Loss: 0.2833
Epoch   1 Batch   16/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7646, Loss: 0.2806
Epoch   1 Batch   17/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7624, Loss: 0.2597
Epoch   1 Batch   18/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7646, Loss: 0.2715
Epoch   1 Batch   19/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7585, Loss: 0.2695
Epoch   1 Batch   20/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7514, Loss: 0.2592
Epoch   1 Batch   21/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7376, Loss: 0.2802
Epoch   1 Batch   22/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7305, Loss: 0.2700
Epoch   1 Batch   23/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7202, Loss: 0.2735
Epoch   1 Batch   24/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7152, Loss: 0.2655
Epoch   1 Batch   25/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7099, Loss: 0.2511
Epoch   1 Batch   26/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.7120, Loss: 0.2798
Epoch   1 Batch   27/1077 - Train Accuracy: 0.8092, Validation Accuracy: 0.7113, Loss: 0.2594
Epoch   1 Batch   28/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7095, Loss: 0.2709
Epoch   1 Batch   29/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7223, Loss: 0.2618
Epoch   1 Batch   30/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7290, Loss: 0.2426
Epoch   1 Batch   31/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7209, Loss: 0.2640
Epoch   1 Batch   32/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.7209, Loss: 0.2580
Epoch   1 Batch   33/1077 - Train Accuracy: 0.7608, Validation Accuracy: 0.7433, Loss: 0.2488
Epoch   1 Batch   34/1077 - Train Accuracy: 0.8293, Validation Accuracy: 0.7528, Loss: 0.2611
Epoch   1 Batch   35/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7642, Loss: 0.2671
Epoch   1 Batch   36/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7628, Loss: 0.2691
Epoch   1 Batch   37/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7528, Loss: 0.2675
Epoch   1 Batch   38/1077 - Train Accuracy: 0.7558, Validation Accuracy: 0.7756, Loss: 0.2911
Epoch   1 Batch   39/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7841, Loss: 0.2986
Epoch   1 Batch   40/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.7933, Loss: 0.2512
Epoch   1 Batch   41/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7919, Loss: 0.2475
Epoch   1 Batch   42/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7546, Loss: 0.2819
Epoch   1 Batch   43/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7493, Loss: 0.2405
Epoch   1 Batch   44/1077 - Train Accuracy: 0.7743, Validation Accuracy: 0.7528, Loss: 0.2674
Epoch   1 Batch   45/1077 - Train Accuracy: 0.7695, Validation Accuracy: 0.7436, Loss: 0.2642
Epoch   1 Batch   46/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7440, Loss: 0.2966
Epoch   1 Batch   47/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7425, Loss: 0.2796
Epoch   1 Batch   48/1077 - Train Accuracy: 0.7332, Validation Accuracy: 0.7404, Loss: 0.2977
Epoch   1 Batch   49/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.7475, Loss: 0.2654
Epoch   1 Batch   50/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7475, Loss: 0.2547
Epoch   1 Batch   51/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7713, Loss: 0.2551
Epoch   1 Batch   52/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7738, Loss: 0.2757
Epoch   1 Batch   53/1077 - Train Accuracy: 0.7833, Validation Accuracy: 0.7741, Loss: 0.2669
Epoch   1 Batch   54/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7731, Loss: 0.3042
Epoch   1 Batch   55/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7678, Loss: 0.2543
Epoch   1 Batch   56/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7802, Loss: 0.2411
Epoch   1 Batch   57/1077 - Train Accuracy: 0.7866, Validation Accuracy: 0.7745, Loss: 0.2365
Epoch   1 Batch   58/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7830, Loss: 0.2511
Epoch   1 Batch   59/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7894, Loss: 0.2585
Epoch   1 Batch   60/1077 - Train Accuracy: 0.8013, Validation Accuracy: 0.7717, Loss: 0.2639
Epoch   1 Batch   61/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7532, Loss: 0.2888
Epoch   1 Batch   62/1077 - Train Accuracy: 0.7278, Validation Accuracy: 0.7379, Loss: 0.2849
Epoch   1 Batch   63/1077 - Train Accuracy: 0.8318, Validation Accuracy: 0.7369, Loss: 0.2398
Epoch   1 Batch   64/1077 - Train Accuracy: 0.7367, Validation Accuracy: 0.7468, Loss: 0.2655
Epoch   1 Batch   65/1077 - Train Accuracy: 0.7237, Validation Accuracy: 0.7624, Loss: 0.2587
Epoch   1 Batch   66/1077 - Train Accuracy: 0.7333, Validation Accuracy: 0.7695, Loss: 0.2427
Epoch   1 Batch   67/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7585, Loss: 0.2501
Epoch   1 Batch   68/1077 - Train Accuracy: 0.7844, Validation Accuracy: 0.7720, Loss: 0.2746
Epoch   1 Batch   69/1077 - Train Accuracy: 0.7586, Validation Accuracy: 0.7724, Loss: 0.2874
Epoch   1 Batch   70/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7706, Loss: 0.2603
Epoch   1 Batch   71/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7660, Loss: 0.2467
Epoch   1 Batch   72/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7397, Loss: 0.2661
Epoch   1 Batch   73/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7351, Loss: 0.2577
Epoch   1 Batch   74/1077 - Train Accuracy: 0.7783, Validation Accuracy: 0.7486, Loss: 0.2389
Epoch   1 Batch   75/1077 - Train Accuracy: 0.7605, Validation Accuracy: 0.7298, Loss: 0.2821
Epoch   1 Batch   76/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7290, Loss: 0.2528
Epoch   1 Batch   77/1077 - Train Accuracy: 0.7340, Validation Accuracy: 0.7273, Loss: 0.2598
Epoch   1 Batch   78/1077 - Train Accuracy: 0.7364, Validation Accuracy: 0.7287, Loss: 0.2713
Epoch   1 Batch   79/1077 - Train Accuracy: 0.7520, Validation Accuracy: 0.7685, Loss: 0.2695
Epoch   1 Batch   80/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7763, Loss: 0.2461
Epoch   1 Batch   81/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7773, Loss: 0.2489
Epoch   1 Batch   82/1077 - Train Accuracy: 0.8139, Validation Accuracy: 0.7752, Loss: 0.2295
Epoch   1 Batch   83/1077 - Train Accuracy: 0.7977, Validation Accuracy: 0.7820, Loss: 0.2621
Epoch   1 Batch   84/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.7844, Loss: 0.2390
Epoch   1 Batch   85/1077 - Train Accuracy: 0.7832, Validation Accuracy: 0.7841, Loss: 0.2560
Epoch   1 Batch   86/1077 - Train Accuracy: 0.8160, Validation Accuracy: 0.7646, Loss: 0.2594
Epoch   1 Batch   87/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7504, Loss: 0.2907
Epoch   1 Batch   88/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7422, Loss: 0.2621
Epoch   1 Batch   89/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7404, Loss: 0.2553
Epoch   1 Batch   90/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7457, Loss: 0.2672
Epoch   1 Batch   91/1077 - Train Accuracy: 0.7920, Validation Accuracy: 0.7489, Loss: 0.2406
Epoch   1 Batch   92/1077 - Train Accuracy: 0.7731, Validation Accuracy: 0.7713, Loss: 0.2631
Epoch   1 Batch   93/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7816, Loss: 0.2621
Epoch   1 Batch   94/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.7898, Loss: 0.2259
Epoch   1 Batch   95/1077 - Train Accuracy: 0.7932, Validation Accuracy: 0.7997, Loss: 0.2568
Epoch   1 Batch   96/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7944, Loss: 0.2500
Epoch   1 Batch   97/1077 - Train Accuracy: 0.7937, Validation Accuracy: 0.7841, Loss: 0.2520
Epoch   1 Batch   98/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7741, Loss: 0.2503
Epoch   1 Batch   99/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7670, Loss: 0.2577
Epoch   1 Batch  100/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.7614, Loss: 0.2544
Epoch   1 Batch  101/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7433, Loss: 0.2446
Epoch   1 Batch  102/1077 - Train Accuracy: 0.7852, Validation Accuracy: 0.7436, Loss: 0.2517
Epoch   1 Batch  103/1077 - Train Accuracy: 0.7767, Validation Accuracy: 0.7401, Loss: 0.2940
Epoch   1 Batch  104/1077 - Train Accuracy: 0.7854, Validation Accuracy: 0.7447, Loss: 0.2635
Epoch   1 Batch  105/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7472, Loss: 0.2447
Epoch   1 Batch  106/1077 - Train Accuracy: 0.7377, Validation Accuracy: 0.7461, Loss: 0.2914
Epoch   1 Batch  107/1077 - Train Accuracy: 0.7303, Validation Accuracy: 0.7386, Loss: 0.2387
Epoch   1 Batch  108/1077 - Train Accuracy: 0.7841, Validation Accuracy: 0.7582, Loss: 0.2293
Epoch   1 Batch  109/1077 - Train Accuracy: 0.7637, Validation Accuracy: 0.7564, Loss: 0.2589
Epoch   1 Batch  110/1077 - Train Accuracy: 0.8004, Validation Accuracy: 0.7649, Loss: 0.2325
Epoch   1 Batch  111/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7734, Loss: 0.2568
Epoch   1 Batch  112/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7734, Loss: 0.2459
Epoch   1 Batch  113/1077 - Train Accuracy: 0.7477, Validation Accuracy: 0.7802, Loss: 0.2629
Epoch   1 Batch  114/1077 - Train Accuracy: 0.8173, Validation Accuracy: 0.7873, Loss: 0.2169
Epoch   1 Batch  115/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7777, Loss: 0.2646
Epoch   1 Batch  116/1077 - Train Accuracy: 0.7242, Validation Accuracy: 0.7674, Loss: 0.2476
Epoch   1 Batch  117/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7475, Loss: 0.2334
Epoch   1 Batch  118/1077 - Train Accuracy: 0.7582, Validation Accuracy: 0.7617, Loss: 0.2614
Epoch   1 Batch  119/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7560, Loss: 0.2497
Epoch   1 Batch  120/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7429, Loss: 0.2816
Epoch   1 Batch  121/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7479, Loss: 0.2479
Epoch   1 Batch  122/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7642, Loss: 0.2563
Epoch   1 Batch  123/1077 - Train Accuracy: 0.7953, Validation Accuracy: 0.7827, Loss: 0.2195
Epoch   1 Batch  124/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.8004, Loss: 0.2641
Epoch   1 Batch  125/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.8033, Loss: 0.2506
Epoch   1 Batch  126/1077 - Train Accuracy: 0.8043, Validation Accuracy: 0.7887, Loss: 0.2292
Epoch   1 Batch  127/1077 - Train Accuracy: 0.7684, Validation Accuracy: 0.7837, Loss: 0.2406
Epoch   1 Batch  128/1077 - Train Accuracy: 0.8181, Validation Accuracy: 0.7624, Loss: 0.2209
Epoch   1 Batch  129/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7319, Loss: 0.2528
Epoch   1 Batch  130/1077 - Train Accuracy: 0.7898, Validation Accuracy: 0.7276, Loss: 0.2275
Epoch   1 Batch  131/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7237, Loss: 0.2426
Epoch   1 Batch  132/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.7156, Loss: 0.2476
Epoch   1 Batch  133/1077 - Train Accuracy: 0.7327, Validation Accuracy: 0.7216, Loss: 0.2369
Epoch   1 Batch  134/1077 - Train Accuracy: 0.7958, Validation Accuracy: 0.7159, Loss: 0.2472
Epoch   1 Batch  135/1077 - Train Accuracy: 0.7726, Validation Accuracy: 0.7244, Loss: 0.2694
Epoch   1 Batch  136/1077 - Train Accuracy: 0.8090, Validation Accuracy: 0.7212, Loss: 0.2493
Epoch   1 Batch  137/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7344, Loss: 0.2112
Epoch   1 Batch  138/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7425, Loss: 0.2419
Epoch   1 Batch  139/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7607, Loss: 0.2581
Epoch   1 Batch  140/1077 - Train Accuracy: 0.7714, Validation Accuracy: 0.7802, Loss: 0.2362
Epoch   1 Batch  141/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7770, Loss: 0.2488
Epoch   1 Batch  142/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7788, Loss: 0.2385
Epoch   1 Batch  143/1077 - Train Accuracy: 0.7316, Validation Accuracy: 0.7670, Loss: 0.2616
Epoch   1 Batch  144/1077 - Train Accuracy: 0.7549, Validation Accuracy: 0.7670, Loss: 0.2648
Epoch   1 Batch  145/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7507, Loss: 0.2613
Epoch   1 Batch  146/1077 - Train Accuracy: 0.7865, Validation Accuracy: 0.7582, Loss: 0.2755
Epoch   1 Batch  147/1077 - Train Accuracy: 0.7410, Validation Accuracy: 0.7571, Loss: 0.2328
Epoch   1 Batch  148/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7571, Loss: 0.2398
Epoch   1 Batch  149/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7344, Loss: 0.2401
Epoch   1 Batch  150/1077 - Train Accuracy: 0.7850, Validation Accuracy: 0.7429, Loss: 0.2488
Epoch   1 Batch  151/1077 - Train Accuracy: 0.7470, Validation Accuracy: 0.7457, Loss: 0.2275
Epoch   1 Batch  152/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7418, Loss: 0.2503
Epoch   1 Batch  153/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7447, Loss: 0.2484
Epoch   1 Batch  154/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7500, Loss: 0.2321
Epoch   1 Batch  155/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.7614, Loss: 0.2413
Epoch   1 Batch  156/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7781, Loss: 0.2334
Epoch   1 Batch  157/1077 - Train Accuracy: 0.7816, Validation Accuracy: 0.8107, Loss: 0.2267
Epoch   1 Batch  158/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.8104, Loss: 0.2561
Epoch   1 Batch  159/1077 - Train Accuracy: 0.8196, Validation Accuracy: 0.8146, Loss: 0.2043
Epoch   1 Batch  160/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.8072, Loss: 0.2361
Epoch   1 Batch  161/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.8001, Loss: 0.2265
Epoch   1 Batch  162/1077 - Train Accuracy: 0.8070, Validation Accuracy: 0.8111, Loss: 0.2641
Epoch   1 Batch  163/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.8043, Loss: 0.2490
Epoch   1 Batch  164/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7880, Loss: 0.2412
Epoch   1 Batch  165/1077 - Train Accuracy: 0.7449, Validation Accuracy: 0.7688, Loss: 0.2124
Epoch   1 Batch  166/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7678, Loss: 0.2469
Epoch   1 Batch  167/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.7525, Loss: 0.2428
Epoch   1 Batch  168/1077 - Train Accuracy: 0.7759, Validation Accuracy: 0.7670, Loss: 0.2654
Epoch   1 Batch  169/1077 - Train Accuracy: 0.7872, Validation Accuracy: 0.7710, Loss: 0.2550
Epoch   1 Batch  170/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7688, Loss: 0.2382
Epoch   1 Batch  171/1077 - Train Accuracy: 0.8015, Validation Accuracy: 0.7791, Loss: 0.2221
Epoch   1 Batch  172/1077 - Train Accuracy: 0.8233, Validation Accuracy: 0.7795, Loss: 0.2160
Epoch   1 Batch  173/1077 - Train Accuracy: 0.7763, Validation Accuracy: 0.7770, Loss: 0.2546
Epoch   1 Batch  174/1077 - Train Accuracy: 0.8320, Validation Accuracy: 0.7976, Loss: 0.2218
Epoch   1 Batch  175/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7933, Loss: 0.2368
Epoch   1 Batch  176/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7919, Loss: 0.2416
Epoch   1 Batch  177/1077 - Train Accuracy: 0.8063, Validation Accuracy: 0.7969, Loss: 0.2658
Epoch   1 Batch  178/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7898, Loss: 0.2521
Epoch   1 Batch  179/1077 - Train Accuracy: 0.7993, Validation Accuracy: 0.7869, Loss: 0.2397
Epoch   1 Batch  180/1077 - Train Accuracy: 0.7641, Validation Accuracy: 0.7795, Loss: 0.2317
Epoch   1 Batch  181/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7901, Loss: 0.2699
Epoch   1 Batch  182/1077 - Train Accuracy: 0.7679, Validation Accuracy: 0.7557, Loss: 0.2552
Epoch   1 Batch  183/1077 - Train Accuracy: 0.7754, Validation Accuracy: 0.7550, Loss: 0.2383
Epoch   1 Batch  184/1077 - Train Accuracy: 0.8168, Validation Accuracy: 0.7504, Loss: 0.2159
Epoch   1 Batch  185/1077 - Train Accuracy: 0.7535, Validation Accuracy: 0.7500, Loss: 0.2390
Epoch   1 Batch  186/1077 - Train Accuracy: 0.7759, Validation Accuracy: 0.7543, Loss: 0.2502
Epoch   1 Batch  187/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7511, Loss: 0.2208
Epoch   1 Batch  188/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7560, Loss: 0.2380
Epoch   1 Batch  189/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7603, Loss: 0.2334
Epoch   1 Batch  190/1077 - Train Accuracy: 0.8258, Validation Accuracy: 0.7745, Loss: 0.2245
Epoch   1 Batch  191/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7795, Loss: 0.2124
Epoch   1 Batch  192/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7823, Loss: 0.2249
Epoch   1 Batch  193/1077 - Train Accuracy: 0.7934, Validation Accuracy: 0.7905, Loss: 0.2422
Epoch   1 Batch  194/1077 - Train Accuracy: 0.8021, Validation Accuracy: 0.7944, Loss: 0.2175
Epoch   1 Batch  195/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7880, Loss: 0.2128
Epoch   1 Batch  196/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.7930, Loss: 0.2309
Epoch   1 Batch  197/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.8004, Loss: 0.2277
Epoch   1 Batch  198/1077 - Train Accuracy: 0.8259, Validation Accuracy: 0.7891, Loss: 0.2273
Epoch   1 Batch  199/1077 - Train Accuracy: 0.7762, Validation Accuracy: 0.7802, Loss: 0.2209
Epoch   1 Batch  200/1077 - Train Accuracy: 0.7656, Validation Accuracy: 0.7663, Loss: 0.2517
Epoch   1 Batch  201/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7539, Loss: 0.2090
Epoch   1 Batch  202/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7621, Loss: 0.2347
Epoch   1 Batch  203/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7443, Loss: 0.2359
Epoch   1 Batch  204/1077 - Train Accuracy: 0.7676, Validation Accuracy: 0.7475, Loss: 0.2618
Epoch   1 Batch  205/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7472, Loss: 0.2444
Epoch   1 Batch  206/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.7443, Loss: 0.2106
Epoch   1 Batch  207/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7500, Loss: 0.2386
Epoch   1 Batch  208/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.7472, Loss: 0.2351
Epoch   1 Batch  209/1077 - Train Accuracy: 0.8077, Validation Accuracy: 0.7646, Loss: 0.2091
Epoch   1 Batch  210/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.7578, Loss: 0.2377
Epoch   1 Batch  211/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7706, Loss: 0.2226
Epoch   1 Batch  212/1077 - Train Accuracy: 0.8010, Validation Accuracy: 0.7926, Loss: 0.2093
Epoch   1 Batch  213/1077 - Train Accuracy: 0.7609, Validation Accuracy: 0.7898, Loss: 0.2081
Epoch   1 Batch  214/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7990, Loss: 0.2352
Epoch   1 Batch  215/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.8086, Loss: 0.2439
Epoch   1 Batch  216/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.8072, Loss: 0.2376
Epoch   1 Batch  217/1077 - Train Accuracy: 0.8199, Validation Accuracy: 0.7962, Loss: 0.2201
Epoch   1 Batch  218/1077 - Train Accuracy: 0.7862, Validation Accuracy: 0.7937, Loss: 0.2727
Epoch   1 Batch  219/1077 - Train Accuracy: 0.8387, Validation Accuracy: 0.7816, Loss: 0.2195
Epoch   1 Batch  220/1077 - Train Accuracy: 0.7993, Validation Accuracy: 0.7610, Loss: 0.2362
Epoch   1 Batch  221/1077 - Train Accuracy: 0.8096, Validation Accuracy: 0.7663, Loss: 0.2420
Epoch   1 Batch  222/1077 - Train Accuracy: 0.7746, Validation Accuracy: 0.7685, Loss: 0.2358
Epoch   1 Batch  223/1077 - Train Accuracy: 0.8125, Validation Accuracy: 0.7727, Loss: 0.2087
Epoch   1 Batch  224/1077 - Train Accuracy: 0.7941, Validation Accuracy: 0.7855, Loss: 0.2346
Epoch   1 Batch  225/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7823, Loss: 0.2368
Epoch   1 Batch  226/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.7816, Loss: 0.2186
Epoch   1 Batch  227/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7674, Loss: 0.2617
Epoch   1 Batch  228/1077 - Train Accuracy: 0.8180, Validation Accuracy: 0.7642, Loss: 0.2065
Epoch   1 Batch  229/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7546, Loss: 0.2254
Epoch   1 Batch  230/1077 - Train Accuracy: 0.7809, Validation Accuracy: 0.7468, Loss: 0.2290
Epoch   1 Batch  231/1077 - Train Accuracy: 0.7875, Validation Accuracy: 0.7504, Loss: 0.2491
Epoch   1 Batch  232/1077 - Train Accuracy: 0.8154, Validation Accuracy: 0.7646, Loss: 0.2407
Epoch   1 Batch  233/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7837, Loss: 0.2603
Epoch   1 Batch  234/1077 - Train Accuracy: 0.7842, Validation Accuracy: 0.7937, Loss: 0.2329
Epoch   1 Batch  235/1077 - Train Accuracy: 0.7835, Validation Accuracy: 0.7855, Loss: 0.2046
Epoch   1 Batch  236/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.7887, Loss: 0.2399
Epoch   1 Batch  237/1077 - Train Accuracy: 0.8356, Validation Accuracy: 0.7894, Loss: 0.2040
Epoch   1 Batch  238/1077 - Train Accuracy: 0.7949, Validation Accuracy: 0.7887, Loss: 0.2290
Epoch   1 Batch  239/1077 - Train Accuracy: 0.8166, Validation Accuracy: 0.7823, Loss: 0.2023
Epoch   1 Batch  240/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.7738, Loss: 0.2123
Epoch   1 Batch  241/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.7720, Loss: 0.2063
Epoch   1 Batch  242/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7812, Loss: 0.2255
Epoch   1 Batch  243/1077 - Train Accuracy: 0.7664, Validation Accuracy: 0.7759, Loss: 0.2389
Epoch   1 Batch  244/1077 - Train Accuracy: 0.8161, Validation Accuracy: 0.7809, Loss: 0.2178
Epoch   1 Batch  245/1077 - Train Accuracy: 0.8281, Validation Accuracy: 0.7802, Loss: 0.2197
Epoch   1 Batch  246/1077 - Train Accuracy: 0.7707, Validation Accuracy: 0.7788, Loss: 0.2360
Epoch   1 Batch  247/1077 - Train Accuracy: 0.8214, Validation Accuracy: 0.7770, Loss: 0.2011
Epoch   1 Batch  248/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7759, Loss: 0.2199
Epoch   1 Batch  249/1077 - Train Accuracy: 0.8098, Validation Accuracy: 0.7859, Loss: 0.2242
Epoch   1 Batch  250/1077 - Train Accuracy: 0.7990, Validation Accuracy: 0.7841, Loss: 0.2114
Epoch   1 Batch  251/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.7837, Loss: 0.2214
Epoch   1 Batch  252/1077 - Train Accuracy: 0.8496, Validation Accuracy: 0.7894, Loss: 0.2473
Epoch   1 Batch  253/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.7812, Loss: 0.2335
Epoch   1 Batch  254/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7830, Loss: 0.2388
Epoch   1 Batch  255/1077 - Train Accuracy: 0.7988, Validation Accuracy: 0.7876, Loss: 0.2262
Epoch   1 Batch  256/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7990, Loss: 0.2611
Epoch   1 Batch  257/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7812, Loss: 0.2232
Epoch   1 Batch  258/1077 - Train Accuracy: 0.7831, Validation Accuracy: 0.7631, Loss: 0.2172
Epoch   1 Batch  259/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7521, Loss: 0.2172
Epoch   1 Batch  260/1077 - Train Accuracy: 0.8147, Validation Accuracy: 0.7461, Loss: 0.1966
Epoch   1 Batch  261/1077 - Train Accuracy: 0.7612, Validation Accuracy: 0.7525, Loss: 0.2125
Epoch   1 Batch  262/1077 - Train Accuracy: 0.7848, Validation Accuracy: 0.7521, Loss: 0.2110
Epoch   1 Batch  263/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7518, Loss: 0.1977
Epoch   1 Batch  264/1077 - Train Accuracy: 0.7711, Validation Accuracy: 0.7507, Loss: 0.2377
Epoch   1 Batch  265/1077 - Train Accuracy: 0.7742, Validation Accuracy: 0.7599, Loss: 0.2013
Epoch   1 Batch  266/1077 - Train Accuracy: 0.7433, Validation Accuracy: 0.7564, Loss: 0.2159
Epoch   1 Batch  267/1077 - Train Accuracy: 0.8061, Validation Accuracy: 0.7592, Loss: 0.2087
Epoch   1 Batch  268/1077 - Train Accuracy: 0.7770, Validation Accuracy: 0.7805, Loss: 0.2243
Epoch   1 Batch  269/1077 - Train Accuracy: 0.7689, Validation Accuracy: 0.7841, Loss: 0.2420
Epoch   1 Batch  270/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7976, Loss: 0.2333
Epoch   1 Batch  271/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.7947, Loss: 0.2201
Epoch   1 Batch  272/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7880, Loss: 0.2624
Epoch   1 Batch  273/1077 - Train Accuracy: 0.7894, Validation Accuracy: 0.7862, Loss: 0.2066
Epoch   1 Batch  274/1077 - Train Accuracy: 0.8155, Validation Accuracy: 0.7710, Loss: 0.2028
Epoch   1 Batch  275/1077 - Train Accuracy: 0.7734, Validation Accuracy: 0.7713, Loss: 0.2123
Epoch   1 Batch  276/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7898, Loss: 0.2483
Epoch   1 Batch  277/1077 - Train Accuracy: 0.8110, Validation Accuracy: 0.7930, Loss: 0.2020
Epoch   1 Batch  278/1077 - Train Accuracy: 0.7859, Validation Accuracy: 0.7898, Loss: 0.2303
Epoch   1 Batch  279/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7923, Loss: 0.2496
Epoch   1 Batch  280/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7841, Loss: 0.2299
Epoch   1 Batch  281/1077 - Train Accuracy: 0.7855, Validation Accuracy: 0.7908, Loss: 0.2362
Epoch   1 Batch  282/1077 - Train Accuracy: 0.7383, Validation Accuracy: 0.7539, Loss: 0.2596
Epoch   1 Batch  283/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.7521, Loss: 0.2343
Epoch   1 Batch  284/1077 - Train Accuracy: 0.7836, Validation Accuracy: 0.7489, Loss: 0.2381
Epoch   1 Batch  285/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7546, Loss: 0.2139
Epoch   1 Batch  286/1077 - Train Accuracy: 0.8371, Validation Accuracy: 0.7571, Loss: 0.2144
Epoch   1 Batch  287/1077 - Train Accuracy: 0.8176, Validation Accuracy: 0.7571, Loss: 0.2066
Epoch   1 Batch  288/1077 - Train Accuracy: 0.7789, Validation Accuracy: 0.7585, Loss: 0.2274
Epoch   1 Batch  289/1077 - Train Accuracy: 0.8270, Validation Accuracy: 0.7649, Loss: 0.2224
Epoch   1 Batch  290/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7653, Loss: 0.2568
Epoch   1 Batch  291/1077 - Train Accuracy: 0.7593, Validation Accuracy: 0.7681, Loss: 0.2683
Epoch   1 Batch  292/1077 - Train Accuracy: 0.8192, Validation Accuracy: 0.7720, Loss: 0.2153
Epoch   1 Batch  293/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7550, Loss: 0.2400
Epoch   1 Batch  294/1077 - Train Accuracy: 0.8036, Validation Accuracy: 0.7670, Loss: 0.2112
Epoch   1 Batch  295/1077 - Train Accuracy: 0.7837, Validation Accuracy: 0.7901, Loss: 0.2448
Epoch   1 Batch  296/1077 - Train Accuracy: 0.8002, Validation Accuracy: 0.8235, Loss: 0.2046
Epoch   1 Batch  297/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.8239, Loss: 0.2445
Epoch   1 Batch  298/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.8185, Loss: 0.2480
Epoch   1 Batch  299/1077 - Train Accuracy: 0.7922, Validation Accuracy: 0.8004, Loss: 0.2361
Epoch   1 Batch  300/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.7873, Loss: 0.2038
Epoch   1 Batch  301/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7820, Loss: 0.2162
Epoch   1 Batch  302/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.7734, Loss: 0.2254
Epoch   1 Batch  303/1077 - Train Accuracy: 0.7668, Validation Accuracy: 0.7713, Loss: 0.2456
Epoch   1 Batch  304/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7674, Loss: 0.2041
Epoch   1 Batch  305/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7585, Loss: 0.2122
Epoch   1 Batch  306/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7589, Loss: 0.2168
Epoch   1 Batch  307/1077 - Train Accuracy: 0.7712, Validation Accuracy: 0.7585, Loss: 0.2224
Epoch   1 Batch  308/1077 - Train Accuracy: 0.8035, Validation Accuracy: 0.7596, Loss: 0.2354
Epoch   1 Batch  309/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.7571, Loss: 0.1854
Epoch   1 Batch  310/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7809, Loss: 0.2207
Epoch   1 Batch  311/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.7930, Loss: 0.2000
Epoch   1 Batch  312/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.8036, Loss: 0.2383
Epoch   1 Batch  313/1077 - Train Accuracy: 0.8270, Validation Accuracy: 0.8079, Loss: 0.2069
Epoch   1 Batch  314/1077 - Train Accuracy: 0.7688, Validation Accuracy: 0.8068, Loss: 0.2340
Epoch   1 Batch  315/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.8061, Loss: 0.2021
Epoch   1 Batch  316/1077 - Train Accuracy: 0.8095, Validation Accuracy: 0.8121, Loss: 0.2099
Epoch   1 Batch  317/1077 - Train Accuracy: 0.8166, Validation Accuracy: 0.8004, Loss: 0.2494
Epoch   1 Batch  318/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7962, Loss: 0.2116
Epoch   1 Batch  319/1077 - Train Accuracy: 0.7738, Validation Accuracy: 0.7876, Loss: 0.2323
Epoch   1 Batch  320/1077 - Train Accuracy: 0.8227, Validation Accuracy: 0.7791, Loss: 0.1964
Epoch   1 Batch  321/1077 - Train Accuracy: 0.7555, Validation Accuracy: 0.7749, Loss: 0.2071
Epoch   1 Batch  322/1077 - Train Accuracy: 0.7667, Validation Accuracy: 0.7802, Loss: 0.1969
Epoch   1 Batch  323/1077 - Train Accuracy: 0.7430, Validation Accuracy: 0.7766, Loss: 0.2224
Epoch   1 Batch  324/1077 - Train Accuracy: 0.7691, Validation Accuracy: 0.7738, Loss: 0.2044
Epoch   1 Batch  325/1077 - Train Accuracy: 0.7827, Validation Accuracy: 0.7884, Loss: 0.2121
Epoch   1 Batch  326/1077 - Train Accuracy: 0.8419, Validation Accuracy: 0.7844, Loss: 0.2095
Epoch   1 Batch  327/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7923, Loss: 0.2319
Epoch   1 Batch  328/1077 - Train Accuracy: 0.8292, Validation Accuracy: 0.7841, Loss: 0.2222
Epoch   1 Batch  329/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7717, Loss: 0.2096
Epoch   1 Batch  330/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7663, Loss: 0.2109
Epoch   1 Batch  331/1077 - Train Accuracy: 0.8220, Validation Accuracy: 0.7816, Loss: 0.2138
Epoch   1 Batch  332/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7766, Loss: 0.1832
Epoch   1 Batch  333/1077 - Train Accuracy: 0.8442, Validation Accuracy: 0.7827, Loss: 0.2140
Epoch   1 Batch  334/1077 - Train Accuracy: 0.8105, Validation Accuracy: 0.7891, Loss: 0.2270
Epoch   1 Batch  335/1077 - Train Accuracy: 0.8356, Validation Accuracy: 0.7823, Loss: 0.1868
Epoch   1 Batch  336/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7852, Loss: 0.2472
Epoch   1 Batch  337/1077 - Train Accuracy: 0.7973, Validation Accuracy: 0.7880, Loss: 0.2112
Epoch   1 Batch  338/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7745, Loss: 0.2226
Epoch   1 Batch  339/1077 - Train Accuracy: 0.8215, Validation Accuracy: 0.7624, Loss: 0.1979
Epoch   1 Batch  340/1077 - Train Accuracy: 0.7981, Validation Accuracy: 0.7706, Loss: 0.2126
Epoch   1 Batch  341/1077 - Train Accuracy: 0.7867, Validation Accuracy: 0.7670, Loss: 0.2448
Epoch   1 Batch  342/1077 - Train Accuracy: 0.7935, Validation Accuracy: 0.7710, Loss: 0.1928
Epoch   1 Batch  343/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7731, Loss: 0.2022
Epoch   1 Batch  344/1077 - Train Accuracy: 0.8410, Validation Accuracy: 0.7777, Loss: 0.2047
Epoch   1 Batch  345/1077 - Train Accuracy: 0.8077, Validation Accuracy: 0.7834, Loss: 0.1936
Epoch   1 Batch  346/1077 - Train Accuracy: 0.7957, Validation Accuracy: 0.7795, Loss: 0.2100
Epoch   1 Batch  347/1077 - Train Accuracy: 0.8229, Validation Accuracy: 0.7827, Loss: 0.1974
Epoch   1 Batch  348/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7859, Loss: 0.2010
Epoch   1 Batch  349/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7745, Loss: 0.2097
Epoch   1 Batch  350/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7798, Loss: 0.2350
Epoch   1 Batch  351/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7944, Loss: 0.2034
Epoch   1 Batch  352/1077 - Train Accuracy: 0.8199, Validation Accuracy: 0.7962, Loss: 0.2055
Epoch   1 Batch  353/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.8132, Loss: 0.2182
Epoch   1 Batch  354/1077 - Train Accuracy: 0.7844, Validation Accuracy: 0.8015, Loss: 0.2196
Epoch   1 Batch  355/1077 - Train Accuracy: 0.8185, Validation Accuracy: 0.7972, Loss: 0.2104
Epoch   1 Batch  356/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.8026, Loss: 0.2032
Epoch   1 Batch  357/1077 - Train Accuracy: 0.7894, Validation Accuracy: 0.8011, Loss: 0.2028
Epoch   1 Batch  358/1077 - Train Accuracy: 0.7771, Validation Accuracy: 0.8168, Loss: 0.2296
Epoch   1 Batch  359/1077 - Train Accuracy: 0.8313, Validation Accuracy: 0.8171, Loss: 0.2205
Epoch   1 Batch  360/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.8072, Loss: 0.2059
Epoch   1 Batch  361/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.8061, Loss: 0.2150
Epoch   1 Batch  362/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.8097, Loss: 0.2030
Epoch   1 Batch  363/1077 - Train Accuracy: 0.7828, Validation Accuracy: 0.8185, Loss: 0.2221
Epoch   1 Batch  364/1077 - Train Accuracy: 0.7914, Validation Accuracy: 0.8054, Loss: 0.2276
Epoch   1 Batch  365/1077 - Train Accuracy: 0.8254, Validation Accuracy: 0.8100, Loss: 0.1881
Epoch   1 Batch  366/1077 - Train Accuracy: 0.7953, Validation Accuracy: 0.8082, Loss: 0.2119
Epoch   1 Batch  367/1077 - Train Accuracy: 0.8158, Validation Accuracy: 0.8011, Loss: 0.1780
Epoch   1 Batch  368/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.7887, Loss: 0.2109
Epoch   1 Batch  369/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7869, Loss: 0.2131
Epoch   1 Batch  370/1077 - Train Accuracy: 0.8255, Validation Accuracy: 0.7695, Loss: 0.2034
Epoch   1 Batch  371/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.7624, Loss: 0.1896
Epoch   1 Batch  372/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.7624, Loss: 0.1847
Epoch   1 Batch  373/1077 - Train Accuracy: 0.8084, Validation Accuracy: 0.7685, Loss: 0.1837
Epoch   1 Batch  374/1077 - Train Accuracy: 0.7629, Validation Accuracy: 0.7734, Loss: 0.2257
Epoch   1 Batch  375/1077 - Train Accuracy: 0.8327, Validation Accuracy: 0.7745, Loss: 0.1893
Epoch   1 Batch  376/1077 - Train Accuracy: 0.8036, Validation Accuracy: 0.7802, Loss: 0.2057
Epoch   1 Batch  377/1077 - Train Accuracy: 0.8105, Validation Accuracy: 0.7876, Loss: 0.1928
Epoch   1 Batch  378/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7972, Loss: 0.1942
Epoch   1 Batch  379/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7894, Loss: 0.2095
Epoch   1 Batch  380/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7972, Loss: 0.2030
Epoch   1 Batch  381/1077 - Train Accuracy: 0.7648, Validation Accuracy: 0.8033, Loss: 0.2304
Epoch   1 Batch  382/1077 - Train Accuracy: 0.7913, Validation Accuracy: 0.7962, Loss: 0.2420
Epoch   1 Batch  383/1077 - Train Accuracy: 0.8225, Validation Accuracy: 0.8026, Loss: 0.1822
Epoch   1 Batch  384/1077 - Train Accuracy: 0.7801, Validation Accuracy: 0.7994, Loss: 0.2007
Epoch   1 Batch  385/1077 - Train Accuracy: 0.8000, Validation Accuracy: 0.7944, Loss: 0.2041
Epoch   1 Batch  386/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.7937, Loss: 0.2114
Epoch   1 Batch  387/1077 - Train Accuracy: 0.8508, Validation Accuracy: 0.7969, Loss: 0.2041
Epoch   1 Batch  388/1077 - Train Accuracy: 0.7500, Validation Accuracy: 0.7965, Loss: 0.1791
Epoch   1 Batch  389/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.7855, Loss: 0.2054
Epoch   1 Batch  390/1077 - Train Accuracy: 0.7793, Validation Accuracy: 0.7820, Loss: 0.2060
Epoch   1 Batch  391/1077 - Train Accuracy: 0.8296, Validation Accuracy: 0.7880, Loss: 0.2058
Epoch   1 Batch  392/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.8043, Loss: 0.2234
Epoch   1 Batch  393/1077 - Train Accuracy: 0.8166, Validation Accuracy: 0.8114, Loss: 0.1851
Epoch   1 Batch  394/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.8224, Loss: 0.1967
Epoch   1 Batch  395/1077 - Train Accuracy: 0.8244, Validation Accuracy: 0.8210, Loss: 0.2056
Epoch   1 Batch  396/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.8171, Loss: 0.2227
Epoch   1 Batch  397/1077 - Train Accuracy: 0.8471, Validation Accuracy: 0.8093, Loss: 0.1862
Epoch   1 Batch  398/1077 - Train Accuracy: 0.8158, Validation Accuracy: 0.8082, Loss: 0.2238
Epoch   1 Batch  399/1077 - Train Accuracy: 0.7775, Validation Accuracy: 0.7969, Loss: 0.1962
Epoch   1 Batch  400/1077 - Train Accuracy: 0.8160, Validation Accuracy: 0.7894, Loss: 0.2171
Epoch   1 Batch  401/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7674, Loss: 0.1920
Epoch   1 Batch  402/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.7504, Loss: 0.1850
Epoch   1 Batch  403/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7496, Loss: 0.2245
Epoch   1 Batch  404/1077 - Train Accuracy: 0.8028, Validation Accuracy: 0.7599, Loss: 0.1882
Epoch   1 Batch  405/1077 - Train Accuracy: 0.8146, Validation Accuracy: 0.7674, Loss: 0.1995
Epoch   1 Batch  406/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.7702, Loss: 0.1875
Epoch   1 Batch  407/1077 - Train Accuracy: 0.7926, Validation Accuracy: 0.7745, Loss: 0.2035
Epoch   1 Batch  408/1077 - Train Accuracy: 0.7723, Validation Accuracy: 0.7727, Loss: 0.2170
Epoch   1 Batch  409/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7749, Loss: 0.2043
Epoch   1 Batch  410/1077 - Train Accuracy: 0.7928, Validation Accuracy: 0.7745, Loss: 0.2292
Epoch   1 Batch  411/1077 - Train Accuracy: 0.8296, Validation Accuracy: 0.7685, Loss: 0.2167
Epoch   1 Batch  412/1077 - Train Accuracy: 0.8160, Validation Accuracy: 0.7823, Loss: 0.1760
Epoch   1 Batch  413/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7830, Loss: 0.1934
Epoch   1 Batch  414/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.8175, Loss: 0.2003
Epoch   1 Batch  415/1077 - Train Accuracy: 0.8032, Validation Accuracy: 0.8168, Loss: 0.2160
Epoch   1 Batch  416/1077 - Train Accuracy: 0.8160, Validation Accuracy: 0.8182, Loss: 0.2184
Epoch   1 Batch  417/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.8157, Loss: 0.2343
Epoch   1 Batch  418/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.8139, Loss: 0.1896
Epoch   1 Batch  419/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.8129, Loss: 0.1997
Epoch   1 Batch  420/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.8029, Loss: 0.1835
Epoch   1 Batch  421/1077 - Train Accuracy: 0.7805, Validation Accuracy: 0.7983, Loss: 0.2249
Epoch   1 Batch  422/1077 - Train Accuracy: 0.7790, Validation Accuracy: 0.7955, Loss: 0.1891
Epoch   1 Batch  423/1077 - Train Accuracy: 0.8336, Validation Accuracy: 0.7812, Loss: 0.2036
Epoch   1 Batch  424/1077 - Train Accuracy: 0.7977, Validation Accuracy: 0.7631, Loss: 0.1958
Epoch   1 Batch  425/1077 - Train Accuracy: 0.8419, Validation Accuracy: 0.7592, Loss: 0.1675
Epoch   1 Batch  426/1077 - Train Accuracy: 0.8031, Validation Accuracy: 0.7731, Loss: 0.2098
Epoch   1 Batch  427/1077 - Train Accuracy: 0.7671, Validation Accuracy: 0.7688, Loss: 0.1989
Epoch   1 Batch  428/1077 - Train Accuracy: 0.8214, Validation Accuracy: 0.7610, Loss: 0.1774
Epoch   1 Batch  429/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.7674, Loss: 0.1814
Epoch   1 Batch  430/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7713, Loss: 0.1918
Epoch   1 Batch  431/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.7823, Loss: 0.2021
Epoch   1 Batch  432/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.7841, Loss: 0.2153
Epoch   1 Batch  433/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.7962, Loss: 0.1962
Epoch   1 Batch  434/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.7884, Loss: 0.1915
Epoch   1 Batch  435/1077 - Train Accuracy: 0.8384, Validation Accuracy: 0.7876, Loss: 0.2044
Epoch   1 Batch  436/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.7947, Loss: 0.2039
Epoch   1 Batch  437/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7947, Loss: 0.1913
Epoch   1 Batch  438/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7997, Loss: 0.2041
Epoch   1 Batch  439/1077 - Train Accuracy: 0.8234, Validation Accuracy: 0.8132, Loss: 0.2131
Epoch   1 Batch  440/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.8189, Loss: 0.2241
Epoch   1 Batch  441/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.8061, Loss: 0.1916
Epoch   1 Batch  442/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.7983, Loss: 0.2071
Epoch   1 Batch  443/1077 - Train Accuracy: 0.8415, Validation Accuracy: 0.8018, Loss: 0.1779
Epoch   1 Batch  444/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.8011, Loss: 0.1818
Epoch   1 Batch  445/1077 - Train Accuracy: 0.7903, Validation Accuracy: 0.8086, Loss: 0.2114
Epoch   1 Batch  446/1077 - Train Accuracy: 0.8248, Validation Accuracy: 0.8114, Loss: 0.1751
Epoch   1 Batch  447/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.8093, Loss: 0.1996
Epoch   1 Batch  448/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.8047, Loss: 0.2280
Epoch   1 Batch  449/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.8107, Loss: 0.2222
Epoch   1 Batch  450/1077 - Train Accuracy: 0.8285, Validation Accuracy: 0.8121, Loss: 0.1960
Epoch   1 Batch  451/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.7809, Loss: 0.1815
Epoch   1 Batch  452/1077 - Train Accuracy: 0.8227, Validation Accuracy: 0.7862, Loss: 0.1989
Epoch   1 Batch  453/1077 - Train Accuracy: 0.8475, Validation Accuracy: 0.7923, Loss: 0.1951
Epoch   1 Batch  454/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.7976, Loss: 0.1863
Epoch   1 Batch  455/1077 - Train Accuracy: 0.8008, Validation Accuracy: 0.7983, Loss: 0.1892
Epoch   1 Batch  456/1077 - Train Accuracy: 0.8156, Validation Accuracy: 0.7937, Loss: 0.1989
Epoch   1 Batch  457/1077 - Train Accuracy: 0.8058, Validation Accuracy: 0.7876, Loss: 0.1748
Epoch   1 Batch  458/1077 - Train Accuracy: 0.7352, Validation Accuracy: 0.7908, Loss: 0.1989
Epoch   1 Batch  459/1077 - Train Accuracy: 0.8095, Validation Accuracy: 0.8100, Loss: 0.1907
Epoch   1 Batch  460/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.8086, Loss: 0.2242
Epoch   1 Batch  461/1077 - Train Accuracy: 0.7977, Validation Accuracy: 0.8335, Loss: 0.2111
Epoch   1 Batch  462/1077 - Train Accuracy: 0.8508, Validation Accuracy: 0.8295, Loss: 0.2045
Epoch   1 Batch  463/1077 - Train Accuracy: 0.7773, Validation Accuracy: 0.8242, Loss: 0.2216
Epoch   1 Batch  464/1077 - Train Accuracy: 0.8336, Validation Accuracy: 0.8232, Loss: 0.1844
Epoch   1 Batch  465/1077 - Train Accuracy: 0.7817, Validation Accuracy: 0.8196, Loss: 0.2212
Epoch   1 Batch  466/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.8224, Loss: 0.1724
Epoch   1 Batch  467/1077 - Train Accuracy: 0.8523, Validation Accuracy: 0.8242, Loss: 0.2056
Epoch   1 Batch  468/1077 - Train Accuracy: 0.8571, Validation Accuracy: 0.8068, Loss: 0.1911
Epoch   1 Batch  469/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.8061, Loss: 0.2015
Epoch   1 Batch  470/1077 - Train Accuracy: 0.8166, Validation Accuracy: 0.8097, Loss: 0.1980
Epoch   1 Batch  471/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8228, Loss: 0.1658
Epoch   1 Batch  472/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.8196, Loss: 0.1846
Epoch   1 Batch  473/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.8040, Loss: 0.2044
Epoch   1 Batch  474/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.7908, Loss: 0.1985
Epoch   1 Batch  475/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.7830, Loss: 0.1902
Epoch   1 Batch  476/1077 - Train Accuracy: 0.8409, Validation Accuracy: 0.7752, Loss: 0.1945
Epoch   1 Batch  477/1077 - Train Accuracy: 0.8631, Validation Accuracy: 0.7766, Loss: 0.1838
Epoch   1 Batch  478/1077 - Train Accuracy: 0.7919, Validation Accuracy: 0.7784, Loss: 0.1936
Epoch   1 Batch  479/1077 - Train Accuracy: 0.8020, Validation Accuracy: 0.8015, Loss: 0.2064
Epoch   1 Batch  480/1077 - Train Accuracy: 0.8067, Validation Accuracy: 0.8089, Loss: 0.1954
Epoch   1 Batch  481/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.8189, Loss: 0.1915
Epoch   1 Batch  482/1077 - Train Accuracy: 0.8154, Validation Accuracy: 0.8345, Loss: 0.2164
Epoch   1 Batch  483/1077 - Train Accuracy: 0.7977, Validation Accuracy: 0.8345, Loss: 0.2066
Epoch   1 Batch  484/1077 - Train Accuracy: 0.8230, Validation Accuracy: 0.8402, Loss: 0.1934
Epoch   1 Batch  485/1077 - Train Accuracy: 0.8508, Validation Accuracy: 0.8324, Loss: 0.2044
Epoch   1 Batch  486/1077 - Train Accuracy: 0.8322, Validation Accuracy: 0.8370, Loss: 0.1946
Epoch   1 Batch  487/1077 - Train Accuracy: 0.8306, Validation Accuracy: 0.8246, Loss: 0.2003
Epoch   1 Batch  488/1077 - Train Accuracy: 0.8335, Validation Accuracy: 0.8306, Loss: 0.1980
Epoch   1 Batch  489/1077 - Train Accuracy: 0.8069, Validation Accuracy: 0.8171, Loss: 0.1755
Epoch   1 Batch  490/1077 - Train Accuracy: 0.8227, Validation Accuracy: 0.8100, Loss: 0.2042
Epoch   1 Batch  491/1077 - Train Accuracy: 0.8305, Validation Accuracy: 0.8072, Loss: 0.1938
Epoch   1 Batch  492/1077 - Train Accuracy: 0.7996, Validation Accuracy: 0.7823, Loss: 0.2080
Epoch   1 Batch  493/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7809, Loss: 0.1912
Epoch   1 Batch  494/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.7720, Loss: 0.1785
Epoch   1 Batch  495/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7678, Loss: 0.1947
Epoch   1 Batch  496/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7745, Loss: 0.2051
Epoch   1 Batch  497/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.8008, Loss: 0.2120
Epoch   1 Batch  498/1077 - Train Accuracy: 0.8504, Validation Accuracy: 0.8075, Loss: 0.1970
Epoch   1 Batch  499/1077 - Train Accuracy: 0.8274, Validation Accuracy: 0.8047, Loss: 0.1804
Epoch   1 Batch  500/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8022, Loss: 0.1867
Epoch   1 Batch  501/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.8054, Loss: 0.1788
Epoch   1 Batch  502/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8114, Loss: 0.2002
Epoch   1 Batch  503/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8221, Loss: 0.1810
Epoch   1 Batch  504/1077 - Train Accuracy: 0.8391, Validation Accuracy: 0.8317, Loss: 0.1986
Epoch   1 Batch  505/1077 - Train Accuracy: 0.8679, Validation Accuracy: 0.8434, Loss: 0.1544
Epoch   1 Batch  506/1077 - Train Accuracy: 0.8172, Validation Accuracy: 0.8374, Loss: 0.1875
Epoch   1 Batch  507/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.8335, Loss: 0.2043
Epoch   1 Batch  508/1077 - Train Accuracy: 0.8545, Validation Accuracy: 0.8185, Loss: 0.1715
Epoch   1 Batch  509/1077 - Train Accuracy: 0.8258, Validation Accuracy: 0.8207, Loss: 0.1981
Epoch   1 Batch  510/1077 - Train Accuracy: 0.8262, Validation Accuracy: 0.8164, Loss: 0.1793
Epoch   1 Batch  511/1077 - Train Accuracy: 0.8376, Validation Accuracy: 0.8129, Loss: 0.1988
Epoch   1 Batch  512/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8121, Loss: 0.1861
Epoch   1 Batch  513/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.8061, Loss: 0.2114
Epoch   1 Batch  514/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.8129, Loss: 0.1952
Epoch   1 Batch  515/1077 - Train Accuracy: 0.8293, Validation Accuracy: 0.8331, Loss: 0.2030
Epoch   1 Batch  516/1077 - Train Accuracy: 0.8560, Validation Accuracy: 0.8374, Loss: 0.1852
Epoch   1 Batch  517/1077 - Train Accuracy: 0.8281, Validation Accuracy: 0.8675, Loss: 0.1909
Epoch   1 Batch  518/1077 - Train Accuracy: 0.8098, Validation Accuracy: 0.8690, Loss: 0.1834
Epoch   1 Batch  519/1077 - Train Accuracy: 0.8621, Validation Accuracy: 0.8580, Loss: 0.1829
Epoch   1 Batch  520/1077 - Train Accuracy: 0.8772, Validation Accuracy: 0.8612, Loss: 0.1909
Epoch   1 Batch  521/1077 - Train Accuracy: 0.8132, Validation Accuracy: 0.8381, Loss: 0.1798
Epoch   1 Batch  522/1077 - Train Accuracy: 0.8023, Validation Accuracy: 0.8146, Loss: 0.2115
Epoch   1 Batch  523/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.8118, Loss: 0.2000
Epoch   1 Batch  524/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.7891, Loss: 0.1866
Epoch   1 Batch  525/1077 - Train Accuracy: 0.8281, Validation Accuracy: 0.7894, Loss: 0.1958
Epoch   1 Batch  526/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.7798, Loss: 0.1838
Epoch   1 Batch  527/1077 - Train Accuracy: 0.7952, Validation Accuracy: 0.7827, Loss: 0.2063
Epoch   1 Batch  528/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7937, Loss: 0.1908
Epoch   1 Batch  529/1077 - Train Accuracy: 0.7945, Validation Accuracy: 0.8111, Loss: 0.1892
Epoch   1 Batch  530/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.8189, Loss: 0.1876
Epoch   1 Batch  531/1077 - Train Accuracy: 0.8402, Validation Accuracy: 0.8352, Loss: 0.1862
Epoch   1 Batch  532/1077 - Train Accuracy: 0.8066, Validation Accuracy: 0.8516, Loss: 0.2055
Epoch   1 Batch  533/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.8306, Loss: 0.2008
Epoch   1 Batch  534/1077 - Train Accuracy: 0.8564, Validation Accuracy: 0.8221, Loss: 0.1712
Epoch   1 Batch  535/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8228, Loss: 0.1879
Epoch   1 Batch  536/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.8214, Loss: 0.1870
Epoch   1 Batch  537/1077 - Train Accuracy: 0.8422, Validation Accuracy: 0.8107, Loss: 0.1794
Epoch   1 Batch  538/1077 - Train Accuracy: 0.8769, Validation Accuracy: 0.8093, Loss: 0.1640
Epoch   1 Batch  539/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.8040, Loss: 0.2175
Epoch   1 Batch  540/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.8121, Loss: 0.1742
Epoch   1 Batch  541/1077 - Train Accuracy: 0.8187, Validation Accuracy: 0.8157, Loss: 0.1897
Epoch   1 Batch  542/1077 - Train Accuracy: 0.8254, Validation Accuracy: 0.8281, Loss: 0.1858
Epoch   1 Batch  543/1077 - Train Accuracy: 0.8297, Validation Accuracy: 0.8331, Loss: 0.1821
Epoch   1 Batch  544/1077 - Train Accuracy: 0.8582, Validation Accuracy: 0.8359, Loss: 0.1578
Epoch   1 Batch  545/1077 - Train Accuracy: 0.8223, Validation Accuracy: 0.8313, Loss: 0.2015
Epoch   1 Batch  546/1077 - Train Accuracy: 0.8281, Validation Accuracy: 0.8423, Loss: 0.2028
Epoch   1 Batch  547/1077 - Train Accuracy: 0.8566, Validation Accuracy: 0.8505, Loss: 0.1854
Epoch   1 Batch  548/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.8558, Loss: 0.1954
Epoch   1 Batch  549/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.8548, Loss: 0.2097
Epoch   1 Batch  550/1077 - Train Accuracy: 0.7902, Validation Accuracy: 0.8537, Loss: 0.1893
Epoch   1 Batch  551/1077 - Train Accuracy: 0.8449, Validation Accuracy: 0.8544, Loss: 0.2095
Epoch   1 Batch  552/1077 - Train Accuracy: 0.8496, Validation Accuracy: 0.8562, Loss: 0.2107
Epoch   1 Batch  553/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.8487, Loss: 0.1960
Epoch   1 Batch  554/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.8366, Loss: 0.1822
Epoch   1 Batch  555/1077 - Train Accuracy: 0.8387, Validation Accuracy: 0.8313, Loss: 0.1880
Epoch   1 Batch  556/1077 - Train Accuracy: 0.8223, Validation Accuracy: 0.8338, Loss: 0.1605
Epoch   1 Batch  557/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.8327, Loss: 0.1907
Epoch   1 Batch  558/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8516, Loss: 0.1886
Epoch   1 Batch  559/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.8530, Loss: 0.1925
Epoch   1 Batch  560/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.8462, Loss: 0.1894
Epoch   1 Batch  561/1077 - Train Accuracy: 0.8504, Validation Accuracy: 0.8356, Loss: 0.1699
Epoch   1 Batch  562/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8462, Loss: 0.1600
Epoch   1 Batch  563/1077 - Train Accuracy: 0.8117, Validation Accuracy: 0.8182, Loss: 0.2023
Epoch   1 Batch  564/1077 - Train Accuracy: 0.8335, Validation Accuracy: 0.8221, Loss: 0.1932
Epoch   1 Batch  565/1077 - Train Accuracy: 0.8400, Validation Accuracy: 0.8374, Loss: 0.1887
Epoch   1 Batch  566/1077 - Train Accuracy: 0.8484, Validation Accuracy: 0.8363, Loss: 0.1966
Epoch   1 Batch  567/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8406, Loss: 0.1797
Epoch   1 Batch  568/1077 - Train Accuracy: 0.8469, Validation Accuracy: 0.8224, Loss: 0.1946
Epoch   1 Batch  569/1077 - Train Accuracy: 0.8613, Validation Accuracy: 0.8246, Loss: 0.1985
Epoch   1 Batch  570/1077 - Train Accuracy: 0.8339, Validation Accuracy: 0.8224, Loss: 0.2107
Epoch   1 Batch  571/1077 - Train Accuracy: 0.8583, Validation Accuracy: 0.8267, Loss: 0.1686
Epoch   1 Batch  572/1077 - Train Accuracy: 0.8765, Validation Accuracy: 0.8324, Loss: 0.1738
Epoch   1 Batch  573/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.8413, Loss: 0.2137
Epoch   1 Batch  574/1077 - Train Accuracy: 0.8458, Validation Accuracy: 0.8356, Loss: 0.1966
Epoch   1 Batch  575/1077 - Train Accuracy: 0.8646, Validation Accuracy: 0.8377, Loss: 0.1714
Epoch   1 Batch  576/1077 - Train Accuracy: 0.8614, Validation Accuracy: 0.8434, Loss: 0.1658
Epoch   1 Batch  577/1077 - Train Accuracy: 0.8417, Validation Accuracy: 0.8572, Loss: 0.2170
Epoch   1 Batch  578/1077 - Train Accuracy: 0.8172, Validation Accuracy: 0.8558, Loss: 0.1880
Epoch   1 Batch  579/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8565, Loss: 0.1933
Epoch   1 Batch  580/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8569, Loss: 0.1713
Epoch   1 Batch  581/1077 - Train Accuracy: 0.8309, Validation Accuracy: 0.8555, Loss: 0.1585
Epoch   1 Batch  582/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.8558, Loss: 0.1856
Epoch   1 Batch  583/1077 - Train Accuracy: 0.8388, Validation Accuracy: 0.8537, Loss: 0.1884
Epoch   1 Batch  584/1077 - Train Accuracy: 0.8092, Validation Accuracy: 0.8576, Loss: 0.1875
Epoch   1 Batch  585/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.8466, Loss: 0.1641
Epoch   1 Batch  586/1077 - Train Accuracy: 0.8392, Validation Accuracy: 0.8306, Loss: 0.1920
Epoch   1 Batch  587/1077 - Train Accuracy: 0.8702, Validation Accuracy: 0.8015, Loss: 0.1846
Epoch   1 Batch  588/1077 - Train Accuracy: 0.8145, Validation Accuracy: 0.7926, Loss: 0.1777
Epoch   1 Batch  589/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7844, Loss: 0.1906
Epoch   1 Batch  590/1077 - Train Accuracy: 0.8026, Validation Accuracy: 0.7855, Loss: 0.2041
Epoch   1 Batch  591/1077 - Train Accuracy: 0.8256, Validation Accuracy: 0.7773, Loss: 0.1674
Epoch   1 Batch  592/1077 - Train Accuracy: 0.8160, Validation Accuracy: 0.7979, Loss: 0.1826
Epoch   1 Batch  593/1077 - Train Accuracy: 0.8088, Validation Accuracy: 0.8097, Loss: 0.1902
Epoch   1 Batch  594/1077 - Train Accuracy: 0.8262, Validation Accuracy: 0.8374, Loss: 0.2059
Epoch   1 Batch  595/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8544, Loss: 0.1715
Epoch   1 Batch  596/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8665, Loss: 0.1929
Epoch   1 Batch  597/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.8548, Loss: 0.1811
Epoch   1 Batch  598/1077 - Train Accuracy: 0.8326, Validation Accuracy: 0.8548, Loss: 0.1871
Epoch   1 Batch  599/1077 - Train Accuracy: 0.8262, Validation Accuracy: 0.8636, Loss: 0.2159
Epoch   1 Batch  600/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.8683, Loss: 0.1879
Epoch   1 Batch  601/1077 - Train Accuracy: 0.8687, Validation Accuracy: 0.8739, Loss: 0.1746
Epoch   1 Batch  602/1077 - Train Accuracy: 0.8324, Validation Accuracy: 0.8619, Loss: 0.1800
Epoch   1 Batch  603/1077 - Train Accuracy: 0.8397, Validation Accuracy: 0.8459, Loss: 0.1854
Epoch   1 Batch  604/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.8395, Loss: 0.1886
Epoch   1 Batch  605/1077 - Train Accuracy: 0.8187, Validation Accuracy: 0.8420, Loss: 0.1992
Epoch   1 Batch  606/1077 - Train Accuracy: 0.8263, Validation Accuracy: 0.8430, Loss: 0.1622
Epoch   1 Batch  607/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.8558, Loss: 0.1673
Epoch   1 Batch  608/1077 - Train Accuracy: 0.8504, Validation Accuracy: 0.8658, Loss: 0.1993
Epoch   1 Batch  609/1077 - Train Accuracy: 0.8406, Validation Accuracy: 0.8615, Loss: 0.1832
Epoch   1 Batch  610/1077 - Train Accuracy: 0.8220, Validation Accuracy: 0.8501, Loss: 0.2093
Epoch   1 Batch  611/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.8480, Loss: 0.1616
Epoch   1 Batch  612/1077 - Train Accuracy: 0.8486, Validation Accuracy: 0.8388, Loss: 0.1813
Epoch   1 Batch  613/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.8327, Loss: 0.1814
Epoch   1 Batch  614/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.8253, Loss: 0.1778
Epoch   1 Batch  615/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.8381, Loss: 0.1752
Epoch   1 Batch  616/1077 - Train Accuracy: 0.8491, Validation Accuracy: 0.8349, Loss: 0.1860
Epoch   1 Batch  617/1077 - Train Accuracy: 0.8434, Validation Accuracy: 0.8384, Loss: 0.1679
Epoch   1 Batch  618/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8402, Loss: 0.1759
Epoch   1 Batch  619/1077 - Train Accuracy: 0.8635, Validation Accuracy: 0.8398, Loss: 0.1673
Epoch   1 Batch  620/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.8448, Loss: 0.1636
Epoch   1 Batch  621/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8352, Loss: 0.1783
Epoch   1 Batch  622/1077 - Train Accuracy: 0.8458, Validation Accuracy: 0.8416, Loss: 0.1944
Epoch   1 Batch  623/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.8388, Loss: 0.1896
Epoch   1 Batch  624/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8352, Loss: 0.1817
Epoch   1 Batch  625/1077 - Train Accuracy: 0.8215, Validation Accuracy: 0.8359, Loss: 0.1869
Epoch   1 Batch  626/1077 - Train Accuracy: 0.8505, Validation Accuracy: 0.8388, Loss: 0.1608
Epoch   1 Batch  627/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.8430, Loss: 0.1578
Epoch   1 Batch  628/1077 - Train Accuracy: 0.8184, Validation Accuracy: 0.8491, Loss: 0.1894
Epoch   1 Batch  629/1077 - Train Accuracy: 0.8265, Validation Accuracy: 0.8413, Loss: 0.2025
Epoch   1 Batch  630/1077 - Train Accuracy: 0.8379, Validation Accuracy: 0.8352, Loss: 0.1865
Epoch   1 Batch  631/1077 - Train Accuracy: 0.8374, Validation Accuracy: 0.8338, Loss: 0.1722
Epoch   1 Batch  632/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.8342, Loss: 0.1598
Epoch   1 Batch  633/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.8398, Loss: 0.1867
Epoch   1 Batch  634/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.8480, Loss: 0.1598
Epoch   1 Batch  635/1077 - Train Accuracy: 0.8400, Validation Accuracy: 0.8469, Loss: 0.2051
Epoch   1 Batch  636/1077 - Train Accuracy: 0.8453, Validation Accuracy: 0.8413, Loss: 0.1689
Epoch   1 Batch  637/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8473, Loss: 0.1652
Epoch   1 Batch  638/1077 - Train Accuracy: 0.8743, Validation Accuracy: 0.8509, Loss: 0.1777
Epoch   1 Batch  639/1077 - Train Accuracy: 0.8484, Validation Accuracy: 0.8530, Loss: 0.1951
Epoch   1 Batch  640/1077 - Train Accuracy: 0.8341, Validation Accuracy: 0.8374, Loss: 0.1825
Epoch   1 Batch  641/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.8455, Loss: 0.1688
Epoch   1 Batch  642/1077 - Train Accuracy: 0.7999, Validation Accuracy: 0.8498, Loss: 0.1883
Epoch   1 Batch  643/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.8455, Loss: 0.1665
Epoch   1 Batch  644/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.8366, Loss: 0.1958
Epoch   1 Batch  645/1077 - Train Accuracy: 0.8326, Validation Accuracy: 0.8491, Loss: 0.1798
Epoch   1 Batch  646/1077 - Train Accuracy: 0.8597, Validation Accuracy: 0.8590, Loss: 0.1787
Epoch   1 Batch  647/1077 - Train Accuracy: 0.8418, Validation Accuracy: 0.8576, Loss: 0.1879
Epoch   1 Batch  648/1077 - Train Accuracy: 0.8683, Validation Accuracy: 0.8572, Loss: 0.1472
Epoch   1 Batch  649/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.8569, Loss: 0.1826
Epoch   1 Batch  650/1077 - Train Accuracy: 0.8449, Validation Accuracy: 0.8455, Loss: 0.1770
Epoch   1 Batch  651/1077 - Train Accuracy: 0.8579, Validation Accuracy: 0.8455, Loss: 0.1602
Epoch   1 Batch  652/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8441, Loss: 0.1831
Epoch   1 Batch  653/1077 - Train Accuracy: 0.8562, Validation Accuracy: 0.8445, Loss: 0.1790
Epoch   1 Batch  654/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8384, Loss: 0.1772
Epoch   1 Batch  655/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.8406, Loss: 0.1902
Epoch   1 Batch  656/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8459, Loss: 0.1686
Epoch   1 Batch  657/1077 - Train Accuracy: 0.8771, Validation Accuracy: 0.8462, Loss: 0.1741
Epoch   1 Batch  658/1077 - Train Accuracy: 0.8214, Validation Accuracy: 0.8441, Loss: 0.1667
Epoch   1 Batch  659/1077 - Train Accuracy: 0.8560, Validation Accuracy: 0.8402, Loss: 0.1742
Epoch   1 Batch  660/1077 - Train Accuracy: 0.8582, Validation Accuracy: 0.8441, Loss: 0.1809
Epoch   1 Batch  661/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8427, Loss: 0.1567
Epoch   1 Batch  662/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8370, Loss: 0.1653
Epoch   1 Batch  663/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8381, Loss: 0.1651
Epoch   1 Batch  664/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8327, Loss: 0.1735
Epoch   1 Batch  665/1077 - Train Accuracy: 0.8340, Validation Accuracy: 0.8271, Loss: 0.1601
Epoch   1 Batch  666/1077 - Train Accuracy: 0.8335, Validation Accuracy: 0.8292, Loss: 0.1843
Epoch   1 Batch  667/1077 - Train Accuracy: 0.8487, Validation Accuracy: 0.8335, Loss: 0.1937
Epoch   1 Batch  668/1077 - Train Accuracy: 0.8545, Validation Accuracy: 0.8260, Loss: 0.1594
Epoch   1 Batch  669/1077 - Train Accuracy: 0.8340, Validation Accuracy: 0.8356, Loss: 0.1741
Epoch   1 Batch  670/1077 - Train Accuracy: 0.8530, Validation Accuracy: 0.8352, Loss: 0.1830
Epoch   1 Batch  671/1077 - Train Accuracy: 0.8487, Validation Accuracy: 0.8370, Loss: 0.1795
Epoch   1 Batch  672/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8306, Loss: 0.1742
Epoch   1 Batch  673/1077 - Train Accuracy: 0.8374, Validation Accuracy: 0.8370, Loss: 0.1683
Epoch   1 Batch  674/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8445, Loss: 0.1682
Epoch   1 Batch  675/1077 - Train Accuracy: 0.8653, Validation Accuracy: 0.8398, Loss: 0.1863
Epoch   1 Batch  676/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8423, Loss: 0.1802
Epoch   1 Batch  677/1077 - Train Accuracy: 0.8074, Validation Accuracy: 0.8494, Loss: 0.2166
Epoch   1 Batch  678/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8445, Loss: 0.1500
Epoch   1 Batch  679/1077 - Train Accuracy: 0.8573, Validation Accuracy: 0.8530, Loss: 0.1882
Epoch   1 Batch  680/1077 - Train Accuracy: 0.8713, Validation Accuracy: 0.8455, Loss: 0.1622
Epoch   1 Batch  681/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8480, Loss: 0.1851
Epoch   1 Batch  682/1077 - Train Accuracy: 0.8309, Validation Accuracy: 0.8622, Loss: 0.1780
Epoch   1 Batch  683/1077 - Train Accuracy: 0.8375, Validation Accuracy: 0.8633, Loss: 0.1831
Epoch   1 Batch  684/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8555, Loss: 0.1684
Epoch   1 Batch  685/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.8565, Loss: 0.1771
Epoch   1 Batch  686/1077 - Train Accuracy: 0.8296, Validation Accuracy: 0.8459, Loss: 0.1625
Epoch   1 Batch  687/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8491, Loss: 0.2005
Epoch   1 Batch  688/1077 - Train Accuracy: 0.8324, Validation Accuracy: 0.8359, Loss: 0.1644
Epoch   1 Batch  689/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8413, Loss: 0.1676
Epoch   1 Batch  690/1077 - Train Accuracy: 0.8648, Validation Accuracy: 0.8388, Loss: 0.1790
Epoch   1 Batch  691/1077 - Train Accuracy: 0.8450, Validation Accuracy: 0.8438, Loss: 0.1967
Epoch   1 Batch  692/1077 - Train Accuracy: 0.8423, Validation Accuracy: 0.8533, Loss: 0.1596
Epoch   1 Batch  693/1077 - Train Accuracy: 0.8030, Validation Accuracy: 0.8516, Loss: 0.2110
Epoch   1 Batch  694/1077 - Train Accuracy: 0.8486, Validation Accuracy: 0.8434, Loss: 0.1797
Epoch   1 Batch  695/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8398, Loss: 0.1637
Epoch   1 Batch  696/1077 - Train Accuracy: 0.8162, Validation Accuracy: 0.8413, Loss: 0.2010
Epoch   1 Batch  697/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8303, Loss: 0.1655
Epoch   1 Batch  698/1077 - Train Accuracy: 0.8542, Validation Accuracy: 0.8303, Loss: 0.1748
Epoch   1 Batch  699/1077 - Train Accuracy: 0.8372, Validation Accuracy: 0.8359, Loss: 0.1717
Epoch   1 Batch  700/1077 - Train Accuracy: 0.8582, Validation Accuracy: 0.8388, Loss: 0.1746
Epoch   1 Batch  701/1077 - Train Accuracy: 0.8488, Validation Accuracy: 0.8459, Loss: 0.1881
Epoch   1 Batch  702/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8640, Loss: 0.1814
Epoch   1 Batch  703/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8619, Loss: 0.1850
Epoch   1 Batch  704/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8612, Loss: 0.1976
Epoch   1 Batch  705/1077 - Train Accuracy: 0.8692, Validation Accuracy: 0.8498, Loss: 0.1860
Epoch   1 Batch  706/1077 - Train Accuracy: 0.7991, Validation Accuracy: 0.8519, Loss: 0.2212
Epoch   1 Batch  707/1077 - Train Accuracy: 0.8230, Validation Accuracy: 0.8565, Loss: 0.1745
Epoch   1 Batch  708/1077 - Train Accuracy: 0.8461, Validation Accuracy: 0.8604, Loss: 0.1855
Epoch   1 Batch  709/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.8477, Loss: 0.1817
Epoch   1 Batch  710/1077 - Train Accuracy: 0.8398, Validation Accuracy: 0.8455, Loss: 0.1701
Epoch   1 Batch  711/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8569, Loss: 0.1837
Epoch   1 Batch  712/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8555, Loss: 0.1740
Epoch   1 Batch  713/1077 - Train Accuracy: 0.8736, Validation Accuracy: 0.8583, Loss: 0.1505
Epoch   1 Batch  714/1077 - Train Accuracy: 0.8765, Validation Accuracy: 0.8700, Loss: 0.1693
Epoch   1 Batch  715/1077 - Train Accuracy: 0.8340, Validation Accuracy: 0.8690, Loss: 0.1937
Epoch   1 Batch  716/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8700, Loss: 0.1659
Epoch   1 Batch  717/1077 - Train Accuracy: 0.8857, Validation Accuracy: 0.8558, Loss: 0.1839
Epoch   1 Batch  718/1077 - Train Accuracy: 0.8238, Validation Accuracy: 0.8594, Loss: 0.1773
Epoch   1 Batch  719/1077 - Train Accuracy: 0.8214, Validation Accuracy: 0.8647, Loss: 0.1819
Epoch   1 Batch  720/1077 - Train Accuracy: 0.8475, Validation Accuracy: 0.8683, Loss: 0.1648
Epoch   1 Batch  721/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.8697, Loss: 0.1952
Epoch   1 Batch  722/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.8601, Loss: 0.1740
Epoch   1 Batch  723/1077 - Train Accuracy: 0.8903, Validation Accuracy: 0.8597, Loss: 0.1675
Epoch   1 Batch  724/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8537, Loss: 0.1923
Epoch   1 Batch  725/1077 - Train Accuracy: 0.8761, Validation Accuracy: 0.8526, Loss: 0.1423
Epoch   1 Batch  726/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8537, Loss: 0.1818
Epoch   1 Batch  727/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8530, Loss: 0.1658
Epoch   1 Batch  728/1077 - Train Accuracy: 0.8170, Validation Accuracy: 0.8480, Loss: 0.1857
Epoch   1 Batch  729/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8388, Loss: 0.1873
Epoch   1 Batch  730/1077 - Train Accuracy: 0.7863, Validation Accuracy: 0.8516, Loss: 0.1846
Epoch   1 Batch  731/1077 - Train Accuracy: 0.7887, Validation Accuracy: 0.8452, Loss: 0.1699
Epoch   1 Batch  732/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.8413, Loss: 0.1829
Epoch   1 Batch  733/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.8335, Loss: 0.1778
Epoch   1 Batch  734/1077 - Train Accuracy: 0.8882, Validation Accuracy: 0.8342, Loss: 0.1778
Epoch   1 Batch  735/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.8306, Loss: 0.1748
Epoch   1 Batch  736/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8402, Loss: 0.1519
Epoch   1 Batch  737/1077 - Train Accuracy: 0.8473, Validation Accuracy: 0.8441, Loss: 0.1818
Epoch   1 Batch  738/1077 - Train Accuracy: 0.8724, Validation Accuracy: 0.8565, Loss: 0.1414
Epoch   1 Batch  739/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8615, Loss: 0.1636
Epoch   1 Batch  740/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8725, Loss: 0.1625
Epoch   1 Batch  741/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8615, Loss: 0.1790
Epoch   1 Batch  742/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8668, Loss: 0.1690
Epoch   1 Batch  743/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8594, Loss: 0.1738
Epoch   1 Batch  744/1077 - Train Accuracy: 0.8683, Validation Accuracy: 0.8558, Loss: 0.1620
Epoch   1 Batch  745/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8505, Loss: 0.1757
Epoch   1 Batch  746/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8569, Loss: 0.1709
Epoch   1 Batch  747/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.8594, Loss: 0.1480
Epoch   1 Batch  748/1077 - Train Accuracy: 0.8469, Validation Accuracy: 0.8658, Loss: 0.1672
Epoch   1 Batch  749/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8636, Loss: 0.1768
Epoch   1 Batch  750/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8633, Loss: 0.1576
Epoch   1 Batch  751/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8548, Loss: 0.1795
Epoch   1 Batch  752/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.8427, Loss: 0.1698
Epoch   1 Batch  753/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8452, Loss: 0.1735
Epoch   1 Batch  754/1077 - Train Accuracy: 0.8582, Validation Accuracy: 0.8452, Loss: 0.1782
Epoch   1 Batch  755/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8480, Loss: 0.1610
Epoch   1 Batch  756/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8587, Loss: 0.1749
Epoch   1 Batch  757/1077 - Train Accuracy: 0.8540, Validation Accuracy: 0.8487, Loss: 0.1674
Epoch   1 Batch  758/1077 - Train Accuracy: 0.8720, Validation Accuracy: 0.8445, Loss: 0.1527
Epoch   1 Batch  759/1077 - Train Accuracy: 0.8683, Validation Accuracy: 0.8320, Loss: 0.1601
Epoch   1 Batch  760/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.8327, Loss: 0.1870
Epoch   1 Batch  761/1077 - Train Accuracy: 0.8277, Validation Accuracy: 0.8349, Loss: 0.1712
Epoch   1 Batch  762/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8349, Loss: 0.1572
Epoch   1 Batch  763/1077 - Train Accuracy: 0.8650, Validation Accuracy: 0.8338, Loss: 0.1535
Epoch   1 Batch  764/1077 - Train Accuracy: 0.8639, Validation Accuracy: 0.8327, Loss: 0.1898
Epoch   1 Batch  765/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8384, Loss: 0.1622
Epoch   1 Batch  766/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.8480, Loss: 0.1655
Epoch   1 Batch  767/1077 - Train Accuracy: 0.8691, Validation Accuracy: 0.8590, Loss: 0.1742
Epoch   1 Batch  768/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.8562, Loss: 0.1648
Epoch   1 Batch  769/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8526, Loss: 0.1654
Epoch   1 Batch  770/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8413, Loss: 0.1736
Epoch   1 Batch  771/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8455, Loss: 0.1769
Epoch   1 Batch  772/1077 - Train Accuracy: 0.8285, Validation Accuracy: 0.8430, Loss: 0.1513
Epoch   1 Batch  773/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8384, Loss: 0.1624
Epoch   1 Batch  774/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8292, Loss: 0.1973
Epoch   1 Batch  775/1077 - Train Accuracy: 0.8508, Validation Accuracy: 0.8395, Loss: 0.1739
Epoch   1 Batch  776/1077 - Train Accuracy: 0.8566, Validation Accuracy: 0.8434, Loss: 0.1607
Epoch   1 Batch  777/1077 - Train Accuracy: 0.8691, Validation Accuracy: 0.8384, Loss: 0.1759
Epoch   1 Batch  778/1077 - Train Accuracy: 0.8694, Validation Accuracy: 0.8402, Loss: 0.1506
Epoch   1 Batch  779/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8416, Loss: 0.1719
Epoch   1 Batch  780/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.8374, Loss: 0.1823
Epoch   1 Batch  781/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8434, Loss: 0.1359
Epoch   1 Batch  782/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8473, Loss: 0.1607
Epoch   1 Batch  783/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.8448, Loss: 0.1812
Epoch   1 Batch  784/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8366, Loss: 0.1522
Epoch   1 Batch  785/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8281, Loss: 0.1458
Epoch   1 Batch  786/1077 - Train Accuracy: 0.8367, Validation Accuracy: 0.8256, Loss: 0.1710
Epoch   1 Batch  787/1077 - Train Accuracy: 0.8579, Validation Accuracy: 0.8288, Loss: 0.1616
Epoch   1 Batch  788/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.8125, Loss: 0.1534
Epoch   1 Batch  789/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.8210, Loss: 0.1715
Epoch   1 Batch  790/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.8306, Loss: 0.1728
Epoch   1 Batch  791/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8349, Loss: 0.1764
Epoch   1 Batch  792/1077 - Train Accuracy: 0.8578, Validation Accuracy: 0.8327, Loss: 0.1818
Epoch   1 Batch  793/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8271, Loss: 0.1615
Epoch   1 Batch  794/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8448, Loss: 0.1724
Epoch   1 Batch  795/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.8462, Loss: 0.1663
Epoch   1 Batch  796/1077 - Train Accuracy: 0.8648, Validation Accuracy: 0.8477, Loss: 0.1761
Epoch   1 Batch  797/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8398, Loss: 0.1630
Epoch   1 Batch  798/1077 - Train Accuracy: 0.8473, Validation Accuracy: 0.8402, Loss: 0.1788
Epoch   1 Batch  799/1077 - Train Accuracy: 0.8379, Validation Accuracy: 0.8356, Loss: 0.2041
Epoch   1 Batch  800/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8338, Loss: 0.1730
Epoch   1 Batch  801/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8391, Loss: 0.1717
Epoch   1 Batch  802/1077 - Train Accuracy: 0.8791, Validation Accuracy: 0.8381, Loss: 0.1676
Epoch   1 Batch  803/1077 - Train Accuracy: 0.8551, Validation Accuracy: 0.8441, Loss: 0.1805
Epoch   1 Batch  804/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8388, Loss: 0.1443
Epoch   1 Batch  805/1077 - Train Accuracy: 0.8187, Validation Accuracy: 0.8441, Loss: 0.1639
Epoch   1 Batch  806/1077 - Train Accuracy: 0.8697, Validation Accuracy: 0.8509, Loss: 0.1561
Epoch   1 Batch  807/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8512, Loss: 0.1499
Epoch   1 Batch  808/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.8391, Loss: 0.1751
Epoch   1 Batch  809/1077 - Train Accuracy: 0.8528, Validation Accuracy: 0.8530, Loss: 0.2078
Epoch   1 Batch  810/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8491, Loss: 0.1486
Epoch   1 Batch  811/1077 - Train Accuracy: 0.8739, Validation Accuracy: 0.8537, Loss: 0.1644
Epoch   1 Batch  812/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.8530, Loss: 0.1690
Epoch   1 Batch  813/1077 - Train Accuracy: 0.8356, Validation Accuracy: 0.8455, Loss: 0.1692
Epoch   1 Batch  814/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.8423, Loss: 0.1691
Epoch   1 Batch  815/1077 - Train Accuracy: 0.8469, Validation Accuracy: 0.8413, Loss: 0.1729
Epoch   1 Batch  816/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8381, Loss: 0.1749
Epoch   1 Batch  817/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.8292, Loss: 0.1820
Epoch   1 Batch  818/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8352, Loss: 0.1796
Epoch   1 Batch  819/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8427, Loss: 0.1643
Epoch   1 Batch  820/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.8384, Loss: 0.1635
Epoch   1 Batch  821/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8274, Loss: 0.1616
Epoch   1 Batch  822/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8203, Loss: 0.1834
Epoch   1 Batch  823/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8306, Loss: 0.1655
Epoch   1 Batch  824/1077 - Train Accuracy: 0.8772, Validation Accuracy: 0.8338, Loss: 0.1696
Epoch   1 Batch  825/1077 - Train Accuracy: 0.8691, Validation Accuracy: 0.8374, Loss: 0.1711
Epoch   1 Batch  826/1077 - Train Accuracy: 0.8322, Validation Accuracy: 0.8391, Loss: 0.1641
Epoch   1 Batch  827/1077 - Train Accuracy: 0.8549, Validation Accuracy: 0.8459, Loss: 0.1580
Epoch   1 Batch  828/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8455, Loss: 0.1637
Epoch   1 Batch  829/1077 - Train Accuracy: 0.8227, Validation Accuracy: 0.8491, Loss: 0.2173
Epoch   1 Batch  830/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.8480, Loss: 0.1664
Epoch   1 Batch  831/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.8441, Loss: 0.1753
Epoch   1 Batch  832/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8466, Loss: 0.1653
Epoch   1 Batch  833/1077 - Train Accuracy: 0.8523, Validation Accuracy: 0.8540, Loss: 0.1711
Epoch   1 Batch  834/1077 - Train Accuracy: 0.8686, Validation Accuracy: 0.8501, Loss: 0.1628
Epoch   1 Batch  835/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8562, Loss: 0.1576
Epoch   1 Batch  836/1077 - Train Accuracy: 0.8475, Validation Accuracy: 0.8466, Loss: 0.1821
Epoch   1 Batch  837/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8519, Loss: 0.1789
Epoch   1 Batch  838/1077 - Train Accuracy: 0.8469, Validation Accuracy: 0.8587, Loss: 0.1656
Epoch   1 Batch  839/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8548, Loss: 0.1493
Epoch   1 Batch  840/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8423, Loss: 0.1361
Epoch   1 Batch  841/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8473, Loss: 0.1630
Epoch   1 Batch  842/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8516, Loss: 0.1695
Epoch   1 Batch  843/1077 - Train Accuracy: 0.8657, Validation Accuracy: 0.8370, Loss: 0.1586
Epoch   1 Batch  844/1077 - Train Accuracy: 0.8330, Validation Accuracy: 0.8452, Loss: 0.1571
Epoch   1 Batch  845/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8455, Loss: 0.1527
Epoch   1 Batch  846/1077 - Train Accuracy: 0.8488, Validation Accuracy: 0.8462, Loss: 0.1805
Epoch   1 Batch  847/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8544, Loss: 0.1827
Epoch   1 Batch  848/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8544, Loss: 0.1595
Epoch   1 Batch  849/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8487, Loss: 0.1511
Epoch   1 Batch  850/1077 - Train Accuracy: 0.8337, Validation Accuracy: 0.8466, Loss: 0.1783
Epoch   1 Batch  851/1077 - Train Accuracy: 0.8597, Validation Accuracy: 0.8473, Loss: 0.1747
Epoch   1 Batch  852/1077 - Train Accuracy: 0.8156, Validation Accuracy: 0.8469, Loss: 0.1799
Epoch   1 Batch  853/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8377, Loss: 0.1606
Epoch   1 Batch  854/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.8363, Loss: 0.1877
Epoch   1 Batch  855/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8430, Loss: 0.1611
Epoch   1 Batch  856/1077 - Train Accuracy: 0.8469, Validation Accuracy: 0.8356, Loss: 0.1692
Epoch   1 Batch  857/1077 - Train Accuracy: 0.8457, Validation Accuracy: 0.8352, Loss: 0.1459
Epoch   1 Batch  858/1077 - Train Accuracy: 0.8620, Validation Accuracy: 0.8331, Loss: 0.1463
Epoch   1 Batch  859/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8345, Loss: 0.1934
Epoch   1 Batch  860/1077 - Train Accuracy: 0.8330, Validation Accuracy: 0.8427, Loss: 0.1766
Epoch   1 Batch  861/1077 - Train Accuracy: 0.8461, Validation Accuracy: 0.8448, Loss: 0.1694
Epoch   1 Batch  862/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8494, Loss: 0.1664
Epoch   1 Batch  863/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8402, Loss: 0.1542
Epoch   1 Batch  864/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.8391, Loss: 0.1659
Epoch   1 Batch  865/1077 - Train Accuracy: 0.8540, Validation Accuracy: 0.8374, Loss: 0.1591
Epoch   1 Batch  866/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8295, Loss: 0.1755
Epoch   1 Batch  867/1077 - Train Accuracy: 0.8129, Validation Accuracy: 0.8285, Loss: 0.2023
Epoch   1 Batch  868/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8335, Loss: 0.1765
Epoch   1 Batch  869/1077 - Train Accuracy: 0.8566, Validation Accuracy: 0.8480, Loss: 0.1727
Epoch   1 Batch  870/1077 - Train Accuracy: 0.8252, Validation Accuracy: 0.8477, Loss: 0.1574
Epoch   1 Batch  871/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.8374, Loss: 0.1583
Epoch   1 Batch  872/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.8406, Loss: 0.1495
Epoch   1 Batch  873/1077 - Train Accuracy: 0.8352, Validation Accuracy: 0.8324, Loss: 0.1636
Epoch   1 Batch  874/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8352, Loss: 0.1667
Epoch   1 Batch  875/1077 - Train Accuracy: 0.8410, Validation Accuracy: 0.8402, Loss: 0.1721
Epoch   1 Batch  876/1077 - Train Accuracy: 0.8449, Validation Accuracy: 0.8501, Loss: 0.1639
Epoch   1 Batch  877/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.8462, Loss: 0.1632
Epoch   1 Batch  878/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8469, Loss: 0.1578
Epoch   1 Batch  879/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8526, Loss: 0.1385
Epoch   1 Batch  880/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8505, Loss: 0.1668
Epoch   1 Batch  881/1077 - Train Accuracy: 0.8414, Validation Accuracy: 0.8587, Loss: 0.1835
Epoch   1 Batch  882/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8516, Loss: 0.1693
Epoch   1 Batch  883/1077 - Train Accuracy: 0.8549, Validation Accuracy: 0.8540, Loss: 0.2209
Epoch   1 Batch  884/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8501, Loss: 0.1616
Epoch   1 Batch  885/1077 - Train Accuracy: 0.8800, Validation Accuracy: 0.8448, Loss: 0.1383
Epoch   1 Batch  886/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8423, Loss: 0.1722
Epoch   1 Batch  887/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8438, Loss: 0.1878
Epoch   1 Batch  888/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8416, Loss: 0.1342
Epoch   1 Batch  889/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.8274, Loss: 0.1612
Epoch   1 Batch  890/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8239, Loss: 0.1619
Epoch   1 Batch  891/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8281, Loss: 0.1539
Epoch   1 Batch  892/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8338, Loss: 0.1476
Epoch   1 Batch  893/1077 - Train Accuracy: 0.8582, Validation Accuracy: 0.8359, Loss: 0.1635
Epoch   1 Batch  894/1077 - Train Accuracy: 0.8839, Validation Accuracy: 0.8384, Loss: 0.1616
Epoch   1 Batch  895/1077 - Train Accuracy: 0.8551, Validation Accuracy: 0.8295, Loss: 0.1430
Epoch   1 Batch  896/1077 - Train Accuracy: 0.8413, Validation Accuracy: 0.8292, Loss: 0.1860
Epoch   1 Batch  897/1077 - Train Accuracy: 0.8717, Validation Accuracy: 0.8324, Loss: 0.1367
Epoch   1 Batch  898/1077 - Train Accuracy: 0.8460, Validation Accuracy: 0.8427, Loss: 0.1354
Epoch   1 Batch  899/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8466, Loss: 0.1691
Epoch   1 Batch  900/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8469, Loss: 0.1852
Epoch   1 Batch  901/1077 - Train Accuracy: 0.8560, Validation Accuracy: 0.8455, Loss: 0.1664
Epoch   1 Batch  902/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8448, Loss: 0.1535
Epoch   1 Batch  903/1077 - Train Accuracy: 0.8727, Validation Accuracy: 0.8484, Loss: 0.1442
Epoch   1 Batch  904/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.8480, Loss: 0.1470
Epoch   1 Batch  905/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8533, Loss: 0.1310
Epoch   1 Batch  906/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8501, Loss: 0.1464
Epoch   1 Batch  907/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8448, Loss: 0.1566
Epoch   1 Batch  908/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.8526, Loss: 0.1874
Epoch   1 Batch  909/1077 - Train Accuracy: 0.8477, Validation Accuracy: 0.8548, Loss: 0.1745
Epoch   1 Batch  910/1077 - Train Accuracy: 0.8780, Validation Accuracy: 0.8540, Loss: 0.1692
Epoch   1 Batch  911/1077 - Train Accuracy: 0.8384, Validation Accuracy: 0.8512, Loss: 0.1520
Epoch   1 Batch  912/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8548, Loss: 0.1725
Epoch   1 Batch  913/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8576, Loss: 0.1897
Epoch   1 Batch  914/1077 - Train Accuracy: 0.8704, Validation Accuracy: 0.8580, Loss: 0.1776
Epoch   1 Batch  915/1077 - Train Accuracy: 0.8458, Validation Accuracy: 0.8516, Loss: 0.1593
Epoch   1 Batch  916/1077 - Train Accuracy: 0.8621, Validation Accuracy: 0.8416, Loss: 0.1859
Epoch   1 Batch  917/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8423, Loss: 0.1539
Epoch   1 Batch  918/1077 - Train Accuracy: 0.8724, Validation Accuracy: 0.8398, Loss: 0.1528
Epoch   1 Batch  919/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8406, Loss: 0.1586
Epoch   1 Batch  920/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.8434, Loss: 0.1605
Epoch   1 Batch  921/1077 - Train Accuracy: 0.8496, Validation Accuracy: 0.8445, Loss: 0.1685
Epoch   1 Batch  922/1077 - Train Accuracy: 0.8486, Validation Accuracy: 0.8381, Loss: 0.1714
Epoch   1 Batch  923/1077 - Train Accuracy: 0.8701, Validation Accuracy: 0.8374, Loss: 0.1590
Epoch   1 Batch  924/1077 - Train Accuracy: 0.8738, Validation Accuracy: 0.8310, Loss: 0.2036
Epoch   1 Batch  925/1077 - Train Accuracy: 0.8772, Validation Accuracy: 0.8285, Loss: 0.1423
Epoch   1 Batch  926/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.8263, Loss: 0.1544
Epoch   1 Batch  927/1077 - Train Accuracy: 0.8199, Validation Accuracy: 0.8260, Loss: 0.1836
Epoch   1 Batch  928/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8175, Loss: 0.1582
Epoch   1 Batch  929/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8239, Loss: 0.1686
Epoch   1 Batch  930/1077 - Train Accuracy: 0.8562, Validation Accuracy: 0.8363, Loss: 0.1557
Epoch   1 Batch  931/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8374, Loss: 0.1605
Epoch   1 Batch  932/1077 - Train Accuracy: 0.8508, Validation Accuracy: 0.8462, Loss: 0.1551
Epoch   1 Batch  933/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8462, Loss: 0.1509
Epoch   1 Batch  934/1077 - Train Accuracy: 0.8332, Validation Accuracy: 0.8501, Loss: 0.1497
Epoch   1 Batch  935/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8462, Loss: 0.1498
Epoch   1 Batch  936/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8509, Loss: 0.1632
Epoch   1 Batch  937/1077 - Train Accuracy: 0.8520, Validation Accuracy: 0.8516, Loss: 0.1776
Epoch   1 Batch  938/1077 - Train Accuracy: 0.8582, Validation Accuracy: 0.8388, Loss: 0.1740
Epoch   1 Batch  939/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8416, Loss: 0.1736
Epoch   1 Batch  940/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.8469, Loss: 0.1483
Epoch   1 Batch  941/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8413, Loss: 0.1499
Epoch   1 Batch  942/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8416, Loss: 0.1481
Epoch   1 Batch  943/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8445, Loss: 0.1564
Epoch   1 Batch  944/1077 - Train Accuracy: 0.8233, Validation Accuracy: 0.8398, Loss: 0.1401
Epoch   1 Batch  945/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8391, Loss: 0.1504
Epoch   1 Batch  946/1077 - Train Accuracy: 0.9021, Validation Accuracy: 0.8540, Loss: 0.1498
Epoch   1 Batch  947/1077 - Train Accuracy: 0.7989, Validation Accuracy: 0.8626, Loss: 0.1832
Epoch   1 Batch  948/1077 - Train Accuracy: 0.8398, Validation Accuracy: 0.8537, Loss: 0.1545
Epoch   1 Batch  949/1077 - Train Accuracy: 0.8813, Validation Accuracy: 0.8516, Loss: 0.1315
Epoch   1 Batch  950/1077 - Train Accuracy: 0.8657, Validation Accuracy: 0.8519, Loss: 0.1398
Epoch   1 Batch  951/1077 - Train Accuracy: 0.8557, Validation Accuracy: 0.8501, Loss: 0.1630
Epoch   1 Batch  952/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8501, Loss: 0.1547
Epoch   1 Batch  953/1077 - Train Accuracy: 0.8968, Validation Accuracy: 0.8345, Loss: 0.1420
Epoch   1 Batch  954/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.8409, Loss: 0.1629
Epoch   1 Batch  955/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8363, Loss: 0.1758
Epoch   1 Batch  956/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8374, Loss: 0.1648
Epoch   1 Batch  957/1077 - Train Accuracy: 0.8843, Validation Accuracy: 0.8267, Loss: 0.1381
Epoch   1 Batch  958/1077 - Train Accuracy: 0.8582, Validation Accuracy: 0.8253, Loss: 0.1641
Epoch   1 Batch  959/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8253, Loss: 0.1497
Epoch   1 Batch  960/1077 - Train Accuracy: 0.8519, Validation Accuracy: 0.8249, Loss: 0.1625
Epoch   1 Batch  961/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8228, Loss: 0.1496
Epoch   1 Batch  962/1077 - Train Accuracy: 0.8876, Validation Accuracy: 0.8235, Loss: 0.1473
Epoch   1 Batch  963/1077 - Train Accuracy: 0.8485, Validation Accuracy: 0.8310, Loss: 0.1855
Epoch   1 Batch  964/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8388, Loss: 0.1523
Epoch   1 Batch  965/1077 - Train Accuracy: 0.8495, Validation Accuracy: 0.8395, Loss: 0.1628
Epoch   1 Batch  966/1077 - Train Accuracy: 0.8702, Validation Accuracy: 0.8491, Loss: 0.1360
Epoch   1 Batch  967/1077 - Train Accuracy: 0.8449, Validation Accuracy: 0.8487, Loss: 0.1629
Epoch   1 Batch  968/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8551, Loss: 0.1778
Epoch   1 Batch  969/1077 - Train Accuracy: 0.8646, Validation Accuracy: 0.8587, Loss: 0.1895
Epoch   1 Batch  970/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8501, Loss: 0.1621
Epoch   1 Batch  971/1077 - Train Accuracy: 0.8962, Validation Accuracy: 0.8597, Loss: 0.1667
Epoch   1 Batch  972/1077 - Train Accuracy: 0.8531, Validation Accuracy: 0.8555, Loss: 0.1560
Epoch   1 Batch  973/1077 - Train Accuracy: 0.9118, Validation Accuracy: 0.8551, Loss: 0.1293
Epoch   1 Batch  974/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8558, Loss: 0.1389
Epoch   1 Batch  975/1077 - Train Accuracy: 0.8542, Validation Accuracy: 0.8587, Loss: 0.1584
Epoch   1 Batch  976/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8622, Loss: 0.1311
Epoch   1 Batch  977/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8572, Loss: 0.1505
Epoch   1 Batch  978/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8608, Loss: 0.1754
Epoch   1 Batch  979/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8516, Loss: 0.1546
Epoch   1 Batch  980/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.8512, Loss: 0.1742
Epoch   1 Batch  981/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8466, Loss: 0.1483
Epoch   1 Batch  982/1077 - Train Accuracy: 0.8724, Validation Accuracy: 0.8498, Loss: 0.1507
Epoch   1 Batch  983/1077 - Train Accuracy: 0.8277, Validation Accuracy: 0.8594, Loss: 0.1666
Epoch   1 Batch  984/1077 - Train Accuracy: 0.8504, Validation Accuracy: 0.8604, Loss: 0.1687
Epoch   1 Batch  985/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8658, Loss: 0.1448
Epoch   1 Batch  986/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.8647, Loss: 0.1642
Epoch   1 Batch  987/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.8629, Loss: 0.1443
Epoch   1 Batch  988/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8665, Loss: 0.1623
Epoch   1 Batch  989/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8590, Loss: 0.1779
Epoch   1 Batch  990/1077 - Train Accuracy: 0.8553, Validation Accuracy: 0.8583, Loss: 0.1849
Epoch   1 Batch  991/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8608, Loss: 0.1550
Epoch   1 Batch  992/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8576, Loss: 0.1474
Epoch   1 Batch  993/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.8523, Loss: 0.1365
Epoch   1 Batch  994/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8320, Loss: 0.1626
Epoch   1 Batch  995/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8281, Loss: 0.1654
Epoch   1 Batch  996/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8370, Loss: 0.1628
Epoch   1 Batch  997/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8388, Loss: 0.1689
Epoch   1 Batch  998/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.8356, Loss: 0.1535
Epoch   1 Batch  999/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8391, Loss: 0.1697
Epoch   1 Batch 1000/1077 - Train Accuracy: 0.8534, Validation Accuracy: 0.8349, Loss: 0.1484
Epoch   1 Batch 1001/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8448, Loss: 0.1292
Epoch   1 Batch 1002/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8487, Loss: 0.1394
Epoch   1 Batch 1003/1077 - Train Accuracy: 0.8853, Validation Accuracy: 0.8477, Loss: 0.1589
Epoch   1 Batch 1004/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8526, Loss: 0.1849
Epoch   1 Batch 1005/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8427, Loss: 0.1420
Epoch   1 Batch 1006/1077 - Train Accuracy: 0.8496, Validation Accuracy: 0.8395, Loss: 0.1343
Epoch   1 Batch 1007/1077 - Train Accuracy: 0.9126, Validation Accuracy: 0.8377, Loss: 0.1392
Epoch   1 Batch 1008/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8462, Loss: 0.1782
Epoch   1 Batch 1009/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8452, Loss: 0.1391
Epoch   1 Batch 1010/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8438, Loss: 0.1507
Epoch   1 Batch 1011/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8487, Loss: 0.1497
Epoch   1 Batch 1012/1077 - Train Accuracy: 0.9048, Validation Accuracy: 0.8398, Loss: 0.1200
Epoch   1 Batch 1013/1077 - Train Accuracy: 0.8888, Validation Accuracy: 0.8409, Loss: 0.1395
Epoch   1 Batch 1014/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.8317, Loss: 0.1506
Epoch   1 Batch 1015/1077 - Train Accuracy: 0.8422, Validation Accuracy: 0.8359, Loss: 0.1781
Epoch   1 Batch 1016/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.8455, Loss: 0.1615
Epoch   1 Batch 1017/1077 - Train Accuracy: 0.8639, Validation Accuracy: 0.8452, Loss: 0.1650
Epoch   1 Batch 1018/1077 - Train Accuracy: 0.8188, Validation Accuracy: 0.8597, Loss: 0.1527
Epoch   1 Batch 1019/1077 - Train Accuracy: 0.8495, Validation Accuracy: 0.8505, Loss: 0.1813
Epoch   1 Batch 1020/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.8548, Loss: 0.1457
Epoch   1 Batch 1021/1077 - Train Accuracy: 0.8538, Validation Accuracy: 0.8501, Loss: 0.1635
Epoch   1 Batch 1022/1077 - Train Accuracy: 0.8783, Validation Accuracy: 0.8473, Loss: 0.1490
Epoch   1 Batch 1023/1077 - Train Accuracy: 0.8597, Validation Accuracy: 0.8565, Loss: 0.1484
Epoch   1 Batch 1024/1077 - Train Accuracy: 0.8262, Validation Accuracy: 0.8540, Loss: 0.1787
Epoch   1 Batch 1025/1077 - Train Accuracy: 0.8449, Validation Accuracy: 0.8540, Loss: 0.1475
Epoch   1 Batch 1026/1077 - Train Accuracy: 0.9345, Validation Accuracy: 0.8594, Loss: 0.1778
Epoch   1 Batch 1027/1077 - Train Accuracy: 0.8691, Validation Accuracy: 0.8480, Loss: 0.1526
Epoch   1 Batch 1028/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.8501, Loss: 0.1396
Epoch   1 Batch 1029/1077 - Train Accuracy: 0.8602, Validation Accuracy: 0.8473, Loss: 0.1595
Epoch   1 Batch 1030/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8516, Loss: 0.1689
Epoch   1 Batch 1031/1077 - Train Accuracy: 0.9042, Validation Accuracy: 0.8512, Loss: 0.1606
Epoch   1 Batch 1032/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8427, Loss: 0.1670
Epoch   1 Batch 1033/1077 - Train Accuracy: 0.8289, Validation Accuracy: 0.8533, Loss: 0.1638
Epoch   1 Batch 1034/1077 - Train Accuracy: 0.8418, Validation Accuracy: 0.8576, Loss: 0.1581
Epoch   1 Batch 1035/1077 - Train Accuracy: 0.9237, Validation Accuracy: 0.8569, Loss: 0.1248
Epoch   1 Batch 1036/1077 - Train Accuracy: 0.8583, Validation Accuracy: 0.8562, Loss: 0.1620
Epoch   1 Batch 1037/1077 - Train Accuracy: 0.8566, Validation Accuracy: 0.8572, Loss: 0.1604
Epoch   1 Batch 1038/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8601, Loss: 0.1763
Epoch   1 Batch 1039/1077 - Train Accuracy: 0.8929, Validation Accuracy: 0.8615, Loss: 0.1667
Epoch   1 Batch 1040/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8651, Loss: 0.1657
Epoch   1 Batch 1041/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8601, Loss: 0.1566
Epoch   1 Batch 1042/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8555, Loss: 0.1515
Epoch   1 Batch 1043/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8665, Loss: 0.1641
Epoch   1 Batch 1044/1077 - Train Accuracy: 0.8254, Validation Accuracy: 0.8633, Loss: 0.1624
Epoch   1 Batch 1045/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8565, Loss: 0.1686
Epoch   1 Batch 1046/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8537, Loss: 0.1362
Epoch   1 Batch 1047/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8477, Loss: 0.1363
Epoch   1 Batch 1048/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8402, Loss: 0.1380
Epoch   1 Batch 1049/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.8253, Loss: 0.1469
Epoch   1 Batch 1050/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8217, Loss: 0.1311
Epoch   1 Batch 1051/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8214, Loss: 0.1594
Epoch   1 Batch 1052/1077 - Train Accuracy: 0.8731, Validation Accuracy: 0.8121, Loss: 0.1505
Epoch   1 Batch 1053/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.8164, Loss: 0.1692
Epoch   1 Batch 1054/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8217, Loss: 0.1649
Epoch   1 Batch 1055/1077 - Train Accuracy: 0.8570, Validation Accuracy: 0.8366, Loss: 0.1598
Epoch   1 Batch 1056/1077 - Train Accuracy: 0.8633, Validation Accuracy: 0.8430, Loss: 0.1510
Epoch   1 Batch 1057/1077 - Train Accuracy: 0.8697, Validation Accuracy: 0.8395, Loss: 0.1593
Epoch   1 Batch 1058/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8434, Loss: 0.1625
Epoch   1 Batch 1059/1077 - Train Accuracy: 0.8347, Validation Accuracy: 0.8438, Loss: 0.1764
Epoch   1 Batch 1060/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8434, Loss: 0.1417
Epoch   1 Batch 1061/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8395, Loss: 0.1622
Epoch   1 Batch 1062/1077 - Train Accuracy: 0.8566, Validation Accuracy: 0.8342, Loss: 0.1489
Epoch   1 Batch 1063/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8366, Loss: 0.1469
Epoch   1 Batch 1064/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8317, Loss: 0.1407
Epoch   1 Batch 1065/1077 - Train Accuracy: 0.8738, Validation Accuracy: 0.8395, Loss: 0.1379
Epoch   1 Batch 1066/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8430, Loss: 0.1362
Epoch   1 Batch 1067/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8448, Loss: 0.1748
Epoch   1 Batch 1068/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8427, Loss: 0.1326
Epoch   1 Batch 1069/1077 - Train Accuracy: 0.8940, Validation Accuracy: 0.8406, Loss: 0.1140
Epoch   1 Batch 1070/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8445, Loss: 0.1452
Epoch   1 Batch 1071/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8473, Loss: 0.1365
Epoch   1 Batch 1072/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8459, Loss: 0.1476
Epoch   1 Batch 1073/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8580, Loss: 0.1615
Epoch   1 Batch 1074/1077 - Train Accuracy: 0.9014, Validation Accuracy: 0.8590, Loss: 0.1627
Epoch   1 Batch 1075/1077 - Train Accuracy: 0.8692, Validation Accuracy: 0.8580, Loss: 0.1738
Epoch   2 Batch    1/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8544, Loss: 0.1345
Epoch   2 Batch    2/1077 - Train Accuracy: 0.8392, Validation Accuracy: 0.8562, Loss: 0.1643
Epoch   2 Batch    3/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8604, Loss: 0.1429
Epoch   2 Batch    4/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8608, Loss: 0.1526
Epoch   2 Batch    5/1077 - Train Accuracy: 0.8391, Validation Accuracy: 0.8540, Loss: 0.1697
Epoch   2 Batch    6/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8597, Loss: 0.1555
Epoch   2 Batch    7/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8555, Loss: 0.1379
Epoch   2 Batch    8/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8505, Loss: 0.1541
Epoch   2 Batch    9/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8548, Loss: 0.1408
Epoch   2 Batch   10/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8494, Loss: 0.1582
Epoch   2 Batch   11/1077 - Train Accuracy: 0.8542, Validation Accuracy: 0.8548, Loss: 0.1567
Epoch   2 Batch   12/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8540, Loss: 0.1554
Epoch   2 Batch   13/1077 - Train Accuracy: 0.8772, Validation Accuracy: 0.8526, Loss: 0.1647
Epoch   2 Batch   14/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8572, Loss: 0.1276
Epoch   2 Batch   15/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8594, Loss: 0.1393
Epoch   2 Batch   16/1077 - Train Accuracy: 0.8570, Validation Accuracy: 0.8572, Loss: 0.1728
Epoch   2 Batch   17/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8565, Loss: 0.1476
Epoch   2 Batch   18/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8608, Loss: 0.1479
Epoch   2 Batch   19/1077 - Train Accuracy: 0.8457, Validation Accuracy: 0.8445, Loss: 0.1476
Epoch   2 Batch   20/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.8505, Loss: 0.1288
Epoch   2 Batch   21/1077 - Train Accuracy: 0.8523, Validation Accuracy: 0.8427, Loss: 0.1634
Epoch   2 Batch   22/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8505, Loss: 0.1529
Epoch   2 Batch   23/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8459, Loss: 0.1518
Epoch   2 Batch   24/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8438, Loss: 0.1409
Epoch   2 Batch   25/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8402, Loss: 0.1382
Epoch   2 Batch   26/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8487, Loss: 0.1548
Epoch   2 Batch   27/1077 - Train Accuracy: 0.8705, Validation Accuracy: 0.8452, Loss: 0.1306
Epoch   2 Batch   28/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8445, Loss: 0.1518
Epoch   2 Batch   29/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8601, Loss: 0.1442
Epoch   2 Batch   30/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8629, Loss: 0.1435
Epoch   2 Batch   31/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8604, Loss: 0.1487
Epoch   2 Batch   32/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8622, Loss: 0.1670
Epoch   2 Batch   33/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.8477, Loss: 0.1247
Epoch   2 Batch   34/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8516, Loss: 0.1396
Epoch   2 Batch   35/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8540, Loss: 0.1271
Epoch   2 Batch   36/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8544, Loss: 0.1481
Epoch   2 Batch   37/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8580, Loss: 0.1345
Epoch   2 Batch   38/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8484, Loss: 0.1900
Epoch   2 Batch   39/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8594, Loss: 0.1586
Epoch   2 Batch   40/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8509, Loss: 0.1394
Epoch   2 Batch   41/1077 - Train Accuracy: 0.8531, Validation Accuracy: 0.8430, Loss: 0.1478
Epoch   2 Batch   42/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8491, Loss: 0.1660
Epoch   2 Batch   43/1077 - Train Accuracy: 0.8919, Validation Accuracy: 0.8505, Loss: 0.1290
Epoch   2 Batch   44/1077 - Train Accuracy: 0.8808, Validation Accuracy: 0.8487, Loss: 0.1503
Epoch   2 Batch   45/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8540, Loss: 0.1462
Epoch   2 Batch   46/1077 - Train Accuracy: 0.8803, Validation Accuracy: 0.8590, Loss: 0.1616
Epoch   2 Batch   47/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.8555, Loss: 0.1633
Epoch   2 Batch   48/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8601, Loss: 0.1841
Epoch   2 Batch   49/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8558, Loss: 0.1718
Epoch   2 Batch   50/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8558, Loss: 0.1449
Epoch   2 Batch   51/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.8512, Loss: 0.1474
Epoch   2 Batch   52/1077 - Train Accuracy: 0.8648, Validation Accuracy: 0.8498, Loss: 0.1600
Epoch   2 Batch   53/1077 - Train Accuracy: 0.8623, Validation Accuracy: 0.8487, Loss: 0.1662
Epoch   2 Batch   54/1077 - Train Accuracy: 0.8473, Validation Accuracy: 0.8445, Loss: 0.1900
Epoch   2 Batch   55/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8452, Loss: 0.1340
Epoch   2 Batch   56/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.8569, Loss: 0.1432
Epoch   2 Batch   57/1077 - Train Accuracy: 0.8388, Validation Accuracy: 0.8544, Loss: 0.1341
Epoch   2 Batch   58/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8615, Loss: 0.1413
Epoch   2 Batch   59/1077 - Train Accuracy: 0.8647, Validation Accuracy: 0.8604, Loss: 0.1368
Epoch   2 Batch   60/1077 - Train Accuracy: 0.8787, Validation Accuracy: 0.8608, Loss: 0.1355
Epoch   2 Batch   61/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8761, Loss: 0.1752
Epoch   2 Batch   62/1077 - Train Accuracy: 0.8466, Validation Accuracy: 0.8707, Loss: 0.1561
Epoch   2 Batch   63/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8558, Loss: 0.1204
Epoch   2 Batch   64/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8540, Loss: 0.1432
Epoch   2 Batch   65/1077 - Train Accuracy: 0.8294, Validation Accuracy: 0.8480, Loss: 0.1522
Epoch   2 Batch   66/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8430, Loss: 0.1212
Epoch   2 Batch   67/1077 - Train Accuracy: 0.8538, Validation Accuracy: 0.8388, Loss: 0.1447
Epoch   2 Batch   68/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8391, Loss: 0.1643
Epoch   2 Batch   69/1077 - Train Accuracy: 0.8371, Validation Accuracy: 0.8491, Loss: 0.1860
Epoch   2 Batch   70/1077 - Train Accuracy: 0.8647, Validation Accuracy: 0.8548, Loss: 0.1734
Epoch   2 Batch   71/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8551, Loss: 0.1162
Epoch   2 Batch   72/1077 - Train Accuracy: 0.8578, Validation Accuracy: 0.8462, Loss: 0.1568
Epoch   2 Batch   73/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8409, Loss: 0.1436
Epoch   2 Batch   74/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8459, Loss: 0.1373
Epoch   2 Batch   75/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8420, Loss: 0.1650
Epoch   2 Batch   76/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.8384, Loss: 0.1274
Epoch   2 Batch   77/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8349, Loss: 0.1691
Epoch   2 Batch   78/1077 - Train Accuracy: 0.8717, Validation Accuracy: 0.8342, Loss: 0.1505
Epoch   2 Batch   79/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8391, Loss: 0.1582
Epoch   2 Batch   80/1077 - Train Accuracy: 0.9008, Validation Accuracy: 0.8441, Loss: 0.1357
Epoch   2 Batch   81/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8445, Loss: 0.1297
Epoch   2 Batch   82/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8540, Loss: 0.1354
Epoch   2 Batch   83/1077 - Train Accuracy: 0.9071, Validation Accuracy: 0.8473, Loss: 0.1400
Epoch   2 Batch   84/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8452, Loss: 0.1422
Epoch   2 Batch   85/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.8452, Loss: 0.1485
Epoch   2 Batch   86/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8398, Loss: 0.1463
Epoch   2 Batch   87/1077 - Train Accuracy: 0.8738, Validation Accuracy: 0.8452, Loss: 0.1718
Epoch   2 Batch   88/1077 - Train Accuracy: 0.8602, Validation Accuracy: 0.8473, Loss: 0.1491
Epoch   2 Batch   89/1077 - Train Accuracy: 0.8449, Validation Accuracy: 0.8459, Loss: 0.1642
Epoch   2 Batch   90/1077 - Train Accuracy: 0.8633, Validation Accuracy: 0.8480, Loss: 0.1576
Epoch   2 Batch   91/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8473, Loss: 0.1271
Epoch   2 Batch   92/1077 - Train Accuracy: 0.8720, Validation Accuracy: 0.8480, Loss: 0.1484
Epoch   2 Batch   93/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8484, Loss: 0.1529
Epoch   2 Batch   94/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8491, Loss: 0.1354
Epoch   2 Batch   95/1077 - Train Accuracy: 0.8899, Validation Accuracy: 0.8477, Loss: 0.1709
Epoch   2 Batch   96/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.8466, Loss: 0.1661
Epoch   2 Batch   97/1077 - Train Accuracy: 0.8309, Validation Accuracy: 0.8455, Loss: 0.1536
Epoch   2 Batch   98/1077 - Train Accuracy: 0.8791, Validation Accuracy: 0.8558, Loss: 0.1643
Epoch   2 Batch   99/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8494, Loss: 0.1520
Epoch   2 Batch  100/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.8462, Loss: 0.1471
Epoch   2 Batch  101/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8416, Loss: 0.1284
Epoch   2 Batch  102/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8423, Loss: 0.1364
Epoch   2 Batch  103/1077 - Train Accuracy: 0.8705, Validation Accuracy: 0.8420, Loss: 0.1505
Epoch   2 Batch  104/1077 - Train Accuracy: 0.8771, Validation Accuracy: 0.8452, Loss: 0.1562
Epoch   2 Batch  105/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.8462, Loss: 0.1431
Epoch   2 Batch  106/1077 - Train Accuracy: 0.8701, Validation Accuracy: 0.8462, Loss: 0.1772
Epoch   2 Batch  107/1077 - Train Accuracy: 0.8501, Validation Accuracy: 0.8519, Loss: 0.1511
Epoch   2 Batch  108/1077 - Train Accuracy: 0.8626, Validation Accuracy: 0.8509, Loss: 0.1328
Epoch   2 Batch  109/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8434, Loss: 0.1507
Epoch   2 Batch  110/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8530, Loss: 0.1367
Epoch   2 Batch  111/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8498, Loss: 0.1530
Epoch   2 Batch  112/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.8484, Loss: 0.1525
Epoch   2 Batch  113/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8612, Loss: 0.1503
Epoch   2 Batch  114/1077 - Train Accuracy: 0.9178, Validation Accuracy: 0.8608, Loss: 0.1258
Epoch   2 Batch  115/1077 - Train Accuracy: 0.8715, Validation Accuracy: 0.8597, Loss: 0.1694
Epoch   2 Batch  116/1077 - Train Accuracy: 0.8391, Validation Accuracy: 0.8601, Loss: 0.1576
Epoch   2 Batch  117/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8654, Loss: 0.1288
Epoch   2 Batch  118/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8512, Loss: 0.1528
Epoch   2 Batch  119/1077 - Train Accuracy: 0.8691, Validation Accuracy: 0.8526, Loss: 0.1445
Epoch   2 Batch  120/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8537, Loss: 0.1592
Epoch   2 Batch  121/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8480, Loss: 0.1418
Epoch   2 Batch  122/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8587, Loss: 0.1373
Epoch   2 Batch  123/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8580, Loss: 0.1232
Epoch   2 Batch  124/1077 - Train Accuracy: 0.8617, Validation Accuracy: 0.8629, Loss: 0.1726
Epoch   2 Batch  125/1077 - Train Accuracy: 0.8955, Validation Accuracy: 0.8608, Loss: 0.1518
Epoch   2 Batch  126/1077 - Train Accuracy: 0.8880, Validation Accuracy: 0.8558, Loss: 0.1394
Epoch   2 Batch  127/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8587, Loss: 0.1335
Epoch   2 Batch  128/1077 - Train Accuracy: 0.9040, Validation Accuracy: 0.8544, Loss: 0.1311
Epoch   2 Batch  129/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8423, Loss: 0.1506
Epoch   2 Batch  130/1077 - Train Accuracy: 0.8795, Validation Accuracy: 0.8580, Loss: 0.1404
Epoch   2 Batch  131/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8402, Loss: 0.1465
Epoch   2 Batch  132/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8331, Loss: 0.1526
Epoch   2 Batch  133/1077 - Train Accuracy: 0.8614, Validation Accuracy: 0.8306, Loss: 0.1329
Epoch   2 Batch  134/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8342, Loss: 0.1364
Epoch   2 Batch  135/1077 - Train Accuracy: 0.8606, Validation Accuracy: 0.8388, Loss: 0.1528
Epoch   2 Batch  136/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8413, Loss: 0.1380
Epoch   2 Batch  137/1077 - Train Accuracy: 0.8810, Validation Accuracy: 0.8377, Loss: 0.1178
Epoch   2 Batch  138/1077 - Train Accuracy: 0.8488, Validation Accuracy: 0.8441, Loss: 0.1255
Epoch   2 Batch  139/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8448, Loss: 0.1475
Epoch   2 Batch  140/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8413, Loss: 0.1463
Epoch   2 Batch  141/1077 - Train Accuracy: 0.8570, Validation Accuracy: 0.8335, Loss: 0.1588
Epoch   2 Batch  142/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8338, Loss: 0.1270
Epoch   2 Batch  143/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8338, Loss: 0.1411
Epoch   2 Batch  144/1077 - Train Accuracy: 0.8470, Validation Accuracy: 0.8434, Loss: 0.1603
Epoch   2 Batch  145/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8512, Loss: 0.1501
Epoch   2 Batch  146/1077 - Train Accuracy: 0.8717, Validation Accuracy: 0.8636, Loss: 0.1660
Epoch   2 Batch  147/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8612, Loss: 0.1446
Epoch   2 Batch  148/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8487, Loss: 0.1540
Epoch   2 Batch  149/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.8594, Loss: 0.1386
Epoch   2 Batch  150/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8562, Loss: 0.1499
Epoch   2 Batch  151/1077 - Train Accuracy: 0.8776, Validation Accuracy: 0.8466, Loss: 0.1420
Epoch   2 Batch  152/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8516, Loss: 0.1757
Epoch   2 Batch  153/1077 - Train Accuracy: 0.8406, Validation Accuracy: 0.8377, Loss: 0.1571
Epoch   2 Batch  154/1077 - Train Accuracy: 0.8894, Validation Accuracy: 0.8366, Loss: 0.1445
Epoch   2 Batch  155/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8384, Loss: 0.1411
Epoch   2 Batch  156/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8338, Loss: 0.1402
Epoch   2 Batch  157/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8391, Loss: 0.1260
Epoch   2 Batch  158/1077 - Train Accuracy: 0.8642, Validation Accuracy: 0.8494, Loss: 0.1447
Epoch   2 Batch  159/1077 - Train Accuracy: 0.9048, Validation Accuracy: 0.8572, Loss: 0.1205
Epoch   2 Batch  160/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8622, Loss: 0.1207
Epoch   2 Batch  161/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8622, Loss: 0.1383
Epoch   2 Batch  162/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8583, Loss: 0.1590
Epoch   2 Batch  163/1077 - Train Accuracy: 0.8882, Validation Accuracy: 0.8533, Loss: 0.1496
Epoch   2 Batch  164/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8530, Loss: 0.1413
Epoch   2 Batch  165/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8523, Loss: 0.1284
Epoch   2 Batch  166/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.8612, Loss: 0.1565
Epoch   2 Batch  167/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8590, Loss: 0.1461
Epoch   2 Batch  168/1077 - Train Accuracy: 0.8536, Validation Accuracy: 0.8544, Loss: 0.1601
Epoch   2 Batch  169/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8530, Loss: 0.1652
Epoch   2 Batch  170/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.8512, Loss: 0.1508
Epoch   2 Batch  171/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8484, Loss: 0.1423
Epoch   2 Batch  172/1077 - Train Accuracy: 0.9144, Validation Accuracy: 0.8562, Loss: 0.1328
Epoch   2 Batch  173/1077 - Train Accuracy: 0.8701, Validation Accuracy: 0.8569, Loss: 0.1555
Epoch   2 Batch  174/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8523, Loss: 0.1442
Epoch   2 Batch  175/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8501, Loss: 0.1533
Epoch   2 Batch  176/1077 - Train Accuracy: 0.8727, Validation Accuracy: 0.8438, Loss: 0.1379
Epoch   2 Batch  177/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8583, Loss: 0.1614
Epoch   2 Batch  178/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8587, Loss: 0.1616
Epoch   2 Batch  179/1077 - Train Accuracy: 0.8779, Validation Accuracy: 0.8540, Loss: 0.1524
Epoch   2 Batch  180/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8583, Loss: 0.1412
Epoch   2 Batch  181/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8526, Loss: 0.1634
Epoch   2 Batch  182/1077 - Train Accuracy: 0.8739, Validation Accuracy: 0.8540, Loss: 0.1680
Epoch   2 Batch  183/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8533, Loss: 0.1459
Epoch   2 Batch  184/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8647, Loss: 0.1288
Epoch   2 Batch  185/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8594, Loss: 0.1433
Epoch   2 Batch  186/1077 - Train Accuracy: 0.8939, Validation Accuracy: 0.8590, Loss: 0.1505
Epoch   2 Batch  187/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8537, Loss: 0.1392
Epoch   2 Batch  188/1077 - Train Accuracy: 0.8336, Validation Accuracy: 0.8540, Loss: 0.1575
Epoch   2 Batch  189/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8466, Loss: 0.1459
Epoch   2 Batch  190/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8498, Loss: 0.1427
Epoch   2 Batch  191/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8572, Loss: 0.1254
Epoch   2 Batch  192/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8594, Loss: 0.1574
Epoch   2 Batch  193/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8658, Loss: 0.1461
Epoch   2 Batch  194/1077 - Train Accuracy: 0.8947, Validation Accuracy: 0.8768, Loss: 0.1196
Epoch   2 Batch  195/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8803, Loss: 0.1207
Epoch   2 Batch  196/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8814, Loss: 0.1344
Epoch   2 Batch  197/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8718, Loss: 0.1659
Epoch   2 Batch  198/1077 - Train Accuracy: 0.9089, Validation Accuracy: 0.8693, Loss: 0.1359
Epoch   2 Batch  199/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8693, Loss: 0.1328
Epoch   2 Batch  200/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8690, Loss: 0.1519
Epoch   2 Batch  201/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8761, Loss: 0.1363
Epoch   2 Batch  202/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8651, Loss: 0.1487
Epoch   2 Batch  203/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.8633, Loss: 0.1357
Epoch   2 Batch  204/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8686, Loss: 0.1651
Epoch   2 Batch  205/1077 - Train Accuracy: 0.8094, Validation Accuracy: 0.8654, Loss: 0.1593
Epoch   2 Batch  206/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8622, Loss: 0.1298
Epoch   2 Batch  207/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.8612, Loss: 0.1495
Epoch   2 Batch  208/1077 - Train Accuracy: 0.9003, Validation Accuracy: 0.8580, Loss: 0.1325
Epoch   2 Batch  209/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8533, Loss: 0.1218
Epoch   2 Batch  210/1077 - Train Accuracy: 0.8717, Validation Accuracy: 0.8594, Loss: 0.1577
Epoch   2 Batch  211/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8675, Loss: 0.1325
Epoch   2 Batch  212/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8700, Loss: 0.1296
Epoch   2 Batch  213/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8583, Loss: 0.1333
Epoch   2 Batch  214/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8565, Loss: 0.1354
Epoch   2 Batch  215/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8572, Loss: 0.1484
Epoch   2 Batch  216/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8604, Loss: 0.1459
Epoch   2 Batch  217/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8565, Loss: 0.1312
Epoch   2 Batch  218/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8558, Loss: 0.1690
Epoch   2 Batch  219/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8512, Loss: 0.1294
Epoch   2 Batch  220/1077 - Train Accuracy: 0.8877, Validation Accuracy: 0.8526, Loss: 0.1410
Epoch   2 Batch  221/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8501, Loss: 0.1449
Epoch   2 Batch  222/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8537, Loss: 0.1485
Epoch   2 Batch  223/1077 - Train Accuracy: 0.9096, Validation Accuracy: 0.8448, Loss: 0.1320
Epoch   2 Batch  224/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8601, Loss: 0.1490
Epoch   2 Batch  225/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8651, Loss: 0.1475
Epoch   2 Batch  226/1077 - Train Accuracy: 0.8562, Validation Accuracy: 0.8729, Loss: 0.1328
Epoch   2 Batch  227/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8647, Loss: 0.1840
Epoch   2 Batch  228/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8597, Loss: 0.1289
Epoch   2 Batch  229/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8590, Loss: 0.1486
Epoch   2 Batch  230/1077 - Train Accuracy: 0.8728, Validation Accuracy: 0.8548, Loss: 0.1456
Epoch   2 Batch  231/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8551, Loss: 0.1684
Epoch   2 Batch  232/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8555, Loss: 0.1368
Epoch   2 Batch  233/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8452, Loss: 0.1864
Epoch   2 Batch  234/1077 - Train Accuracy: 0.8545, Validation Accuracy: 0.8548, Loss: 0.1553
Epoch   2 Batch  235/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8629, Loss: 0.1473
Epoch   2 Batch  236/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8643, Loss: 0.1609
Epoch   2 Batch  237/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8665, Loss: 0.1320
Epoch   2 Batch  238/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8594, Loss: 0.1355
Epoch   2 Batch  239/1077 - Train Accuracy: 0.8917, Validation Accuracy: 0.8640, Loss: 0.1185
Epoch   2 Batch  240/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8658, Loss: 0.1465
Epoch   2 Batch  241/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8672, Loss: 0.1244
Epoch   2 Batch  242/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8647, Loss: 0.1402
Epoch   2 Batch  243/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8643, Loss: 0.1430
Epoch   2 Batch  244/1077 - Train Accuracy: 0.8952, Validation Accuracy: 0.8725, Loss: 0.1375
Epoch   2 Batch  245/1077 - Train Accuracy: 0.8862, Validation Accuracy: 0.8732, Loss: 0.1312
Epoch   2 Batch  246/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8778, Loss: 0.1305
Epoch   2 Batch  247/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8661, Loss: 0.1323
Epoch   2 Batch  248/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8640, Loss: 0.1460
Epoch   2 Batch  249/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8714, Loss: 0.1424
Epoch   2 Batch  250/1077 - Train Accuracy: 0.8640, Validation Accuracy: 0.8714, Loss: 0.1405
Epoch   2 Batch  251/1077 - Train Accuracy: 0.8761, Validation Accuracy: 0.8803, Loss: 0.1431
Epoch   2 Batch  252/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8739, Loss: 0.1600
Epoch   2 Batch  253/1077 - Train Accuracy: 0.8558, Validation Accuracy: 0.8793, Loss: 0.1429
Epoch   2 Batch  254/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8796, Loss: 0.1588
Epoch   2 Batch  255/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8622, Loss: 0.1529
Epoch   2 Batch  256/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8626, Loss: 0.1552
Epoch   2 Batch  257/1077 - Train Accuracy: 0.8504, Validation Accuracy: 0.8704, Loss: 0.1421
Epoch   2 Batch  258/1077 - Train Accuracy: 0.8947, Validation Accuracy: 0.8690, Loss: 0.1421
Epoch   2 Batch  259/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8640, Loss: 0.1388
Epoch   2 Batch  260/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.8640, Loss: 0.1141
Epoch   2 Batch  261/1077 - Train Accuracy: 0.8917, Validation Accuracy: 0.8672, Loss: 0.1430
Epoch   2 Batch  262/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8658, Loss: 0.1352
Epoch   2 Batch  263/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.8619, Loss: 0.1240
Epoch   2 Batch  264/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8608, Loss: 0.1484
Epoch   2 Batch  265/1077 - Train Accuracy: 0.8625, Validation Accuracy: 0.8604, Loss: 0.1408
Epoch   2 Batch  266/1077 - Train Accuracy: 0.8285, Validation Accuracy: 0.8555, Loss: 0.1481
Epoch   2 Batch  267/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8576, Loss: 0.1182
Epoch   2 Batch  268/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8523, Loss: 0.1415
Epoch   2 Batch  269/1077 - Train Accuracy: 0.8635, Validation Accuracy: 0.8445, Loss: 0.1630
Epoch   2 Batch  270/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.8505, Loss: 0.1519
Epoch   2 Batch  271/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8505, Loss: 0.1313
Epoch   2 Batch  272/1077 - Train Accuracy: 0.8635, Validation Accuracy: 0.8445, Loss: 0.1851
Epoch   2 Batch  273/1077 - Train Accuracy: 0.8962, Validation Accuracy: 0.8594, Loss: 0.1277
Epoch   2 Batch  274/1077 - Train Accuracy: 0.9107, Validation Accuracy: 0.8398, Loss: 0.1232
Epoch   2 Batch  275/1077 - Train Accuracy: 0.8687, Validation Accuracy: 0.8327, Loss: 0.1389
Epoch   2 Batch  276/1077 - Train Accuracy: 0.8520, Validation Accuracy: 0.8420, Loss: 0.1713
Epoch   2 Batch  277/1077 - Train Accuracy: 0.9182, Validation Accuracy: 0.8406, Loss: 0.1265
Epoch   2 Batch  278/1077 - Train Accuracy: 0.8195, Validation Accuracy: 0.8420, Loss: 0.1746
Epoch   2 Batch  279/1077 - Train Accuracy: 0.8422, Validation Accuracy: 0.8423, Loss: 0.1576
Epoch   2 Batch  280/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8384, Loss: 0.1466
Epoch   2 Batch  281/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8455, Loss: 0.1481
Epoch   2 Batch  282/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.8558, Loss: 0.1568
Epoch   2 Batch  283/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8540, Loss: 0.1612
Epoch   2 Batch  284/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.8636, Loss: 0.1402
Epoch   2 Batch  285/1077 - Train Accuracy: 0.8772, Validation Accuracy: 0.8622, Loss: 0.1318
Epoch   2 Batch  286/1077 - Train Accuracy: 0.8962, Validation Accuracy: 0.8661, Loss: 0.1296
Epoch   2 Batch  287/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8601, Loss: 0.1516
Epoch   2 Batch  288/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8739, Loss: 0.1379
Epoch   2 Batch  289/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8793, Loss: 0.1330
Epoch   2 Batch  290/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8700, Loss: 0.1818
Epoch   2 Batch  291/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8580, Loss: 0.1643
Epoch   2 Batch  292/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8679, Loss: 0.1490
Epoch   2 Batch  293/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8668, Loss: 0.1524
Epoch   2 Batch  294/1077 - Train Accuracy: 0.8963, Validation Accuracy: 0.8729, Loss: 0.1490
Epoch   2 Batch  295/1077 - Train Accuracy: 0.8421, Validation Accuracy: 0.8778, Loss: 0.1504
Epoch   2 Batch  296/1077 - Train Accuracy: 0.8932, Validation Accuracy: 0.8789, Loss: 0.1280
Epoch   2 Batch  297/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8803, Loss: 0.1587
Epoch   2 Batch  298/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8707, Loss: 0.1605
Epoch   2 Batch  299/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8661, Loss: 0.1465
Epoch   2 Batch  300/1077 - Train Accuracy: 0.9182, Validation Accuracy: 0.8647, Loss: 0.1362
Epoch   2 Batch  301/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8629, Loss: 0.1221
Epoch   2 Batch  302/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8587, Loss: 0.1458
Epoch   2 Batch  303/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8629, Loss: 0.1587
Epoch   2 Batch  304/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.8629, Loss: 0.1270
Epoch   2 Batch  305/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8590, Loss: 0.1293
Epoch   2 Batch  306/1077 - Train Accuracy: 0.8888, Validation Accuracy: 0.8551, Loss: 0.1398
Epoch   2 Batch  307/1077 - Train Accuracy: 0.8679, Validation Accuracy: 0.8516, Loss: 0.1318
Epoch   2 Batch  308/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8714, Loss: 0.1582
Epoch   2 Batch  309/1077 - Train Accuracy: 0.8999, Validation Accuracy: 0.8651, Loss: 0.1248
Epoch   2 Batch  310/1077 - Train Accuracy: 0.8602, Validation Accuracy: 0.8704, Loss: 0.1442
Epoch   2 Batch  311/1077 - Train Accuracy: 0.8810, Validation Accuracy: 0.8679, Loss: 0.1327
Epoch   2 Batch  312/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8647, Loss: 0.1564
Epoch   2 Batch  313/1077 - Train Accuracy: 0.8625, Validation Accuracy: 0.8718, Loss: 0.1169
Epoch   2 Batch  314/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8647, Loss: 0.1427
Epoch   2 Batch  315/1077 - Train Accuracy: 0.9260, Validation Accuracy: 0.8626, Loss: 0.1201
Epoch   2 Batch  316/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8608, Loss: 0.1331
Epoch   2 Batch  317/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8612, Loss: 0.1715
Epoch   2 Batch  318/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8594, Loss: 0.1443
Epoch   2 Batch  319/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8633, Loss: 0.1500
Epoch   2 Batch  320/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8636, Loss: 0.1513
Epoch   2 Batch  321/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.8683, Loss: 0.1228
Epoch   2 Batch  322/1077 - Train Accuracy: 0.8661, Validation Accuracy: 0.8750, Loss: 0.1257
Epoch   2 Batch  323/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8849, Loss: 0.1390
Epoch   2 Batch  324/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8810, Loss: 0.1283
Epoch   2 Batch  325/1077 - Train Accuracy: 0.8690, Validation Accuracy: 0.8828, Loss: 0.1387
Epoch   2 Batch  326/1077 - Train Accuracy: 0.8843, Validation Accuracy: 0.8711, Loss: 0.1319
Epoch   2 Batch  327/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8714, Loss: 0.1481
Epoch   2 Batch  328/1077 - Train Accuracy: 0.8783, Validation Accuracy: 0.8647, Loss: 0.1436
Epoch   2 Batch  329/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8587, Loss: 0.1493
Epoch   2 Batch  330/1077 - Train Accuracy: 0.8648, Validation Accuracy: 0.8512, Loss: 0.1391
Epoch   2 Batch  331/1077 - Train Accuracy: 0.8931, Validation Accuracy: 0.8498, Loss: 0.1413
Epoch   2 Batch  332/1077 - Train Accuracy: 0.8858, Validation Accuracy: 0.8391, Loss: 0.1146
Epoch   2 Batch  333/1077 - Train Accuracy: 0.9186, Validation Accuracy: 0.8480, Loss: 0.1357
Epoch   2 Batch  334/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8487, Loss: 0.1355
Epoch   2 Batch  335/1077 - Train Accuracy: 0.9204, Validation Accuracy: 0.8477, Loss: 0.1284
Epoch   2 Batch  336/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8594, Loss: 0.1828
Epoch   2 Batch  337/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8626, Loss: 0.1374
Epoch   2 Batch  338/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8636, Loss: 0.1509
Epoch   2 Batch  339/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8604, Loss: 0.1242
Epoch   2 Batch  340/1077 - Train Accuracy: 0.8935, Validation Accuracy: 0.8505, Loss: 0.1338
Epoch   2 Batch  341/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8558, Loss: 0.1676
Epoch   2 Batch  342/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8622, Loss: 0.1101
Epoch   2 Batch  343/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8587, Loss: 0.1363
Epoch   2 Batch  344/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8643, Loss: 0.1378
Epoch   2 Batch  345/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8654, Loss: 0.1433
Epoch   2 Batch  346/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8558, Loss: 0.1426
Epoch   2 Batch  347/1077 - Train Accuracy: 0.9360, Validation Accuracy: 0.8555, Loss: 0.1255
Epoch   2 Batch  348/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8640, Loss: 0.1375
Epoch   2 Batch  349/1077 - Train Accuracy: 0.8379, Validation Accuracy: 0.8533, Loss: 0.1433
Epoch   2 Batch  350/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8484, Loss: 0.1440
Epoch   2 Batch  351/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8441, Loss: 0.1468
Epoch   2 Batch  352/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8384, Loss: 0.1250
Epoch   2 Batch  353/1077 - Train Accuracy: 0.8248, Validation Accuracy: 0.8395, Loss: 0.1646
Epoch   2 Batch  354/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8406, Loss: 0.1531
Epoch   2 Batch  355/1077 - Train Accuracy: 0.8542, Validation Accuracy: 0.8423, Loss: 0.1353
Epoch   2 Batch  356/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8693, Loss: 0.1414
Epoch   2 Batch  357/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8654, Loss: 0.1472
Epoch   2 Batch  358/1077 - Train Accuracy: 0.8224, Validation Accuracy: 0.8544, Loss: 0.1729
Epoch   2 Batch  359/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8636, Loss: 0.1479
Epoch   2 Batch  360/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8622, Loss: 0.1388
Epoch   2 Batch  361/1077 - Train Accuracy: 0.9169, Validation Accuracy: 0.8633, Loss: 0.1348
Epoch   2 Batch  362/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8597, Loss: 0.1490
Epoch   2 Batch  363/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8647, Loss: 0.1445
Epoch   2 Batch  364/1077 - Train Accuracy: 0.8715, Validation Accuracy: 0.8643, Loss: 0.1668
Epoch   2 Batch  365/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8686, Loss: 0.1241
Epoch   2 Batch  366/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8690, Loss: 0.1437
Epoch   2 Batch  367/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8580, Loss: 0.1306
Epoch   2 Batch  368/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8594, Loss: 0.1302
Epoch   2 Batch  369/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8615, Loss: 0.1480
Epoch   2 Batch  370/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8477, Loss: 0.1317
Epoch   2 Batch  371/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8516, Loss: 0.1218
Epoch   2 Batch  372/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8658, Loss: 0.1218
Epoch   2 Batch  373/1077 - Train Accuracy: 0.8802, Validation Accuracy: 0.8668, Loss: 0.1211
Epoch   2 Batch  374/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8739, Loss: 0.1415
Epoch   2 Batch  375/1077 - Train Accuracy: 0.9119, Validation Accuracy: 0.8743, Loss: 0.1393
Epoch   2 Batch  376/1077 - Train Accuracy: 0.8881, Validation Accuracy: 0.8789, Loss: 0.1247
Epoch   2 Batch  377/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8732, Loss: 0.1287
Epoch   2 Batch  378/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8739, Loss: 0.1197
Epoch   2 Batch  379/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8675, Loss: 0.1523
Epoch   2 Batch  380/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8800, Loss: 0.1330
Epoch   2 Batch  381/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8849, Loss: 0.1606
Epoch   2 Batch  382/1077 - Train Accuracy: 0.8981, Validation Accuracy: 0.8885, Loss: 0.1703
Epoch   2 Batch  383/1077 - Train Accuracy: 0.8899, Validation Accuracy: 0.8860, Loss: 0.1203
Epoch   2 Batch  384/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.8903, Loss: 0.1334
Epoch   2 Batch  385/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8924, Loss: 0.1187
Epoch   2 Batch  386/1077 - Train Accuracy: 0.8958, Validation Accuracy: 0.8860, Loss: 0.1320
Epoch   2 Batch  387/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.8810, Loss: 0.1292
Epoch   2 Batch  388/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8800, Loss: 0.1317
Epoch   2 Batch  389/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8796, Loss: 0.1245
Epoch   2 Batch  390/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8786, Loss: 0.1598
Epoch   2 Batch  391/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8661, Loss: 0.1448
Epoch   2 Batch  392/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8661, Loss: 0.1456
Epoch   2 Batch  393/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8722, Loss: 0.1254
Epoch   2 Batch  394/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8651, Loss: 0.1353
Epoch   2 Batch  395/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8654, Loss: 0.1318
Epoch   2 Batch  396/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8654, Loss: 0.1272
Epoch   2 Batch  397/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8640, Loss: 0.1321
Epoch   2 Batch  398/1077 - Train Accuracy: 0.8808, Validation Accuracy: 0.8658, Loss: 0.1451
Epoch   2 Batch  399/1077 - Train Accuracy: 0.8405, Validation Accuracy: 0.8565, Loss: 0.1413
Epoch   2 Batch  400/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8580, Loss: 0.1509
Epoch   2 Batch  401/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8544, Loss: 0.1296
Epoch   2 Batch  402/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8505, Loss: 0.1215
Epoch   2 Batch  403/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8558, Loss: 0.1403
Epoch   2 Batch  404/1077 - Train Accuracy: 0.8761, Validation Accuracy: 0.8569, Loss: 0.1235
Epoch   2 Batch  405/1077 - Train Accuracy: 0.8771, Validation Accuracy: 0.8587, Loss: 0.1292
Epoch   2 Batch  406/1077 - Train Accuracy: 0.9046, Validation Accuracy: 0.8619, Loss: 0.1230
Epoch   2 Batch  407/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8587, Loss: 0.1712
Epoch   2 Batch  408/1077 - Train Accuracy: 0.8551, Validation Accuracy: 0.8597, Loss: 0.1222
Epoch   2 Batch  409/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8704, Loss: 0.1459
Epoch   2 Batch  410/1077 - Train Accuracy: 0.8618, Validation Accuracy: 0.8690, Loss: 0.1426
Epoch   2 Batch  411/1077 - Train Accuracy: 0.8917, Validation Accuracy: 0.8743, Loss: 0.1417
Epoch   2 Batch  412/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.8718, Loss: 0.1183
Epoch   2 Batch  413/1077 - Train Accuracy: 0.8508, Validation Accuracy: 0.8729, Loss: 0.1386
Epoch   2 Batch  414/1077 - Train Accuracy: 0.8602, Validation Accuracy: 0.8725, Loss: 0.1368
Epoch   2 Batch  415/1077 - Train Accuracy: 0.8657, Validation Accuracy: 0.8690, Loss: 0.1518
Epoch   2 Batch  416/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8750, Loss: 0.1377
Epoch   2 Batch  417/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8700, Loss: 0.1767
Epoch   2 Batch  418/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8658, Loss: 0.1223
Epoch   2 Batch  419/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8633, Loss: 0.1451
Epoch   2 Batch  420/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8587, Loss: 0.1288
Epoch   2 Batch  421/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8587, Loss: 0.1581
Epoch   2 Batch  422/1077 - Train Accuracy: 0.8638, Validation Accuracy: 0.8583, Loss: 0.1254
Epoch   2 Batch  423/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.8551, Loss: 0.1455
Epoch   2 Batch  424/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8594, Loss: 0.1397
Epoch   2 Batch  425/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8576, Loss: 0.1117
Epoch   2 Batch  426/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8636, Loss: 0.1628
Epoch   2 Batch  427/1077 - Train Accuracy: 0.8865, Validation Accuracy: 0.8654, Loss: 0.1297
Epoch   2 Batch  428/1077 - Train Accuracy: 0.9267, Validation Accuracy: 0.8704, Loss: 0.1113
Epoch   2 Batch  429/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8658, Loss: 0.1313
Epoch   2 Batch  430/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8700, Loss: 0.1227
Epoch   2 Batch  431/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8732, Loss: 0.1223
Epoch   2 Batch  432/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8725, Loss: 0.1443
Epoch   2 Batch  433/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.8587, Loss: 0.1392
Epoch   2 Batch  434/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8590, Loss: 0.1284
Epoch   2 Batch  435/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8544, Loss: 0.1480
Epoch   2 Batch  436/1077 - Train Accuracy: 0.8713, Validation Accuracy: 0.8601, Loss: 0.1456
Epoch   2 Batch  437/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8604, Loss: 0.1190
Epoch   2 Batch  438/1077 - Train Accuracy: 0.8387, Validation Accuracy: 0.8551, Loss: 0.1413
Epoch   2 Batch  439/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8548, Loss: 0.1461
Epoch   2 Batch  440/1077 - Train Accuracy: 0.8473, Validation Accuracy: 0.8580, Loss: 0.1547
Epoch   2 Batch  441/1077 - Train Accuracy: 0.8340, Validation Accuracy: 0.8558, Loss: 0.1400
Epoch   2 Batch  442/1077 - Train Accuracy: 0.8635, Validation Accuracy: 0.8526, Loss: 0.1384
Epoch   2 Batch  443/1077 - Train Accuracy: 0.9014, Validation Accuracy: 0.8487, Loss: 0.1192
Epoch   2 Batch  444/1077 - Train Accuracy: 0.8523, Validation Accuracy: 0.8501, Loss: 0.1266
Epoch   2 Batch  445/1077 - Train Accuracy: 0.8322, Validation Accuracy: 0.8420, Loss: 0.1368
Epoch   2 Batch  446/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8438, Loss: 0.1127
Epoch   2 Batch  447/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8448, Loss: 0.1315
Epoch   2 Batch  448/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8356, Loss: 0.1511
Epoch   2 Batch  449/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8398, Loss: 0.1431
Epoch   2 Batch  450/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8420, Loss: 0.1342
Epoch   2 Batch  451/1077 - Train Accuracy: 0.8728, Validation Accuracy: 0.8501, Loss: 0.1347
Epoch   2 Batch  452/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8533, Loss: 0.1279
Epoch   2 Batch  453/1077 - Train Accuracy: 0.8847, Validation Accuracy: 0.8526, Loss: 0.1459
Epoch   2 Batch  454/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8434, Loss: 0.1279
Epoch   2 Batch  455/1077 - Train Accuracy: 0.8896, Validation Accuracy: 0.8562, Loss: 0.1438
Epoch   2 Batch  456/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8629, Loss: 0.1425
Epoch   2 Batch  457/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8704, Loss: 0.1122
Epoch   2 Batch  458/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8679, Loss: 0.1321
Epoch   2 Batch  459/1077 - Train Accuracy: 0.8981, Validation Accuracy: 0.8672, Loss: 0.1290
Epoch   2 Batch  460/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8604, Loss: 0.1392
Epoch   2 Batch  461/1077 - Train Accuracy: 0.8523, Validation Accuracy: 0.8558, Loss: 0.1246
Epoch   2 Batch  462/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8498, Loss: 0.1277
Epoch   2 Batch  463/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8477, Loss: 0.1355
Epoch   2 Batch  464/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8523, Loss: 0.1379
Epoch   2 Batch  465/1077 - Train Accuracy: 0.8470, Validation Accuracy: 0.8530, Loss: 0.1543
Epoch   2 Batch  466/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8537, Loss: 0.1165
Epoch   2 Batch  467/1077 - Train Accuracy: 0.8854, Validation Accuracy: 0.8388, Loss: 0.1383
Epoch   2 Batch  468/1077 - Train Accuracy: 0.8999, Validation Accuracy: 0.8366, Loss: 0.1511
Epoch   2 Batch  469/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8320, Loss: 0.1368
Epoch   2 Batch  470/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8370, Loss: 0.1518
Epoch   2 Batch  471/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8335, Loss: 0.1118
Epoch   2 Batch  472/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8356, Loss: 0.1275
Epoch   2 Batch  473/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8416, Loss: 0.1198
Epoch   2 Batch  474/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8533, Loss: 0.1331
Epoch   2 Batch  475/1077 - Train Accuracy: 0.8738, Validation Accuracy: 0.8679, Loss: 0.1323
Epoch   2 Batch  476/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8615, Loss: 0.1057
Epoch   2 Batch  477/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8597, Loss: 0.1326
Epoch   2 Batch  478/1077 - Train Accuracy: 0.8853, Validation Accuracy: 0.8562, Loss: 0.1389
Epoch   2 Batch  479/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8615, Loss: 0.1537
Epoch   2 Batch  480/1077 - Train Accuracy: 0.8853, Validation Accuracy: 0.8619, Loss: 0.1354
Epoch   2 Batch  481/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8608, Loss: 0.1227
Epoch   2 Batch  482/1077 - Train Accuracy: 0.8655, Validation Accuracy: 0.8548, Loss: 0.1642
Epoch   2 Batch  483/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8523, Loss: 0.1419
Epoch   2 Batch  484/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8604, Loss: 0.1554
Epoch   2 Batch  485/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8551, Loss: 0.1348
Epoch   2 Batch  486/1077 - Train Accuracy: 0.9157, Validation Accuracy: 0.8555, Loss: 0.1284
Epoch   2 Batch  487/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8512, Loss: 0.1312
Epoch   2 Batch  488/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8494, Loss: 0.1354
Epoch   2 Batch  489/1077 - Train Accuracy: 0.8847, Validation Accuracy: 0.8604, Loss: 0.1078
Epoch   2 Batch  490/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8484, Loss: 0.1327
Epoch   2 Batch  491/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8409, Loss: 0.1469
Epoch   2 Batch  492/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8480, Loss: 0.1590
Epoch   2 Batch  493/1077 - Train Accuracy: 0.9029, Validation Accuracy: 0.8523, Loss: 0.1058
Epoch   2 Batch  494/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8533, Loss: 0.1246
Epoch   2 Batch  495/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8580, Loss: 0.1281
Epoch   2 Batch  496/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8462, Loss: 0.1349
Epoch   2 Batch  497/1077 - Train Accuracy: 0.8565, Validation Accuracy: 0.8462, Loss: 0.1214
Epoch   2 Batch  498/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8612, Loss: 0.1249
Epoch   2 Batch  499/1077 - Train Accuracy: 0.8713, Validation Accuracy: 0.8636, Loss: 0.1178
Epoch   2 Batch  500/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8640, Loss: 0.1207
Epoch   2 Batch  501/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8690, Loss: 0.1153
Epoch   2 Batch  502/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8697, Loss: 0.1302
Epoch   2 Batch  503/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8771, Loss: 0.1178
Epoch   2 Batch  504/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8725, Loss: 0.1216
Epoch   2 Batch  505/1077 - Train Accuracy: 0.9115, Validation Accuracy: 0.8778, Loss: 0.1082
Epoch   2 Batch  506/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8924, Loss: 0.1325
Epoch   2 Batch  507/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.8853, Loss: 0.1426
Epoch   2 Batch  508/1077 - Train Accuracy: 0.8795, Validation Accuracy: 0.8775, Loss: 0.1158
Epoch   2 Batch  509/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8786, Loss: 0.1339
Epoch   2 Batch  510/1077 - Train Accuracy: 0.8492, Validation Accuracy: 0.8764, Loss: 0.1384
Epoch   2 Batch  511/1077 - Train Accuracy: 0.8606, Validation Accuracy: 0.8746, Loss: 0.1451
Epoch   2 Batch  512/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.8729, Loss: 0.1145
Epoch   2 Batch  513/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.8725, Loss: 0.1401
Epoch   2 Batch  514/1077 - Train Accuracy: 0.8578, Validation Accuracy: 0.8729, Loss: 0.1371
Epoch   2 Batch  515/1077 - Train Accuracy: 0.8570, Validation Accuracy: 0.8679, Loss: 0.1393
Epoch   2 Batch  516/1077 - Train Accuracy: 0.9111, Validation Accuracy: 0.8679, Loss: 0.1373
Epoch   2 Batch  517/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8651, Loss: 0.1510
Epoch   2 Batch  518/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8686, Loss: 0.1313
Epoch   2 Batch  519/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8835, Loss: 0.1207
Epoch   2 Batch  520/1077 - Train Accuracy: 0.9226, Validation Accuracy: 0.8768, Loss: 0.1248
Epoch   2 Batch  521/1077 - Train Accuracy: 0.8787, Validation Accuracy: 0.8718, Loss: 0.1201
Epoch   2 Batch  522/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8825, Loss: 0.1608
Epoch   2 Batch  523/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8860, Loss: 0.1410
Epoch   2 Batch  524/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8920, Loss: 0.1354
Epoch   2 Batch  525/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8878, Loss: 0.1470
Epoch   2 Batch  526/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8832, Loss: 0.1214
Epoch   2 Batch  527/1077 - Train Accuracy: 0.8479, Validation Accuracy: 0.8729, Loss: 0.1488
Epoch   2 Batch  528/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8789, Loss: 0.1311
Epoch   2 Batch  529/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8711, Loss: 0.1369
Epoch   2 Batch  530/1077 - Train Accuracy: 0.8477, Validation Accuracy: 0.8672, Loss: 0.1492
Epoch   2 Batch  531/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8786, Loss: 0.1261
Epoch   2 Batch  532/1077 - Train Accuracy: 0.8523, Validation Accuracy: 0.8714, Loss: 0.1458
Epoch   2 Batch  533/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8608, Loss: 0.1331
Epoch   2 Batch  534/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8580, Loss: 0.1347
Epoch   2 Batch  535/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8519, Loss: 0.1323
Epoch   2 Batch  536/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8434, Loss: 0.1317
Epoch   2 Batch  537/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8352, Loss: 0.1225
Epoch   2 Batch  538/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8409, Loss: 0.1078
Epoch   2 Batch  539/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8409, Loss: 0.1520
Epoch   2 Batch  540/1077 - Train Accuracy: 0.9008, Validation Accuracy: 0.8445, Loss: 0.1145
Epoch   2 Batch  541/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8583, Loss: 0.1191
Epoch   2 Batch  542/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8647, Loss: 0.1304
Epoch   2 Batch  543/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8647, Loss: 0.1309
Epoch   2 Batch  544/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.8594, Loss: 0.1137
Epoch   2 Batch  545/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8636, Loss: 0.1289
Epoch   2 Batch  546/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8651, Loss: 0.1335
Epoch   2 Batch  547/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8640, Loss: 0.1232
Epoch   2 Batch  548/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8683, Loss: 0.1353
Epoch   2 Batch  549/1077 - Train Accuracy: 0.8453, Validation Accuracy: 0.8675, Loss: 0.1518
Epoch   2 Batch  550/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8654, Loss: 0.1380
Epoch   2 Batch  551/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8675, Loss: 0.1423
Epoch   2 Batch  552/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8654, Loss: 0.1503
Epoch   2 Batch  553/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8615, Loss: 0.1491
Epoch   2 Batch  554/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8668, Loss: 0.1167
Epoch   2 Batch  555/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8690, Loss: 0.1363
Epoch   2 Batch  556/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8643, Loss: 0.1178
Epoch   2 Batch  557/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8711, Loss: 0.1241
Epoch   2 Batch  558/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8807, Loss: 0.1133
Epoch   2 Batch  559/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8757, Loss: 0.1312
Epoch   2 Batch  560/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.8736, Loss: 0.1205
Epoch   2 Batch  561/1077 - Train Accuracy: 0.8847, Validation Accuracy: 0.8750, Loss: 0.1171
Epoch   2 Batch  562/1077 - Train Accuracy: 0.8817, Validation Accuracy: 0.8686, Loss: 0.1256
Epoch   2 Batch  563/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.8679, Loss: 0.1469
Epoch   2 Batch  564/1077 - Train Accuracy: 0.8968, Validation Accuracy: 0.8622, Loss: 0.1385
Epoch   2 Batch  565/1077 - Train Accuracy: 0.8705, Validation Accuracy: 0.8494, Loss: 0.1235
Epoch   2 Batch  566/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8484, Loss: 0.1283
Epoch   2 Batch  567/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8452, Loss: 0.1241
Epoch   2 Batch  568/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8441, Loss: 0.1394
Epoch   2 Batch  569/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8501, Loss: 0.1408
Epoch   2 Batch  570/1077 - Train Accuracy: 0.8701, Validation Accuracy: 0.8583, Loss: 0.1384
Epoch   2 Batch  571/1077 - Train Accuracy: 0.8847, Validation Accuracy: 0.8604, Loss: 0.1134
Epoch   2 Batch  572/1077 - Train Accuracy: 0.8932, Validation Accuracy: 0.8651, Loss: 0.1163
Epoch   2 Batch  573/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8693, Loss: 0.1507
Epoch   2 Batch  574/1077 - Train Accuracy: 0.8775, Validation Accuracy: 0.8654, Loss: 0.1570
Epoch   2 Batch  575/1077 - Train Accuracy: 0.8780, Validation Accuracy: 0.8576, Loss: 0.1057
Epoch   2 Batch  576/1077 - Train Accuracy: 0.9112, Validation Accuracy: 0.8636, Loss: 0.1248
Epoch   2 Batch  577/1077 - Train Accuracy: 0.9017, Validation Accuracy: 0.8746, Loss: 0.1442
Epoch   2 Batch  578/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8757, Loss: 0.1101
Epoch   2 Batch  579/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8775, Loss: 0.1218
Epoch   2 Batch  580/1077 - Train Accuracy: 0.8806, Validation Accuracy: 0.8810, Loss: 0.1152
Epoch   2 Batch  581/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8722, Loss: 0.1085
Epoch   2 Batch  582/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8679, Loss: 0.1305
Epoch   2 Batch  583/1077 - Train Accuracy: 0.9009, Validation Accuracy: 0.8761, Loss: 0.1227
Epoch   2 Batch  584/1077 - Train Accuracy: 0.8873, Validation Accuracy: 0.8672, Loss: 0.1332
Epoch   2 Batch  585/1077 - Train Accuracy: 0.8947, Validation Accuracy: 0.8714, Loss: 0.1086
Epoch   2 Batch  586/1077 - Train Accuracy: 0.8976, Validation Accuracy: 0.8746, Loss: 0.1369
Epoch   2 Batch  587/1077 - Train Accuracy: 0.8958, Validation Accuracy: 0.8800, Loss: 0.1228
Epoch   2 Batch  588/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8810, Loss: 0.1079
Epoch   2 Batch  589/1077 - Train Accuracy: 0.9071, Validation Accuracy: 0.8849, Loss: 0.1217
Epoch   2 Batch  590/1077 - Train Accuracy: 0.8524, Validation Accuracy: 0.8839, Loss: 0.1343
Epoch   2 Batch  591/1077 - Train Accuracy: 0.8849, Validation Accuracy: 0.8867, Loss: 0.1194
Epoch   2 Batch  592/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8864, Loss: 0.1412
Epoch   2 Batch  593/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8771, Loss: 0.1362
Epoch   2 Batch  594/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8832, Loss: 0.1322
Epoch   2 Batch  595/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8910, Loss: 0.1179
Epoch   2 Batch  596/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8853, Loss: 0.1423
Epoch   2 Batch  597/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8761, Loss: 0.1236
Epoch   2 Batch  598/1077 - Train Accuracy: 0.8806, Validation Accuracy: 0.8768, Loss: 0.1449
Epoch   2 Batch  599/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.8786, Loss: 0.1652
Epoch   2 Batch  600/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8853, Loss: 0.1442
Epoch   2 Batch  601/1077 - Train Accuracy: 0.8810, Validation Accuracy: 0.8849, Loss: 0.1406
Epoch   2 Batch  602/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.8800, Loss: 0.1237
Epoch   2 Batch  603/1077 - Train Accuracy: 0.8947, Validation Accuracy: 0.8739, Loss: 0.1192
Epoch   2 Batch  604/1077 - Train Accuracy: 0.8480, Validation Accuracy: 0.8835, Loss: 0.1513
Epoch   2 Batch  605/1077 - Train Accuracy: 0.8643, Validation Accuracy: 0.8796, Loss: 0.1363
Epoch   2 Batch  606/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8839, Loss: 0.1111
Epoch   2 Batch  607/1077 - Train Accuracy: 0.8917, Validation Accuracy: 0.9002, Loss: 0.1195
Epoch   2 Batch  608/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.9006, Loss: 0.1439
Epoch   2 Batch  609/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8864, Loss: 0.1326
Epoch   2 Batch  610/1077 - Train Accuracy: 0.8779, Validation Accuracy: 0.8956, Loss: 0.1473
Epoch   2 Batch  611/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8860, Loss: 0.1027
Epoch   2 Batch  612/1077 - Train Accuracy: 0.9103, Validation Accuracy: 0.8757, Loss: 0.1256
Epoch   2 Batch  613/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8761, Loss: 0.1288
Epoch   2 Batch  614/1077 - Train Accuracy: 0.8821, Validation Accuracy: 0.8853, Loss: 0.1234
Epoch   2 Batch  615/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8931, Loss: 0.1188
Epoch   2 Batch  616/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8874, Loss: 0.1335
Epoch   2 Batch  617/1077 - Train Accuracy: 0.8843, Validation Accuracy: 0.8793, Loss: 0.1275
Epoch   2 Batch  618/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8892, Loss: 0.1280
Epoch   2 Batch  619/1077 - Train Accuracy: 0.9034, Validation Accuracy: 0.8896, Loss: 0.1077
Epoch   2 Batch  620/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8967, Loss: 0.1335
Epoch   2 Batch  621/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.8878, Loss: 0.1305
Epoch   2 Batch  622/1077 - Train Accuracy: 0.8935, Validation Accuracy: 0.8789, Loss: 0.1485
Epoch   2 Batch  623/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8746, Loss: 0.1342
Epoch   2 Batch  624/1077 - Train Accuracy: 0.8769, Validation Accuracy: 0.8700, Loss: 0.1327
Epoch   2 Batch  625/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8729, Loss: 0.1346
Epoch   2 Batch  626/1077 - Train Accuracy: 0.8853, Validation Accuracy: 0.8661, Loss: 0.1090
Epoch   2 Batch  627/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8754, Loss: 0.1026
Epoch   2 Batch  628/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8800, Loss: 0.1415
Epoch   2 Batch  629/1077 - Train Accuracy: 0.8845, Validation Accuracy: 0.8896, Loss: 0.1497
Epoch   2 Batch  630/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8942, Loss: 0.1217
Epoch   2 Batch  631/1077 - Train Accuracy: 0.8616, Validation Accuracy: 0.8991, Loss: 0.1324
Epoch   2 Batch  632/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8984, Loss: 0.1105
Epoch   2 Batch  633/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8867, Loss: 0.1294
Epoch   2 Batch  634/1077 - Train Accuracy: 0.8958, Validation Accuracy: 0.8881, Loss: 0.1128
Epoch   2 Batch  635/1077 - Train Accuracy: 0.8931, Validation Accuracy: 0.8839, Loss: 0.1547
Epoch   2 Batch  636/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8849, Loss: 0.1166
Epoch   2 Batch  637/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8761, Loss: 0.1264
Epoch   2 Batch  638/1077 - Train Accuracy: 0.8869, Validation Accuracy: 0.8711, Loss: 0.1152
Epoch   2 Batch  639/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8736, Loss: 0.1549
Epoch   2 Batch  640/1077 - Train Accuracy: 0.9014, Validation Accuracy: 0.8764, Loss: 0.1349
Epoch   2 Batch  641/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8711, Loss: 0.1184
Epoch   2 Batch  642/1077 - Train Accuracy: 0.8497, Validation Accuracy: 0.8679, Loss: 0.1316
Epoch   2 Batch  643/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.8857, Loss: 0.1061
Epoch   2 Batch  644/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8906, Loss: 0.1461
Epoch   2 Batch  645/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8920, Loss: 0.1338
Epoch   2 Batch  646/1077 - Train Accuracy: 0.9226, Validation Accuracy: 0.9009, Loss: 0.1314
Epoch   2 Batch  647/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8974, Loss: 0.1310
Epoch   2 Batch  648/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8967, Loss: 0.1089
Epoch   2 Batch  649/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8931, Loss: 0.1378
Epoch   2 Batch  650/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8871, Loss: 0.1179
Epoch   2 Batch  651/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8778, Loss: 0.1281
Epoch   2 Batch  652/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8789, Loss: 0.1379
Epoch   2 Batch  653/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8683, Loss: 0.1308
Epoch   2 Batch  654/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8683, Loss: 0.1108
Epoch   2 Batch  655/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8658, Loss: 0.1327
Epoch   2 Batch  656/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8651, Loss: 0.1249
Epoch   2 Batch  657/1077 - Train Accuracy: 0.9087, Validation Accuracy: 0.8693, Loss: 0.1154
Epoch   2 Batch  658/1077 - Train Accuracy: 0.8873, Validation Accuracy: 0.8739, Loss: 0.1231
Epoch   2 Batch  659/1077 - Train Accuracy: 0.8966, Validation Accuracy: 0.8722, Loss: 0.1372
Epoch   2 Batch  660/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8697, Loss: 0.1218
Epoch   2 Batch  661/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8693, Loss: 0.1299
Epoch   2 Batch  662/1077 - Train Accuracy: 0.9189, Validation Accuracy: 0.8697, Loss: 0.1186
Epoch   2 Batch  663/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8448, Loss: 0.1302
Epoch   2 Batch  664/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8398, Loss: 0.1289
Epoch   2 Batch  665/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8551, Loss: 0.1228
Epoch   2 Batch  666/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8626, Loss: 0.1338
Epoch   2 Batch  667/1077 - Train Accuracy: 0.8639, Validation Accuracy: 0.8615, Loss: 0.1482
Epoch   2 Batch  668/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8626, Loss: 0.1349
Epoch   2 Batch  669/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8640, Loss: 0.1223
Epoch   2 Batch  670/1077 - Train Accuracy: 0.8970, Validation Accuracy: 0.8697, Loss: 0.1415
Epoch   2 Batch  671/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8796, Loss: 0.1533
Epoch   2 Batch  672/1077 - Train Accuracy: 0.8958, Validation Accuracy: 0.8615, Loss: 0.1312
Epoch   2 Batch  673/1077 - Train Accuracy: 0.8813, Validation Accuracy: 0.8683, Loss: 0.1145
Epoch   2 Batch  674/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8590, Loss: 0.1147
Epoch   2 Batch  675/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8636, Loss: 0.1435
Epoch   2 Batch  676/1077 - Train Accuracy: 0.8795, Validation Accuracy: 0.8583, Loss: 0.1288
Epoch   2 Batch  677/1077 - Train Accuracy: 0.8562, Validation Accuracy: 0.8583, Loss: 0.1467
Epoch   2 Batch  678/1077 - Train Accuracy: 0.8981, Validation Accuracy: 0.8668, Loss: 0.1082
Epoch   2 Batch  679/1077 - Train Accuracy: 0.9038, Validation Accuracy: 0.8668, Loss: 0.1344
Epoch   2 Batch  680/1077 - Train Accuracy: 0.8720, Validation Accuracy: 0.8778, Loss: 0.1212
Epoch   2 Batch  681/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8853, Loss: 0.1474
Epoch   2 Batch  682/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8906, Loss: 0.1396
Epoch   2 Batch  683/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8849, Loss: 0.1182
Epoch   2 Batch  684/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.8849, Loss: 0.1207
Epoch   2 Batch  685/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8842, Loss: 0.1318
Epoch   2 Batch  686/1077 - Train Accuracy: 0.8661, Validation Accuracy: 0.8828, Loss: 0.1198
Epoch   2 Batch  687/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8849, Loss: 0.1571
Epoch   2 Batch  688/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8789, Loss: 0.1283
Epoch   2 Batch  689/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.8569, Loss: 0.1071
Epoch   2 Batch  690/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8523, Loss: 0.1294
Epoch   2 Batch  691/1077 - Train Accuracy: 0.8549, Validation Accuracy: 0.8555, Loss: 0.1376
Epoch   2 Batch  692/1077 - Train Accuracy: 0.8962, Validation Accuracy: 0.8523, Loss: 0.1113
Epoch   2 Batch  693/1077 - Train Accuracy: 0.8240, Validation Accuracy: 0.8434, Loss: 0.1652
Epoch   2 Batch  694/1077 - Train Accuracy: 0.9085, Validation Accuracy: 0.8501, Loss: 0.1373
Epoch   2 Batch  695/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8597, Loss: 0.1144
Epoch   2 Batch  696/1077 - Train Accuracy: 0.8655, Validation Accuracy: 0.8544, Loss: 0.1364
Epoch   2 Batch  697/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8537, Loss: 0.1213
Epoch   2 Batch  698/1077 - Train Accuracy: 0.8981, Validation Accuracy: 0.8526, Loss: 0.1176
Epoch   2 Batch  699/1077 - Train Accuracy: 0.8877, Validation Accuracy: 0.8519, Loss: 0.1187
Epoch   2 Batch  700/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8505, Loss: 0.1067
Epoch   2 Batch  701/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8530, Loss: 0.1284
Epoch   2 Batch  702/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8562, Loss: 0.1376
Epoch   2 Batch  703/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8622, Loss: 0.1416
Epoch   2 Batch  704/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8665, Loss: 0.1514
Epoch   2 Batch  705/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8562, Loss: 0.1249
Epoch   2 Batch  706/1077 - Train Accuracy: 0.8393, Validation Accuracy: 0.8601, Loss: 0.1752
Epoch   2 Batch  707/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8658, Loss: 0.1191
Epoch   2 Batch  708/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8658, Loss: 0.1436
Epoch   2 Batch  709/1077 - Train Accuracy: 0.8715, Validation Accuracy: 0.8647, Loss: 0.1392
Epoch   2 Batch  710/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8601, Loss: 0.1060
Epoch   2 Batch  711/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8732, Loss: 0.1432
Epoch   2 Batch  712/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.8825, Loss: 0.1311
Epoch   2 Batch  713/1077 - Train Accuracy: 0.9073, Validation Accuracy: 0.8846, Loss: 0.1054
Epoch   2 Batch  714/1077 - Train Accuracy: 0.9111, Validation Accuracy: 0.8892, Loss: 0.1157
Epoch   2 Batch  715/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8817, Loss: 0.1466
Epoch   2 Batch  716/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8828, Loss: 0.1210
Epoch   2 Batch  717/1077 - Train Accuracy: 0.9235, Validation Accuracy: 0.8874, Loss: 0.1231
Epoch   2 Batch  718/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8938, Loss: 0.1213
Epoch   2 Batch  719/1077 - Train Accuracy: 0.8698, Validation Accuracy: 0.8981, Loss: 0.1165
Epoch   2 Batch  720/1077 - Train Accuracy: 0.8939, Validation Accuracy: 0.8910, Loss: 0.1266
Epoch   2 Batch  721/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8952, Loss: 0.1372
Epoch   2 Batch  722/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8942, Loss: 0.1113
Epoch   2 Batch  723/1077 - Train Accuracy: 0.9275, Validation Accuracy: 0.8878, Loss: 0.1273
Epoch   2 Batch  724/1077 - Train Accuracy: 0.8882, Validation Accuracy: 0.8878, Loss: 0.1350
Epoch   2 Batch  725/1077 - Train Accuracy: 0.9126, Validation Accuracy: 0.8714, Loss: 0.0970
Epoch   2 Batch  726/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8771, Loss: 0.1259
Epoch   2 Batch  727/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8903, Loss: 0.1244
Epoch   2 Batch  728/1077 - Train Accuracy: 0.8497, Validation Accuracy: 0.8860, Loss: 0.1341
Epoch   2 Batch  729/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8771, Loss: 0.1400
Epoch   2 Batch  730/1077 - Train Accuracy: 0.8602, Validation Accuracy: 0.8771, Loss: 0.1503
Epoch   2 Batch  731/1077 - Train Accuracy: 0.8601, Validation Accuracy: 0.8707, Loss: 0.1405
Epoch   2 Batch  732/1077 - Train Accuracy: 0.8606, Validation Accuracy: 0.8558, Loss: 0.1390
Epoch   2 Batch  733/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8580, Loss: 0.1203
Epoch   2 Batch  734/1077 - Train Accuracy: 0.9264, Validation Accuracy: 0.8636, Loss: 0.1484
Epoch   2 Batch  735/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8718, Loss: 0.1317
Epoch   2 Batch  736/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8746, Loss: 0.1103
Epoch   2 Batch  737/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8700, Loss: 0.1384
Epoch   2 Batch  738/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8683, Loss: 0.1120
Epoch   2 Batch  739/1077 - Train Accuracy: 0.9277, Validation Accuracy: 0.8697, Loss: 0.1095
Epoch   2 Batch  740/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8690, Loss: 0.1248
Epoch   2 Batch  741/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8704, Loss: 0.1303
Epoch   2 Batch  742/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8743, Loss: 0.1281
Epoch   2 Batch  743/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8793, Loss: 0.1497
Epoch   2 Batch  744/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8754, Loss: 0.1498
Epoch   2 Batch  745/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8754, Loss: 0.1362
Epoch   2 Batch  746/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8661, Loss: 0.1239
Epoch   2 Batch  747/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8654, Loss: 0.1111
Epoch   2 Batch  748/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8651, Loss: 0.1291
Epoch   2 Batch  749/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8686, Loss: 0.1390
Epoch   2 Batch  750/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8722, Loss: 0.1288
Epoch   2 Batch  751/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8668, Loss: 0.1353
Epoch   2 Batch  752/1077 - Train Accuracy: 0.8724, Validation Accuracy: 0.8725, Loss: 0.1247
Epoch   2 Batch  753/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8704, Loss: 0.1217
Epoch   2 Batch  754/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8736, Loss: 0.1413
Epoch   2 Batch  755/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8782, Loss: 0.1378
Epoch   2 Batch  756/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8789, Loss: 0.1346
Epoch   2 Batch  757/1077 - Train Accuracy: 0.8717, Validation Accuracy: 0.8732, Loss: 0.1465
Epoch   2 Batch  758/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8675, Loss: 0.1334
Epoch   2 Batch  759/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8626, Loss: 0.1326
Epoch   2 Batch  760/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8661, Loss: 0.1506
Epoch   2 Batch  761/1077 - Train Accuracy: 0.8446, Validation Accuracy: 0.8679, Loss: 0.1516
Epoch   2 Batch  762/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8640, Loss: 0.1260
Epoch   2 Batch  763/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8594, Loss: 0.1053
Epoch   2 Batch  764/1077 - Train Accuracy: 0.8721, Validation Accuracy: 0.8633, Loss: 0.1308
Epoch   2 Batch  765/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8725, Loss: 0.1251
Epoch   2 Batch  766/1077 - Train Accuracy: 0.8480, Validation Accuracy: 0.8718, Loss: 0.1251
Epoch   2 Batch  767/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8786, Loss: 0.1401
Epoch   2 Batch  768/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8800, Loss: 0.1401
Epoch   2 Batch  769/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8828, Loss: 0.1322
Epoch   2 Batch  770/1077 - Train Accuracy: 0.8850, Validation Accuracy: 0.8739, Loss: 0.1326
Epoch   2 Batch  771/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8849, Loss: 0.1479
Epoch   2 Batch  772/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8775, Loss: 0.1235
Epoch   2 Batch  773/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8718, Loss: 0.1464
Epoch   2 Batch  774/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8771, Loss: 0.1317
Epoch   2 Batch  775/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8771, Loss: 0.1251
Epoch   2 Batch  776/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8764, Loss: 0.1178
Epoch   2 Batch  777/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8778, Loss: 0.1464
Epoch   2 Batch  778/1077 - Train Accuracy: 0.8787, Validation Accuracy: 0.8725, Loss: 0.1275
Epoch   2 Batch  779/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8736, Loss: 0.1449
Epoch   2 Batch  780/1077 - Train Accuracy: 0.8379, Validation Accuracy: 0.8786, Loss: 0.1629
Epoch   2 Batch  781/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8714, Loss: 0.1120
Epoch   2 Batch  782/1077 - Train Accuracy: 0.8817, Validation Accuracy: 0.8704, Loss: 0.1207
Epoch   2 Batch  783/1077 - Train Accuracy: 0.8757, Validation Accuracy: 0.8754, Loss: 0.1414
Epoch   2 Batch  784/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8732, Loss: 0.1324
Epoch   2 Batch  785/1077 - Train Accuracy: 0.9412, Validation Accuracy: 0.8661, Loss: 0.1211
Epoch   2 Batch  786/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.8654, Loss: 0.1149
Epoch   2 Batch  787/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8654, Loss: 0.1303
Epoch   2 Batch  788/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8668, Loss: 0.1183
Epoch   2 Batch  789/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8661, Loss: 0.1483
Epoch   2 Batch  790/1077 - Train Accuracy: 0.8613, Validation Accuracy: 0.8718, Loss: 0.1472
Epoch   2 Batch  791/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8636, Loss: 0.1457
Epoch   2 Batch  792/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8693, Loss: 0.1407
Epoch   2 Batch  793/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8697, Loss: 0.1194
Epoch   2 Batch  794/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8686, Loss: 0.1224
Epoch   2 Batch  795/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8679, Loss: 0.1402
Epoch   2 Batch  796/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8686, Loss: 0.1227
Epoch   2 Batch  797/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8533, Loss: 0.1375
Epoch   2 Batch  798/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8640, Loss: 0.1490
Epoch   2 Batch  799/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8619, Loss: 0.1624
Epoch   2 Batch  800/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8697, Loss: 0.1318
Epoch   2 Batch  801/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8704, Loss: 0.1397
Epoch   2 Batch  802/1077 - Train Accuracy: 0.9036, Validation Accuracy: 0.8665, Loss: 0.1307
Epoch   2 Batch  803/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8654, Loss: 0.1433
Epoch   2 Batch  804/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8636, Loss: 0.1200
Epoch   2 Batch  805/1077 - Train Accuracy: 0.8355, Validation Accuracy: 0.8700, Loss: 0.1321
Epoch   2 Batch  806/1077 - Train Accuracy: 0.8697, Validation Accuracy: 0.8697, Loss: 0.1266
Epoch   2 Batch  807/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8615, Loss: 0.1180
Epoch   2 Batch  808/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8700, Loss: 0.1345
Epoch   2 Batch  809/1077 - Train Accuracy: 0.8729, Validation Accuracy: 0.8746, Loss: 0.1688
Epoch   2 Batch  810/1077 - Train Accuracy: 0.8657, Validation Accuracy: 0.8800, Loss: 0.1188
Epoch   2 Batch  811/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8683, Loss: 0.1308
Epoch   2 Batch  812/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8572, Loss: 0.1228
Epoch   2 Batch  813/1077 - Train Accuracy: 0.9014, Validation Accuracy: 0.8565, Loss: 0.1191
Epoch   2 Batch  814/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8697, Loss: 0.1457
Epoch   2 Batch  815/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8693, Loss: 0.1261
Epoch   2 Batch  816/1077 - Train Accuracy: 0.9083, Validation Accuracy: 0.8704, Loss: 0.1339
Epoch   2 Batch  817/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.8750, Loss: 0.1449
Epoch   2 Batch  818/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8615, Loss: 0.1346
Epoch   2 Batch  819/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8562, Loss: 0.1319
Epoch   2 Batch  820/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.8516, Loss: 0.1213
Epoch   2 Batch  821/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.8459, Loss: 0.1378
Epoch   2 Batch  822/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8540, Loss: 0.1292
Epoch   2 Batch  823/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8643, Loss: 0.1246
Epoch   2 Batch  824/1077 - Train Accuracy: 0.8903, Validation Accuracy: 0.8558, Loss: 0.1267
Epoch   2 Batch  825/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8540, Loss: 0.1220
Epoch   2 Batch  826/1077 - Train Accuracy: 0.8225, Validation Accuracy: 0.8505, Loss: 0.1189
Epoch   2 Batch  827/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8445, Loss: 0.1229
Epoch   2 Batch  828/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8466, Loss: 0.1232
Epoch   2 Batch  829/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8413, Loss: 0.1605
Epoch   2 Batch  830/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.8438, Loss: 0.1440
Epoch   2 Batch  831/1077 - Train Accuracy: 0.8254, Validation Accuracy: 0.8434, Loss: 0.1385
Epoch   2 Batch  832/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8509, Loss: 0.1173
Epoch   2 Batch  833/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8597, Loss: 0.1302
Epoch   2 Batch  834/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8704, Loss: 0.1339
Epoch   2 Batch  835/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8807, Loss: 0.1271
Epoch   2 Batch  836/1077 - Train Accuracy: 0.9025, Validation Accuracy: 0.8761, Loss: 0.1428
Epoch   2 Batch  837/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8864, Loss: 0.1757
Epoch   2 Batch  838/1077 - Train Accuracy: 0.8957, Validation Accuracy: 0.8711, Loss: 0.1285
Epoch   2 Batch  839/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8636, Loss: 0.1220
Epoch   2 Batch  840/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8590, Loss: 0.1124
Epoch   2 Batch  841/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8668, Loss: 0.1269
Epoch   2 Batch  842/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8672, Loss: 0.1258
Epoch   2 Batch  843/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8725, Loss: 0.1180
Epoch   2 Batch  844/1077 - Train Accuracy: 0.8735, Validation Accuracy: 0.8778, Loss: 0.1274
Epoch   2 Batch  845/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8629, Loss: 0.1138
Epoch   2 Batch  846/1077 - Train Accuracy: 0.8496, Validation Accuracy: 0.8722, Loss: 0.1497
Epoch   2 Batch  847/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8683, Loss: 0.1527
Epoch   2 Batch  848/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.8626, Loss: 0.1194
Epoch   2 Batch  849/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.8665, Loss: 0.1142
Epoch   2 Batch  850/1077 - Train Accuracy: 0.8728, Validation Accuracy: 0.8658, Loss: 0.1483
Epoch   2 Batch  851/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8640, Loss: 0.1423
Epoch   2 Batch  852/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8643, Loss: 0.1523
Epoch   2 Batch  853/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8643, Loss: 0.1193
Epoch   2 Batch  854/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8597, Loss: 0.1363
Epoch   2 Batch  855/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8597, Loss: 0.1267
Epoch   2 Batch  856/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8594, Loss: 0.1290
Epoch   2 Batch  857/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8580, Loss: 0.1318
Epoch   2 Batch  858/1077 - Train Accuracy: 0.8880, Validation Accuracy: 0.8537, Loss: 0.1306
Epoch   2 Batch  859/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8636, Loss: 0.1583
Epoch   2 Batch  860/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8810, Loss: 0.1337
Epoch   2 Batch  861/1077 - Train Accuracy: 0.8496, Validation Accuracy: 0.8910, Loss: 0.1281
Epoch   2 Batch  862/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8903, Loss: 0.1154
Epoch   2 Batch  863/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8846, Loss: 0.1132
Epoch   2 Batch  864/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.8697, Loss: 0.1183
Epoch   2 Batch  865/1077 - Train Accuracy: 0.8853, Validation Accuracy: 0.8746, Loss: 0.1310
Epoch   2 Batch  866/1077 - Train Accuracy: 0.8687, Validation Accuracy: 0.8690, Loss: 0.1437
Epoch   2 Batch  867/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8651, Loss: 0.1661
Epoch   2 Batch  868/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8569, Loss: 0.1368
Epoch   2 Batch  869/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.8572, Loss: 0.1215
Epoch   2 Batch  870/1077 - Train Accuracy: 0.8499, Validation Accuracy: 0.8576, Loss: 0.1314
Epoch   2 Batch  871/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8572, Loss: 0.1137
Epoch   2 Batch  872/1077 - Train Accuracy: 0.8957, Validation Accuracy: 0.8626, Loss: 0.1249
Epoch   2 Batch  873/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8647, Loss: 0.1345
Epoch   2 Batch  874/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8651, Loss: 0.1433
Epoch   2 Batch  875/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8793, Loss: 0.1280
Epoch   2 Batch  876/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8768, Loss: 0.1124
Epoch   2 Batch  877/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8736, Loss: 0.1113
Epoch   2 Batch  878/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8729, Loss: 0.1101
Epoch   2 Batch  879/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8771, Loss: 0.1128
Epoch   2 Batch  880/1077 - Train Accuracy: 0.9293, Validation Accuracy: 0.8775, Loss: 0.1146
Epoch   2 Batch  881/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8675, Loss: 0.1289
Epoch   2 Batch  882/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8658, Loss: 0.1390
Epoch   2 Batch  883/1077 - Train Accuracy: 0.8701, Validation Accuracy: 0.8565, Loss: 0.1543
Epoch   2 Batch  884/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8555, Loss: 0.1234
Epoch   2 Batch  885/1077 - Train Accuracy: 0.9251, Validation Accuracy: 0.8569, Loss: 0.0994
Epoch   2 Batch  886/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8537, Loss: 0.1335
Epoch   2 Batch  887/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8544, Loss: 0.1421
Epoch   2 Batch  888/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8565, Loss: 0.1032
Epoch   2 Batch  889/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8615, Loss: 0.1159
Epoch   2 Batch  890/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8615, Loss: 0.1171
Epoch   2 Batch  891/1077 - Train Accuracy: 0.9079, Validation Accuracy: 0.8615, Loss: 0.1213
Epoch   2 Batch  892/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8629, Loss: 0.1135
Epoch   2 Batch  893/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8640, Loss: 0.1266
Epoch   2 Batch  894/1077 - Train Accuracy: 0.8880, Validation Accuracy: 0.8562, Loss: 0.1326
Epoch   2 Batch  895/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8558, Loss: 0.1313
Epoch   2 Batch  896/1077 - Train Accuracy: 0.8717, Validation Accuracy: 0.8601, Loss: 0.1364
Epoch   2 Batch  897/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8640, Loss: 0.1034
Epoch   2 Batch  898/1077 - Train Accuracy: 0.8798, Validation Accuracy: 0.8619, Loss: 0.1091
Epoch   2 Batch  899/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8622, Loss: 0.1489
Epoch   2 Batch  900/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8746, Loss: 0.1364
Epoch   2 Batch  901/1077 - Train Accuracy: 0.8776, Validation Accuracy: 0.8739, Loss: 0.1627
Epoch   2 Batch  902/1077 - Train Accuracy: 0.8571, Validation Accuracy: 0.8857, Loss: 0.1339
Epoch   2 Batch  903/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8899, Loss: 0.1179
Epoch   2 Batch  904/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8821, Loss: 0.1212
Epoch   2 Batch  905/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8817, Loss: 0.1028
Epoch   2 Batch  906/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8683, Loss: 0.1239
Epoch   2 Batch  907/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8533, Loss: 0.1263
Epoch   2 Batch  908/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.8633, Loss: 0.1375
Epoch   2 Batch  909/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8626, Loss: 0.1315
Epoch   2 Batch  910/1077 - Train Accuracy: 0.8780, Validation Accuracy: 0.8789, Loss: 0.1304
Epoch   2 Batch  911/1077 - Train Accuracy: 0.8942, Validation Accuracy: 0.8746, Loss: 0.1392
Epoch   2 Batch  912/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8771, Loss: 0.1261
Epoch   2 Batch  913/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8906, Loss: 0.1621
Epoch   2 Batch  914/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8828, Loss: 0.1491
Epoch   2 Batch  915/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8839, Loss: 0.1198
Epoch   2 Batch  916/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8832, Loss: 0.1498
Epoch   2 Batch  917/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8782, Loss: 0.1210
Epoch   2 Batch  918/1077 - Train Accuracy: 0.9003, Validation Accuracy: 0.8768, Loss: 0.1177
Epoch   2 Batch  919/1077 - Train Accuracy: 0.8919, Validation Accuracy: 0.8736, Loss: 0.1322
Epoch   2 Batch  920/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8668, Loss: 0.1238
Epoch   2 Batch  921/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8612, Loss: 0.1584
Epoch   2 Batch  922/1077 - Train Accuracy: 0.8903, Validation Accuracy: 0.8601, Loss: 0.1370
Epoch   2 Batch  923/1077 - Train Accuracy: 0.8857, Validation Accuracy: 0.8558, Loss: 0.1020
Epoch   2 Batch  924/1077 - Train Accuracy: 0.8919, Validation Accuracy: 0.8516, Loss: 0.1709
Epoch   2 Batch  925/1077 - Train Accuracy: 0.8847, Validation Accuracy: 0.8466, Loss: 0.1128
Epoch   2 Batch  926/1077 - Train Accuracy: 0.8480, Validation Accuracy: 0.8473, Loss: 0.1299
Epoch   2 Batch  927/1077 - Train Accuracy: 0.8672, Validation Accuracy: 0.8526, Loss: 0.1534
Epoch   2 Batch  928/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8540, Loss: 0.1314
Epoch   2 Batch  929/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8722, Loss: 0.1360
Epoch   2 Batch  930/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8707, Loss: 0.1305
Epoch   2 Batch  931/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8817, Loss: 0.1136
Epoch   2 Batch  932/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8814, Loss: 0.1293
Epoch   2 Batch  933/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8846, Loss: 0.1191
Epoch   2 Batch  934/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8853, Loss: 0.1189
Epoch   2 Batch  935/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.8700, Loss: 0.1197
Epoch   2 Batch  936/1077 - Train Accuracy: 0.9200, Validation Accuracy: 0.8746, Loss: 0.1311
Epoch   2 Batch  937/1077 - Train Accuracy: 0.8935, Validation Accuracy: 0.8622, Loss: 0.1413
Epoch   2 Batch  938/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8516, Loss: 0.1296
Epoch   2 Batch  939/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8484, Loss: 0.1432
Epoch   2 Batch  940/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.8487, Loss: 0.1117
Epoch   2 Batch  941/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8597, Loss: 0.1171
Epoch   2 Batch  942/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8459, Loss: 0.1280
Epoch   2 Batch  943/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8370, Loss: 0.1404
Epoch   2 Batch  944/1077 - Train Accuracy: 0.8683, Validation Accuracy: 0.8391, Loss: 0.1081
Epoch   2 Batch  945/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8455, Loss: 0.0980
Epoch   2 Batch  946/1077 - Train Accuracy: 0.9342, Validation Accuracy: 0.8594, Loss: 0.1133
Epoch   2 Batch  947/1077 - Train Accuracy: 0.8141, Validation Accuracy: 0.8597, Loss: 0.1345
Epoch   2 Batch  948/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8651, Loss: 0.1303
Epoch   2 Batch  949/1077 - Train Accuracy: 0.9081, Validation Accuracy: 0.8647, Loss: 0.1017
Epoch   2 Batch  950/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8651, Loss: 0.1140
Epoch   2 Batch  951/1077 - Train Accuracy: 0.8553, Validation Accuracy: 0.8711, Loss: 0.1553
Epoch   2 Batch  952/1077 - Train Accuracy: 0.9316, Validation Accuracy: 0.8725, Loss: 0.1144
Epoch   2 Batch  953/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.8661, Loss: 0.1100
Epoch   2 Batch  954/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8626, Loss: 0.1292
Epoch   2 Batch  955/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8675, Loss: 0.1281
Epoch   2 Batch  956/1077 - Train Accuracy: 0.8957, Validation Accuracy: 0.8679, Loss: 0.1382
Epoch   2 Batch  957/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.8540, Loss: 0.0972
Epoch   2 Batch  958/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8430, Loss: 0.1220
Epoch   2 Batch  959/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8551, Loss: 0.1115
Epoch   2 Batch  960/1077 - Train Accuracy: 0.8899, Validation Accuracy: 0.8697, Loss: 0.1293
Epoch   2 Batch  961/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8782, Loss: 0.1165
Epoch   2 Batch  962/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.8665, Loss: 0.1239
Epoch   2 Batch  963/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8651, Loss: 0.1515
Epoch   2 Batch  964/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8640, Loss: 0.1088
Epoch   2 Batch  965/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8594, Loss: 0.1560
Epoch   2 Batch  966/1077 - Train Accuracy: 0.9175, Validation Accuracy: 0.8619, Loss: 0.1174
Epoch   2 Batch  967/1077 - Train Accuracy: 0.8715, Validation Accuracy: 0.8668, Loss: 0.1408
Epoch   2 Batch  968/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8754, Loss: 0.1514
Epoch   2 Batch  969/1077 - Train Accuracy: 0.8650, Validation Accuracy: 0.8810, Loss: 0.1406
Epoch   2 Batch  970/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8810, Loss: 0.1405
Epoch   2 Batch  971/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.8711, Loss: 0.1431
Epoch   2 Batch  972/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8629, Loss: 0.1224
Epoch   2 Batch  973/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8640, Loss: 0.1008
Epoch   2 Batch  974/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8615, Loss: 0.1035
Epoch   2 Batch  975/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.8633, Loss: 0.1298
Epoch   2 Batch  976/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8793, Loss: 0.1242
Epoch   2 Batch  977/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8690, Loss: 0.1136
Epoch   2 Batch  978/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8686, Loss: 0.1379
Epoch   2 Batch  979/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8651, Loss: 0.1416
Epoch   2 Batch  980/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8658, Loss: 0.1491
Epoch   2 Batch  981/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8683, Loss: 0.1154
Epoch   2 Batch  982/1077 - Train Accuracy: 0.9025, Validation Accuracy: 0.8707, Loss: 0.1239
Epoch   2 Batch  983/1077 - Train Accuracy: 0.8935, Validation Accuracy: 0.8683, Loss: 0.1160
Epoch   2 Batch  984/1077 - Train Accuracy: 0.8359, Validation Accuracy: 0.8693, Loss: 0.1291
Epoch   2 Batch  985/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8743, Loss: 0.1181
Epoch   2 Batch  986/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8832, Loss: 0.1216
Epoch   2 Batch  987/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8839, Loss: 0.1046
Epoch   2 Batch  988/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8832, Loss: 0.1280
Epoch   2 Batch  989/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8739, Loss: 0.1518
Epoch   2 Batch  990/1077 - Train Accuracy: 0.8869, Validation Accuracy: 0.8786, Loss: 0.1487
Epoch   2 Batch  991/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8910, Loss: 0.1331
Epoch   2 Batch  992/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8885, Loss: 0.1174
Epoch   2 Batch  993/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.8846, Loss: 0.1056
Epoch   2 Batch  994/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8842, Loss: 0.1181
Epoch   2 Batch  995/1077 - Train Accuracy: 0.8865, Validation Accuracy: 0.8789, Loss: 0.1205
Epoch   2 Batch  996/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8796, Loss: 0.1234
Epoch   2 Batch  997/1077 - Train Accuracy: 0.8923, Validation Accuracy: 0.8817, Loss: 0.1294
Epoch   2 Batch  998/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8722, Loss: 0.1185
Epoch   2 Batch  999/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8729, Loss: 0.1263
Epoch   2 Batch 1000/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8732, Loss: 0.1085
Epoch   2 Batch 1001/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8778, Loss: 0.1001
Epoch   2 Batch 1002/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8690, Loss: 0.1087
Epoch   2 Batch 1003/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8654, Loss: 0.1505
Epoch   2 Batch 1004/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8665, Loss: 0.1304
Epoch   2 Batch 1005/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8608, Loss: 0.1141
Epoch   2 Batch 1006/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8608, Loss: 0.0983
Epoch   2 Batch 1007/1077 - Train Accuracy: 0.9170, Validation Accuracy: 0.8640, Loss: 0.1127
Epoch   2 Batch 1008/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8700, Loss: 0.1505
Epoch   2 Batch 1009/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.8714, Loss: 0.0966
Epoch   2 Batch 1010/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.8693, Loss: 0.0995
Epoch   2 Batch 1011/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8725, Loss: 0.1209
Epoch   2 Batch 1012/1077 - Train Accuracy: 0.9423, Validation Accuracy: 0.8679, Loss: 0.1026
Epoch   2 Batch 1013/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8683, Loss: 0.0996
Epoch   2 Batch 1014/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8690, Loss: 0.1275
Epoch   2 Batch 1015/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8597, Loss: 0.1410
Epoch   2 Batch 1016/1077 - Train Accuracy: 0.8553, Validation Accuracy: 0.8643, Loss: 0.1329
Epoch   2 Batch 1017/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8640, Loss: 0.1318
Epoch   2 Batch 1018/1077 - Train Accuracy: 0.8560, Validation Accuracy: 0.8619, Loss: 0.1172
Epoch   2 Batch 1019/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8619, Loss: 0.1613
Epoch   2 Batch 1020/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8629, Loss: 0.1128
Epoch   2 Batch 1021/1077 - Train Accuracy: 0.8769, Validation Accuracy: 0.8580, Loss: 0.1226
Epoch   2 Batch 1022/1077 - Train Accuracy: 0.8962, Validation Accuracy: 0.8572, Loss: 0.1191
Epoch   2 Batch 1023/1077 - Train Accuracy: 0.8960, Validation Accuracy: 0.8576, Loss: 0.1096
Epoch   2 Batch 1024/1077 - Train Accuracy: 0.8516, Validation Accuracy: 0.8640, Loss: 0.1345
Epoch   2 Batch 1025/1077 - Train Accuracy: 0.8769, Validation Accuracy: 0.8690, Loss: 0.1237
Epoch   2 Batch 1026/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.8846, Loss: 0.1317
Epoch   2 Batch 1027/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8849, Loss: 0.1208
Epoch   2 Batch 1028/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8704, Loss: 0.1138
Epoch   2 Batch 1029/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8746, Loss: 0.1156
Epoch   2 Batch 1030/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8693, Loss: 0.1534
Epoch   2 Batch 1031/1077 - Train Accuracy: 0.9120, Validation Accuracy: 0.8590, Loss: 0.1326
Epoch   2 Batch 1032/1077 - Train Accuracy: 0.8679, Validation Accuracy: 0.8587, Loss: 0.1383
Epoch   2 Batch 1033/1077 - Train Accuracy: 0.8493, Validation Accuracy: 0.8512, Loss: 0.1447
Epoch   2 Batch 1034/1077 - Train Accuracy: 0.8484, Validation Accuracy: 0.8569, Loss: 0.1459
Epoch   2 Batch 1035/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8640, Loss: 0.1034
Epoch   2 Batch 1036/1077 - Train Accuracy: 0.8802, Validation Accuracy: 0.8683, Loss: 0.1404
Epoch   2 Batch 1037/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8675, Loss: 0.1295
Epoch   2 Batch 1038/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8782, Loss: 0.1416
Epoch   2 Batch 1039/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8878, Loss: 0.1413
Epoch   2 Batch 1040/1077 - Train Accuracy: 0.8886, Validation Accuracy: 0.8896, Loss: 0.1417
Epoch   2 Batch 1041/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8704, Loss: 0.1340
Epoch   2 Batch 1042/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8754, Loss: 0.1190
Epoch   2 Batch 1043/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8906, Loss: 0.1257
Epoch   2 Batch 1044/1077 - Train Accuracy: 0.8551, Validation Accuracy: 0.8924, Loss: 0.1482
Epoch   2 Batch 1045/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8839, Loss: 0.1414
Epoch   2 Batch 1046/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8683, Loss: 0.1096
Epoch   2 Batch 1047/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8587, Loss: 0.1031
Epoch   2 Batch 1048/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8480, Loss: 0.1275
Epoch   2 Batch 1049/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8445, Loss: 0.1208
Epoch   2 Batch 1050/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8480, Loss: 0.1143
Epoch   2 Batch 1051/1077 - Train Accuracy: 0.9025, Validation Accuracy: 0.8356, Loss: 0.1278
Epoch   2 Batch 1052/1077 - Train Accuracy: 0.9118, Validation Accuracy: 0.8363, Loss: 0.1336
Epoch   2 Batch 1053/1077 - Train Accuracy: 0.8958, Validation Accuracy: 0.8366, Loss: 0.1259
Epoch   2 Batch 1054/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8469, Loss: 0.1155
Epoch   2 Batch 1055/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8530, Loss: 0.1365
Epoch   2 Batch 1056/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8622, Loss: 0.1321
Epoch   2 Batch 1057/1077 - Train Accuracy: 0.9149, Validation Accuracy: 0.8558, Loss: 0.1437
Epoch   2 Batch 1058/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8619, Loss: 0.1378
Epoch   2 Batch 1059/1077 - Train Accuracy: 0.8466, Validation Accuracy: 0.8473, Loss: 0.1496
Epoch   2 Batch 1060/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8480, Loss: 0.1172
Epoch   2 Batch 1061/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8469, Loss: 0.1396
Epoch   2 Batch 1062/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8452, Loss: 0.1349
Epoch   2 Batch 1063/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8448, Loss: 0.1401
Epoch   2 Batch 1064/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8544, Loss: 0.1245
Epoch   2 Batch 1065/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8501, Loss: 0.1132
Epoch   2 Batch 1066/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.8494, Loss: 0.1258
Epoch   2 Batch 1067/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8651, Loss: 0.1461
Epoch   2 Batch 1068/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8615, Loss: 0.1051
Epoch   2 Batch 1069/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8615, Loss: 0.0857
Epoch   2 Batch 1070/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8615, Loss: 0.1300
Epoch   2 Batch 1071/1077 - Train Accuracy: 0.8727, Validation Accuracy: 0.8608, Loss: 0.1129
Epoch   2 Batch 1072/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8597, Loss: 0.1397
Epoch   2 Batch 1073/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8668, Loss: 0.1401
Epoch   2 Batch 1074/1077 - Train Accuracy: 0.8921, Validation Accuracy: 0.8668, Loss: 0.1516
Epoch   2 Batch 1075/1077 - Train Accuracy: 0.8606, Validation Accuracy: 0.8775, Loss: 0.1376
Epoch   3 Batch    1/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.8807, Loss: 0.1003
Epoch   3 Batch    2/1077 - Train Accuracy: 0.8853, Validation Accuracy: 0.8803, Loss: 0.1283
Epoch   3 Batch    3/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8661, Loss: 0.1199
Epoch   3 Batch    4/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8654, Loss: 0.1157
Epoch   3 Batch    5/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8683, Loss: 0.1538
Epoch   3 Batch    6/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.8679, Loss: 0.1287
Epoch   3 Batch    7/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8633, Loss: 0.1058
Epoch   3 Batch    8/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.8633, Loss: 0.1333
Epoch   3 Batch    9/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8633, Loss: 0.1188
Epoch   3 Batch   10/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8665, Loss: 0.1295
Epoch   3 Batch   11/1077 - Train Accuracy: 0.8780, Validation Accuracy: 0.8707, Loss: 0.1248
Epoch   3 Batch   12/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8704, Loss: 0.1491
Epoch   3 Batch   13/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8732, Loss: 0.1244
Epoch   3 Batch   14/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.8739, Loss: 0.1052
Epoch   3 Batch   15/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.8817, Loss: 0.1152
Epoch   3 Batch   16/1077 - Train Accuracy: 0.8594, Validation Accuracy: 0.8817, Loss: 0.1373
Epoch   3 Batch   17/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8821, Loss: 0.1384
Epoch   3 Batch   18/1077 - Train Accuracy: 0.8652, Validation Accuracy: 0.8771, Loss: 0.1270
Epoch   3 Batch   19/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8800, Loss: 0.1315
Epoch   3 Batch   20/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8789, Loss: 0.1042
Epoch   3 Batch   21/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8761, Loss: 0.1498
Epoch   3 Batch   22/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8853, Loss: 0.1400
Epoch   3 Batch   23/1077 - Train Accuracy: 0.8578, Validation Accuracy: 0.8693, Loss: 0.1291
Epoch   3 Batch   24/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8647, Loss: 0.1205
Epoch   3 Batch   25/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8594, Loss: 0.1055
Epoch   3 Batch   26/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8576, Loss: 0.1132
Epoch   3 Batch   27/1077 - Train Accuracy: 0.8661, Validation Accuracy: 0.8629, Loss: 0.1298
Epoch   3 Batch   28/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8615, Loss: 0.1336
Epoch   3 Batch   29/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8679, Loss: 0.1202
Epoch   3 Batch   30/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8643, Loss: 0.1139
Epoch   3 Batch   31/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.8651, Loss: 0.1113
Epoch   3 Batch   32/1077 - Train Accuracy: 0.8601, Validation Accuracy: 0.8679, Loss: 0.1471
Epoch   3 Batch   33/1077 - Train Accuracy: 0.8780, Validation Accuracy: 0.8722, Loss: 0.1164
Epoch   3 Batch   34/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8835, Loss: 0.1257
Epoch   3 Batch   35/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8931, Loss: 0.1109
Epoch   3 Batch   36/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8931, Loss: 0.1322
Epoch   3 Batch   37/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8878, Loss: 0.1225
Epoch   3 Batch   38/1077 - Train Accuracy: 0.8849, Validation Accuracy: 0.8828, Loss: 0.1516
Epoch   3 Batch   39/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8825, Loss: 0.1456
Epoch   3 Batch   40/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8913, Loss: 0.1165
Epoch   3 Batch   41/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8803, Loss: 0.1302
Epoch   3 Batch   42/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8796, Loss: 0.1410
Epoch   3 Batch   43/1077 - Train Accuracy: 0.9108, Validation Accuracy: 0.8754, Loss: 0.0949
Epoch   3 Batch   44/1077 - Train Accuracy: 0.9025, Validation Accuracy: 0.8697, Loss: 0.1146
Epoch   3 Batch   45/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8714, Loss: 0.1203
Epoch   3 Batch   46/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.8764, Loss: 0.1273
Epoch   3 Batch   47/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8732, Loss: 0.1277
Epoch   3 Batch   48/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8725, Loss: 0.1411
Epoch   3 Batch   49/1077 - Train Accuracy: 0.8880, Validation Accuracy: 0.8754, Loss: 0.1214
Epoch   3 Batch   50/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8793, Loss: 0.1134
Epoch   3 Batch   51/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8853, Loss: 0.1201
Epoch   3 Batch   52/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8867, Loss: 0.1363
Epoch   3 Batch   53/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8817, Loss: 0.1094
Epoch   3 Batch   54/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8814, Loss: 0.1748
Epoch   3 Batch   55/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8704, Loss: 0.1202
Epoch   3 Batch   56/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8647, Loss: 0.1069
Epoch   3 Batch   57/1077 - Train Accuracy: 0.8683, Validation Accuracy: 0.8761, Loss: 0.1209
Epoch   3 Batch   58/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8757, Loss: 0.1148
Epoch   3 Batch   59/1077 - Train Accuracy: 0.9120, Validation Accuracy: 0.8548, Loss: 0.1168
Epoch   3 Batch   60/1077 - Train Accuracy: 0.9144, Validation Accuracy: 0.8533, Loss: 0.1115
Epoch   3 Batch   61/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8601, Loss: 0.1535
Epoch   3 Batch   62/1077 - Train Accuracy: 0.8507, Validation Accuracy: 0.8608, Loss: 0.1301
Epoch   3 Batch   63/1077 - Train Accuracy: 0.9282, Validation Accuracy: 0.8615, Loss: 0.0998
Epoch   3 Batch   64/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8675, Loss: 0.1165
Epoch   3 Batch   65/1077 - Train Accuracy: 0.8721, Validation Accuracy: 0.8619, Loss: 0.1167
Epoch   3 Batch   66/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8587, Loss: 0.0907
Epoch   3 Batch   67/1077 - Train Accuracy: 0.8873, Validation Accuracy: 0.8533, Loss: 0.1274
Epoch   3 Batch   68/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8580, Loss: 0.1423
Epoch   3 Batch   69/1077 - Train Accuracy: 0.8484, Validation Accuracy: 0.8594, Loss: 0.1625
Epoch   3 Batch   70/1077 - Train Accuracy: 0.8877, Validation Accuracy: 0.8661, Loss: 0.1344
Epoch   3 Batch   71/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8807, Loss: 0.1077
Epoch   3 Batch   72/1077 - Train Accuracy: 0.8613, Validation Accuracy: 0.8743, Loss: 0.1205
Epoch   3 Batch   73/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8835, Loss: 0.1184
Epoch   3 Batch   74/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8789, Loss: 0.1062
Epoch   3 Batch   75/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8729, Loss: 0.1597
Epoch   3 Batch   76/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8665, Loss: 0.1002
Epoch   3 Batch   77/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8722, Loss: 0.1130
Epoch   3 Batch   78/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8729, Loss: 0.1299
Epoch   3 Batch   79/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8739, Loss: 0.1293
Epoch   3 Batch   80/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8743, Loss: 0.1097
Epoch   3 Batch   81/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8764, Loss: 0.0957
Epoch   3 Batch   82/1077 - Train Accuracy: 0.9162, Validation Accuracy: 0.8675, Loss: 0.1098
Epoch   3 Batch   83/1077 - Train Accuracy: 0.8997, Validation Accuracy: 0.8672, Loss: 0.1275
Epoch   3 Batch   84/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.8665, Loss: 0.1105
Epoch   3 Batch   85/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8714, Loss: 0.1196
Epoch   3 Batch   86/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8754, Loss: 0.1200
Epoch   3 Batch   87/1077 - Train Accuracy: 0.8504, Validation Accuracy: 0.8871, Loss: 0.1431
Epoch   3 Batch   88/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8810, Loss: 0.1305
Epoch   3 Batch   89/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8778, Loss: 0.1179
Epoch   3 Batch   90/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.8896, Loss: 0.1084
Epoch   3 Batch   91/1077 - Train Accuracy: 0.9308, Validation Accuracy: 0.8960, Loss: 0.1091
Epoch   3 Batch   92/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8956, Loss: 0.1160
Epoch   3 Batch   93/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8967, Loss: 0.1013
Epoch   3 Batch   94/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8917, Loss: 0.1147
Epoch   3 Batch   95/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8839, Loss: 0.1390
Epoch   3 Batch   96/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8832, Loss: 0.1316
Epoch   3 Batch   97/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8825, Loss: 0.1370
Epoch   3 Batch   98/1077 - Train Accuracy: 0.8839, Validation Accuracy: 0.8991, Loss: 0.1294
Epoch   3 Batch   99/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8885, Loss: 0.1250
Epoch   3 Batch  100/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8786, Loss: 0.1310
Epoch   3 Batch  101/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8764, Loss: 0.1172
Epoch   3 Batch  102/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8683, Loss: 0.1108
Epoch   3 Batch  103/1077 - Train Accuracy: 0.8919, Validation Accuracy: 0.8665, Loss: 0.1156
Epoch   3 Batch  104/1077 - Train Accuracy: 0.8869, Validation Accuracy: 0.8597, Loss: 0.1319
Epoch   3 Batch  105/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8619, Loss: 0.1058
Epoch   3 Batch  106/1077 - Train Accuracy: 0.8845, Validation Accuracy: 0.8619, Loss: 0.1500
Epoch   3 Batch  107/1077 - Train Accuracy: 0.8464, Validation Accuracy: 0.8629, Loss: 0.1127
Epoch   3 Batch  108/1077 - Train Accuracy: 0.8970, Validation Accuracy: 0.8633, Loss: 0.1034
Epoch   3 Batch  109/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8711, Loss: 0.1236
Epoch   3 Batch  110/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.8775, Loss: 0.1086
Epoch   3 Batch  111/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8768, Loss: 0.1224
Epoch   3 Batch  112/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8814, Loss: 0.1159
Epoch   3 Batch  113/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8832, Loss: 0.1232
Epoch   3 Batch  114/1077 - Train Accuracy: 0.9338, Validation Accuracy: 0.8718, Loss: 0.0986
Epoch   3 Batch  115/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8722, Loss: 0.1470
Epoch   3 Batch  116/1077 - Train Accuracy: 0.8578, Validation Accuracy: 0.8704, Loss: 0.1328
Epoch   3 Batch  117/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8711, Loss: 0.1070
Epoch   3 Batch  118/1077 - Train Accuracy: 0.8779, Validation Accuracy: 0.8757, Loss: 0.1221
Epoch   3 Batch  119/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8707, Loss: 0.1146
Epoch   3 Batch  120/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8764, Loss: 0.1392
Epoch   3 Batch  121/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8754, Loss: 0.1119
Epoch   3 Batch  122/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8800, Loss: 0.1181
Epoch   3 Batch  123/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8775, Loss: 0.0959
Epoch   3 Batch  124/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8757, Loss: 0.1287
Epoch   3 Batch  125/1077 - Train Accuracy: 0.9144, Validation Accuracy: 0.8736, Loss: 0.1131
Epoch   3 Batch  126/1077 - Train Accuracy: 0.9014, Validation Accuracy: 0.8675, Loss: 0.1039
Epoch   3 Batch  127/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8679, Loss: 0.1078
Epoch   3 Batch  128/1077 - Train Accuracy: 0.9222, Validation Accuracy: 0.8750, Loss: 0.1230
Epoch   3 Batch  129/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8754, Loss: 0.1663
Epoch   3 Batch  130/1077 - Train Accuracy: 0.8858, Validation Accuracy: 0.8828, Loss: 0.1076
Epoch   3 Batch  131/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8786, Loss: 0.1213
Epoch   3 Batch  132/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8750, Loss: 0.1248
Epoch   3 Batch  133/1077 - Train Accuracy: 0.8717, Validation Accuracy: 0.8654, Loss: 0.1050
Epoch   3 Batch  134/1077 - Train Accuracy: 0.9353, Validation Accuracy: 0.8675, Loss: 0.1123
Epoch   3 Batch  135/1077 - Train Accuracy: 0.8783, Validation Accuracy: 0.8633, Loss: 0.1208
Epoch   3 Batch  136/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.8636, Loss: 0.1093
Epoch   3 Batch  137/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8690, Loss: 0.0903
Epoch   3 Batch  138/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8693, Loss: 0.1100
Epoch   3 Batch  139/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8764, Loss: 0.1261
Epoch   3 Batch  140/1077 - Train Accuracy: 0.9009, Validation Accuracy: 0.8718, Loss: 0.1225
Epoch   3 Batch  141/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8693, Loss: 0.1131
Epoch   3 Batch  142/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8640, Loss: 0.1149
Epoch   3 Batch  143/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8640, Loss: 0.1334
Epoch   3 Batch  144/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8594, Loss: 0.1467
Epoch   3 Batch  145/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.8594, Loss: 0.1322
Epoch   3 Batch  146/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8512, Loss: 0.1441
Epoch   3 Batch  147/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8636, Loss: 0.1135
Epoch   3 Batch  148/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.8729, Loss: 0.1151
Epoch   3 Batch  149/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8626, Loss: 0.1164
Epoch   3 Batch  150/1077 - Train Accuracy: 0.8850, Validation Accuracy: 0.8562, Loss: 0.1143
Epoch   3 Batch  151/1077 - Train Accuracy: 0.8876, Validation Accuracy: 0.8597, Loss: 0.1021
Epoch   3 Batch  152/1077 - Train Accuracy: 0.8691, Validation Accuracy: 0.8590, Loss: 0.1488
Epoch   3 Batch  153/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.8509, Loss: 0.1211
Epoch   3 Batch  154/1077 - Train Accuracy: 0.8865, Validation Accuracy: 0.8608, Loss: 0.1282
Epoch   3 Batch  155/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8750, Loss: 0.1189
Epoch   3 Batch  156/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8750, Loss: 0.1192
Epoch   3 Batch  157/1077 - Train Accuracy: 0.8715, Validation Accuracy: 0.8786, Loss: 0.1157
Epoch   3 Batch  158/1077 - Train Accuracy: 0.8903, Validation Accuracy: 0.8700, Loss: 0.1341
Epoch   3 Batch  159/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8615, Loss: 0.1014
Epoch   3 Batch  160/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8658, Loss: 0.1008
Epoch   3 Batch  161/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8647, Loss: 0.1163
Epoch   3 Batch  162/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8693, Loss: 0.1503
Epoch   3 Batch  163/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8683, Loss: 0.1429
Epoch   3 Batch  164/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8658, Loss: 0.1173
Epoch   3 Batch  165/1077 - Train Accuracy: 0.8688, Validation Accuracy: 0.8583, Loss: 0.1036
Epoch   3 Batch  166/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8558, Loss: 0.1385
Epoch   3 Batch  167/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8590, Loss: 0.1210
Epoch   3 Batch  168/1077 - Train Accuracy: 0.8565, Validation Accuracy: 0.8626, Loss: 0.1282
Epoch   3 Batch  169/1077 - Train Accuracy: 0.8999, Validation Accuracy: 0.8693, Loss: 0.1399
Epoch   3 Batch  170/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8707, Loss: 0.1155
Epoch   3 Batch  171/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8700, Loss: 0.1243
Epoch   3 Batch  172/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8651, Loss: 0.1029
Epoch   3 Batch  173/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8661, Loss: 0.1301
Epoch   3 Batch  174/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8665, Loss: 0.1108
Epoch   3 Batch  175/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8569, Loss: 0.1255
Epoch   3 Batch  176/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8590, Loss: 0.1086
Epoch   3 Batch  177/1077 - Train Accuracy: 0.8738, Validation Accuracy: 0.8647, Loss: 0.1482
Epoch   3 Batch  178/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8739, Loss: 0.1215
Epoch   3 Batch  179/1077 - Train Accuracy: 0.8873, Validation Accuracy: 0.8743, Loss: 0.1270
Epoch   3 Batch  180/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8732, Loss: 0.1091
Epoch   3 Batch  181/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8626, Loss: 0.1298
Epoch   3 Batch  182/1077 - Train Accuracy: 0.8999, Validation Accuracy: 0.8651, Loss: 0.1296
Epoch   3 Batch  183/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8626, Loss: 0.1222
Epoch   3 Batch  184/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.8629, Loss: 0.0989
Epoch   3 Batch  185/1077 - Train Accuracy: 0.8766, Validation Accuracy: 0.8718, Loss: 0.1256
Epoch   3 Batch  186/1077 - Train Accuracy: 0.8976, Validation Accuracy: 0.8796, Loss: 0.1192
Epoch   3 Batch  187/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8693, Loss: 0.0901
Epoch   3 Batch  188/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8718, Loss: 0.1277
Epoch   3 Batch  189/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8693, Loss: 0.1192
Epoch   3 Batch  190/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8658, Loss: 0.1112
Epoch   3 Batch  191/1077 - Train Accuracy: 0.8729, Validation Accuracy: 0.8615, Loss: 0.1043
Epoch   3 Batch  192/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8622, Loss: 0.1177
Epoch   3 Batch  193/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8661, Loss: 0.1040
Epoch   3 Batch  194/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8661, Loss: 0.1015
Epoch   3 Batch  195/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8651, Loss: 0.0971
Epoch   3 Batch  196/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8576, Loss: 0.0954
Epoch   3 Batch  197/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8583, Loss: 0.1207
Epoch   3 Batch  198/1077 - Train Accuracy: 0.8929, Validation Accuracy: 0.8601, Loss: 0.1132
Epoch   3 Batch  199/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8690, Loss: 0.1033
Epoch   3 Batch  200/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8679, Loss: 0.1399
Epoch   3 Batch  201/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8714, Loss: 0.1007
Epoch   3 Batch  202/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.8771, Loss: 0.1204
Epoch   3 Batch  203/1077 - Train Accuracy: 0.8520, Validation Accuracy: 0.8690, Loss: 0.1157
Epoch   3 Batch  204/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8700, Loss: 0.1441
Epoch   3 Batch  205/1077 - Train Accuracy: 0.8621, Validation Accuracy: 0.8736, Loss: 0.1317
Epoch   3 Batch  206/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8725, Loss: 0.1084
Epoch   3 Batch  207/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8789, Loss: 0.1207
Epoch   3 Batch  208/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8786, Loss: 0.1208
Epoch   3 Batch  209/1077 - Train Accuracy: 0.9010, Validation Accuracy: 0.8732, Loss: 0.0993
Epoch   3 Batch  210/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8693, Loss: 0.1363
Epoch   3 Batch  211/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.8690, Loss: 0.1113
Epoch   3 Batch  212/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8686, Loss: 0.1145
Epoch   3 Batch  213/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8732, Loss: 0.1025
Epoch   3 Batch  214/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8732, Loss: 0.1213
Epoch   3 Batch  215/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8711, Loss: 0.1237
Epoch   3 Batch  216/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8700, Loss: 0.1203
Epoch   3 Batch  217/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8700, Loss: 0.1071
Epoch   3 Batch  218/1077 - Train Accuracy: 0.8861, Validation Accuracy: 0.8736, Loss: 0.1528
Epoch   3 Batch  219/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8690, Loss: 0.1026
Epoch   3 Batch  220/1077 - Train Accuracy: 0.9206, Validation Accuracy: 0.8718, Loss: 0.1107
Epoch   3 Batch  221/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8658, Loss: 0.1273
Epoch   3 Batch  222/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8608, Loss: 0.1264
Epoch   3 Batch  223/1077 - Train Accuracy: 0.9085, Validation Accuracy: 0.8665, Loss: 0.0919
Epoch   3 Batch  224/1077 - Train Accuracy: 0.9039, Validation Accuracy: 0.8718, Loss: 0.1328
Epoch   3 Batch  225/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8832, Loss: 0.1428
Epoch   3 Batch  226/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8903, Loss: 0.1129
Epoch   3 Batch  227/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8860, Loss: 0.1342
Epoch   3 Batch  228/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.8849, Loss: 0.0940
Epoch   3 Batch  229/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8846, Loss: 0.1325
Epoch   3 Batch  230/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8810, Loss: 0.1201
Epoch   3 Batch  231/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8739, Loss: 0.1305
Epoch   3 Batch  232/1077 - Train Accuracy: 0.9058, Validation Accuracy: 0.8732, Loss: 0.1134
Epoch   3 Batch  233/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8782, Loss: 0.1626
Epoch   3 Batch  234/1077 - Train Accuracy: 0.8560, Validation Accuracy: 0.8832, Loss: 0.1255
Epoch   3 Batch  235/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8789, Loss: 0.1084
Epoch   3 Batch  236/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8665, Loss: 0.1313
Epoch   3 Batch  237/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8683, Loss: 0.1000
Epoch   3 Batch  238/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.8764, Loss: 0.1176
Epoch   3 Batch  239/1077 - Train Accuracy: 0.9267, Validation Accuracy: 0.8864, Loss: 0.0996
Epoch   3 Batch  240/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.8807, Loss: 0.1195
Epoch   3 Batch  241/1077 - Train Accuracy: 0.9277, Validation Accuracy: 0.8803, Loss: 0.1046
Epoch   3 Batch  242/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8700, Loss: 0.1111
Epoch   3 Batch  243/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.8707, Loss: 0.1209
Epoch   3 Batch  244/1077 - Train Accuracy: 0.9134, Validation Accuracy: 0.8729, Loss: 0.1124
Epoch   3 Batch  245/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8686, Loss: 0.1151
Epoch   3 Batch  246/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8729, Loss: 0.1097
Epoch   3 Batch  247/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8718, Loss: 0.1170
Epoch   3 Batch  248/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8729, Loss: 0.1148
Epoch   3 Batch  249/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8729, Loss: 0.1177
Epoch   3 Batch  250/1077 - Train Accuracy: 0.9045, Validation Accuracy: 0.8807, Loss: 0.1185
Epoch   3 Batch  251/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8725, Loss: 0.1195
Epoch   3 Batch  252/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8764, Loss: 0.1141
Epoch   3 Batch  253/1077 - Train Accuracy: 0.8803, Validation Accuracy: 0.8768, Loss: 0.1291
Epoch   3 Batch  254/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8754, Loss: 0.1142
Epoch   3 Batch  255/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8778, Loss: 0.1361
Epoch   3 Batch  256/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8793, Loss: 0.1441
Epoch   3 Batch  257/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8793, Loss: 0.1038
Epoch   3 Batch  258/1077 - Train Accuracy: 0.9089, Validation Accuracy: 0.8821, Loss: 0.1251
Epoch   3 Batch  259/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8857, Loss: 0.1126
Epoch   3 Batch  260/1077 - Train Accuracy: 0.8940, Validation Accuracy: 0.8903, Loss: 0.1053
Epoch   3 Batch  261/1077 - Train Accuracy: 0.8947, Validation Accuracy: 0.8835, Loss: 0.1207
Epoch   3 Batch  262/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8828, Loss: 0.1015
Epoch   3 Batch  263/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8825, Loss: 0.1036
Epoch   3 Batch  264/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8817, Loss: 0.1051
Epoch   3 Batch  265/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8839, Loss: 0.1246
Epoch   3 Batch  266/1077 - Train Accuracy: 0.8791, Validation Accuracy: 0.8842, Loss: 0.1181
Epoch   3 Batch  267/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8789, Loss: 0.0983
Epoch   3 Batch  268/1077 - Train Accuracy: 0.8613, Validation Accuracy: 0.8757, Loss: 0.1371
Epoch   3 Batch  269/1077 - Train Accuracy: 0.8853, Validation Accuracy: 0.8707, Loss: 0.1503
Epoch   3 Batch  270/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8707, Loss: 0.1261
Epoch   3 Batch  271/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8704, Loss: 0.1206
Epoch   3 Batch  272/1077 - Train Accuracy: 0.9159, Validation Accuracy: 0.8732, Loss: 0.1581
Epoch   3 Batch  273/1077 - Train Accuracy: 0.8880, Validation Accuracy: 0.8732, Loss: 0.1049
Epoch   3 Batch  274/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.8832, Loss: 0.1040
Epoch   3 Batch  275/1077 - Train Accuracy: 0.8958, Validation Accuracy: 0.8736, Loss: 0.1094
Epoch   3 Batch  276/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8739, Loss: 0.1405
Epoch   3 Batch  277/1077 - Train Accuracy: 0.9360, Validation Accuracy: 0.8636, Loss: 0.1039
Epoch   3 Batch  278/1077 - Train Accuracy: 0.8461, Validation Accuracy: 0.8569, Loss: 0.1379
Epoch   3 Batch  279/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8615, Loss: 0.1309
Epoch   3 Batch  280/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8647, Loss: 0.1210
Epoch   3 Batch  281/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8754, Loss: 0.1204
Epoch   3 Batch  282/1077 - Train Accuracy: 0.8559, Validation Accuracy: 0.8764, Loss: 0.1397
Epoch   3 Batch  283/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.8782, Loss: 0.1350
Epoch   3 Batch  284/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8796, Loss: 0.1253
Epoch   3 Batch  285/1077 - Train Accuracy: 0.9107, Validation Accuracy: 0.8846, Loss: 0.1241
Epoch   3 Batch  286/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8881, Loss: 0.1284
Epoch   3 Batch  287/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8885, Loss: 0.1151
Epoch   3 Batch  288/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8899, Loss: 0.1240
Epoch   3 Batch  289/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8849, Loss: 0.1129
Epoch   3 Batch  290/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8800, Loss: 0.1476
Epoch   3 Batch  291/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8672, Loss: 0.1324
Epoch   3 Batch  292/1077 - Train Accuracy: 0.8921, Validation Accuracy: 0.8686, Loss: 0.1219
Epoch   3 Batch  293/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8643, Loss: 0.1256
Epoch   3 Batch  294/1077 - Train Accuracy: 0.8942, Validation Accuracy: 0.8647, Loss: 0.1137
Epoch   3 Batch  295/1077 - Train Accuracy: 0.8655, Validation Accuracy: 0.8643, Loss: 0.1364
Epoch   3 Batch  296/1077 - Train Accuracy: 0.8850, Validation Accuracy: 0.8707, Loss: 0.1012
Epoch   3 Batch  297/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8658, Loss: 0.1293
Epoch   3 Batch  298/1077 - Train Accuracy: 0.8277, Validation Accuracy: 0.8668, Loss: 0.1393
Epoch   3 Batch  299/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8786, Loss: 0.1334
Epoch   3 Batch  300/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.8690, Loss: 0.1097
Epoch   3 Batch  301/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8626, Loss: 0.1059
Epoch   3 Batch  302/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.8612, Loss: 0.1026
Epoch   3 Batch  303/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8686, Loss: 0.1443
Epoch   3 Batch  304/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8711, Loss: 0.1033
Epoch   3 Batch  305/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8718, Loss: 0.1121
Epoch   3 Batch  306/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8725, Loss: 0.1215
Epoch   3 Batch  307/1077 - Train Accuracy: 0.8743, Validation Accuracy: 0.8718, Loss: 0.1133
Epoch   3 Batch  308/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8672, Loss: 0.1417
Epoch   3 Batch  309/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8643, Loss: 0.1085
Epoch   3 Batch  310/1077 - Train Accuracy: 0.8598, Validation Accuracy: 0.8658, Loss: 0.1207
Epoch   3 Batch  311/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8704, Loss: 0.1072
Epoch   3 Batch  312/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8654, Loss: 0.1446
Epoch   3 Batch  313/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8707, Loss: 0.0937
Epoch   3 Batch  314/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8846, Loss: 0.1178
Epoch   3 Batch  315/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.8881, Loss: 0.1114
Epoch   3 Batch  316/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8878, Loss: 0.1139
Epoch   3 Batch  317/1077 - Train Accuracy: 0.9001, Validation Accuracy: 0.8768, Loss: 0.1473
Epoch   3 Batch  318/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8793, Loss: 0.1215
Epoch   3 Batch  319/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8839, Loss: 0.1414
Epoch   3 Batch  320/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8757, Loss: 0.1240
Epoch   3 Batch  321/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8697, Loss: 0.0944
Epoch   3 Batch  322/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8675, Loss: 0.1134
Epoch   3 Batch  323/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8580, Loss: 0.1169
Epoch   3 Batch  324/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8665, Loss: 0.1193
Epoch   3 Batch  325/1077 - Train Accuracy: 0.8661, Validation Accuracy: 0.8704, Loss: 0.1303
Epoch   3 Batch  326/1077 - Train Accuracy: 0.8962, Validation Accuracy: 0.8757, Loss: 0.1221
Epoch   3 Batch  327/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8746, Loss: 0.1266
Epoch   3 Batch  328/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8796, Loss: 0.1283
Epoch   3 Batch  329/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8864, Loss: 0.1191
Epoch   3 Batch  330/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8711, Loss: 0.1196
Epoch   3 Batch  331/1077 - Train Accuracy: 0.9083, Validation Accuracy: 0.8590, Loss: 0.1313
Epoch   3 Batch  332/1077 - Train Accuracy: 0.8917, Validation Accuracy: 0.8558, Loss: 0.1099
Epoch   3 Batch  333/1077 - Train Accuracy: 0.9157, Validation Accuracy: 0.8469, Loss: 0.1085
Epoch   3 Batch  334/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8459, Loss: 0.1366
Epoch   3 Batch  335/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8480, Loss: 0.1192
Epoch   3 Batch  336/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8480, Loss: 0.1519
Epoch   3 Batch  337/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8526, Loss: 0.1384
Epoch   3 Batch  338/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8533, Loss: 0.1390
Epoch   3 Batch  339/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8608, Loss: 0.1275
Epoch   3 Batch  340/1077 - Train Accuracy: 0.9108, Validation Accuracy: 0.8686, Loss: 0.1365
Epoch   3 Batch  341/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8796, Loss: 0.1330
Epoch   3 Batch  342/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8803, Loss: 0.0991
Epoch   3 Batch  343/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8864, Loss: 0.1107
Epoch   3 Batch  344/1077 - Train Accuracy: 0.8957, Validation Accuracy: 0.8828, Loss: 0.1130
Epoch   3 Batch  345/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8817, Loss: 0.1124
Epoch   3 Batch  346/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8771, Loss: 0.1320
Epoch   3 Batch  347/1077 - Train Accuracy: 0.9342, Validation Accuracy: 0.8750, Loss: 0.1073
Epoch   3 Batch  348/1077 - Train Accuracy: 0.9003, Validation Accuracy: 0.8690, Loss: 0.1182
Epoch   3 Batch  349/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8597, Loss: 0.1015
Epoch   3 Batch  350/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8477, Loss: 0.1164
Epoch   3 Batch  351/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8487, Loss: 0.1157
Epoch   3 Batch  352/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8491, Loss: 0.0971
Epoch   3 Batch  353/1077 - Train Accuracy: 0.8150, Validation Accuracy: 0.8530, Loss: 0.1396
Epoch   3 Batch  354/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8686, Loss: 0.1317
Epoch   3 Batch  355/1077 - Train Accuracy: 0.8929, Validation Accuracy: 0.8714, Loss: 0.1125
Epoch   3 Batch  356/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8672, Loss: 0.1265
Epoch   3 Batch  357/1077 - Train Accuracy: 0.8865, Validation Accuracy: 0.8558, Loss: 0.1147
Epoch   3 Batch  358/1077 - Train Accuracy: 0.8368, Validation Accuracy: 0.8764, Loss: 0.1417
Epoch   3 Batch  359/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8743, Loss: 0.1256
Epoch   3 Batch  360/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8718, Loss: 0.1056
Epoch   3 Batch  361/1077 - Train Accuracy: 0.9206, Validation Accuracy: 0.8814, Loss: 0.1233
Epoch   3 Batch  362/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8828, Loss: 0.1163
Epoch   3 Batch  363/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8793, Loss: 0.1280
Epoch   3 Batch  364/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8814, Loss: 0.1351
Epoch   3 Batch  365/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8746, Loss: 0.1009
Epoch   3 Batch  366/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8821, Loss: 0.1213
Epoch   3 Batch  367/1077 - Train Accuracy: 0.9089, Validation Accuracy: 0.8725, Loss: 0.1070
Epoch   3 Batch  368/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8686, Loss: 0.1249
Epoch   3 Batch  369/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8569, Loss: 0.1259
Epoch   3 Batch  370/1077 - Train Accuracy: 0.9174, Validation Accuracy: 0.8580, Loss: 0.1098
Epoch   3 Batch  371/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8622, Loss: 0.1082
Epoch   3 Batch  372/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8700, Loss: 0.1055
Epoch   3 Batch  373/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8711, Loss: 0.1029
Epoch   3 Batch  374/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8796, Loss: 0.1318
Epoch   3 Batch  375/1077 - Train Accuracy: 0.9183, Validation Accuracy: 0.8704, Loss: 0.1153
Epoch   3 Batch  376/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8732, Loss: 0.1308
Epoch   3 Batch  377/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8700, Loss: 0.1207
Epoch   3 Batch  378/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8857, Loss: 0.1049
Epoch   3 Batch  379/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8938, Loss: 0.1382
Epoch   3 Batch  380/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8888, Loss: 0.1125
Epoch   3 Batch  381/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8938, Loss: 0.1367
Epoch   3 Batch  382/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8952, Loss: 0.1543
Epoch   3 Batch  383/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8977, Loss: 0.1156
Epoch   3 Batch  384/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8949, Loss: 0.1061
Epoch   3 Batch  385/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8878, Loss: 0.0963
Epoch   3 Batch  386/1077 - Train Accuracy: 0.8940, Validation Accuracy: 0.8913, Loss: 0.1250
Epoch   3 Batch  387/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8800, Loss: 0.1346
Epoch   3 Batch  388/1077 - Train Accuracy: 0.8724, Validation Accuracy: 0.8800, Loss: 0.1086
Epoch   3 Batch  389/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8690, Loss: 0.1238
Epoch   3 Batch  390/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.8789, Loss: 0.1266
Epoch   3 Batch  391/1077 - Train Accuracy: 0.9044, Validation Accuracy: 0.8746, Loss: 0.1209
Epoch   3 Batch  392/1077 - Train Accuracy: 0.9039, Validation Accuracy: 0.8768, Loss: 0.1339
Epoch   3 Batch  393/1077 - Train Accuracy: 0.8888, Validation Accuracy: 0.8871, Loss: 0.1006
Epoch   3 Batch  394/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8768, Loss: 0.1067
Epoch   3 Batch  395/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8821, Loss: 0.1067
Epoch   3 Batch  396/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8750, Loss: 0.1281
Epoch   3 Batch  397/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8686, Loss: 0.1172
Epoch   3 Batch  398/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8672, Loss: 0.1351
Epoch   3 Batch  399/1077 - Train Accuracy: 0.8487, Validation Accuracy: 0.8622, Loss: 0.1221
Epoch   3 Batch  400/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8722, Loss: 0.1241
Epoch   3 Batch  401/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8711, Loss: 0.0992
Epoch   3 Batch  402/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8654, Loss: 0.1108
Epoch   3 Batch  403/1077 - Train Accuracy: 0.8691, Validation Accuracy: 0.8594, Loss: 0.1452
Epoch   3 Batch  404/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8640, Loss: 0.1184
Epoch   3 Batch  405/1077 - Train Accuracy: 0.8791, Validation Accuracy: 0.8697, Loss: 0.1125
Epoch   3 Batch  406/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8704, Loss: 0.1083
Epoch   3 Batch  407/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.8711, Loss: 0.1335
Epoch   3 Batch  408/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8732, Loss: 0.1300
Epoch   3 Batch  409/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8633, Loss: 0.1267
Epoch   3 Batch  410/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8523, Loss: 0.1278
Epoch   3 Batch  411/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8526, Loss: 0.1086
Epoch   3 Batch  412/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8548, Loss: 0.1029
Epoch   3 Batch  413/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8612, Loss: 0.1189
Epoch   3 Batch  414/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8612, Loss: 0.1100
Epoch   3 Batch  415/1077 - Train Accuracy: 0.8955, Validation Accuracy: 0.8683, Loss: 0.1327
Epoch   3 Batch  416/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.8672, Loss: 0.1152
Epoch   3 Batch  417/1077 - Train Accuracy: 0.8715, Validation Accuracy: 0.8732, Loss: 0.1494
Epoch   3 Batch  418/1077 - Train Accuracy: 0.9203, Validation Accuracy: 0.8732, Loss: 0.0921
Epoch   3 Batch  419/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8771, Loss: 0.1113
Epoch   3 Batch  420/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8711, Loss: 0.0963
Epoch   3 Batch  421/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8675, Loss: 0.1318
Epoch   3 Batch  422/1077 - Train Accuracy: 0.8865, Validation Accuracy: 0.8778, Loss: 0.1080
Epoch   3 Batch  423/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8853, Loss: 0.1309
Epoch   3 Batch  424/1077 - Train Accuracy: 0.8738, Validation Accuracy: 0.8917, Loss: 0.1200
Epoch   3 Batch  425/1077 - Train Accuracy: 0.9029, Validation Accuracy: 0.8896, Loss: 0.0909
Epoch   3 Batch  426/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8729, Loss: 0.1169
Epoch   3 Batch  427/1077 - Train Accuracy: 0.8888, Validation Accuracy: 0.8651, Loss: 0.1053
Epoch   3 Batch  428/1077 - Train Accuracy: 0.9334, Validation Accuracy: 0.8746, Loss: 0.0975
Epoch   3 Batch  429/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.8732, Loss: 0.1036
Epoch   3 Batch  430/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.8736, Loss: 0.0959
Epoch   3 Batch  431/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8750, Loss: 0.0905
Epoch   3 Batch  432/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8750, Loss: 0.1316
Epoch   3 Batch  433/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.8750, Loss: 0.1168
Epoch   3 Batch  434/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8729, Loss: 0.1111
Epoch   3 Batch  435/1077 - Train Accuracy: 0.9104, Validation Accuracy: 0.8732, Loss: 0.1190
Epoch   3 Batch  436/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8700, Loss: 0.1218
Epoch   3 Batch  437/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8704, Loss: 0.0882
Epoch   3 Batch  438/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8612, Loss: 0.1266
Epoch   3 Batch  439/1077 - Train Accuracy: 0.8625, Validation Accuracy: 0.8601, Loss: 0.1312
Epoch   3 Batch  440/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8643, Loss: 0.1289
Epoch   3 Batch  441/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8633, Loss: 0.1152
Epoch   3 Batch  442/1077 - Train Accuracy: 0.8955, Validation Accuracy: 0.8583, Loss: 0.1178
Epoch   3 Batch  443/1077 - Train Accuracy: 0.9226, Validation Accuracy: 0.8640, Loss: 0.1001
Epoch   3 Batch  444/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8640, Loss: 0.0987
Epoch   3 Batch  445/1077 - Train Accuracy: 0.8314, Validation Accuracy: 0.8526, Loss: 0.1155
Epoch   3 Batch  446/1077 - Train Accuracy: 0.9170, Validation Accuracy: 0.8551, Loss: 0.1017
Epoch   3 Batch  447/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.8576, Loss: 0.1166
Epoch   3 Batch  448/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8615, Loss: 0.1538
Epoch   3 Batch  449/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8636, Loss: 0.1269
Epoch   3 Batch  450/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8636, Loss: 0.1106
Epoch   3 Batch  451/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8643, Loss: 0.1224
Epoch   3 Batch  452/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8732, Loss: 0.1115
Epoch   3 Batch  453/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8732, Loss: 0.1044
Epoch   3 Batch  454/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.8764, Loss: 0.0978
Epoch   3 Batch  455/1077 - Train Accuracy: 0.8846, Validation Accuracy: 0.8704, Loss: 0.1162
Epoch   3 Batch  456/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8608, Loss: 0.1187
Epoch   3 Batch  457/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8612, Loss: 0.0970
Epoch   3 Batch  458/1077 - Train Accuracy: 0.8957, Validation Accuracy: 0.8668, Loss: 0.1209
Epoch   3 Batch  459/1077 - Train Accuracy: 0.9115, Validation Accuracy: 0.8665, Loss: 0.1037
Epoch   3 Batch  460/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8693, Loss: 0.1201
Epoch   3 Batch  461/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8690, Loss: 0.1045
Epoch   3 Batch  462/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8693, Loss: 0.1126
Epoch   3 Batch  463/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8739, Loss: 0.1141
Epoch   3 Batch  464/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8633, Loss: 0.0951
Epoch   3 Batch  465/1077 - Train Accuracy: 0.8877, Validation Accuracy: 0.8583, Loss: 0.1087
Epoch   3 Batch  466/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8583, Loss: 0.0980
Epoch   3 Batch  467/1077 - Train Accuracy: 0.9036, Validation Accuracy: 0.8672, Loss: 0.1250
Epoch   3 Batch  468/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8672, Loss: 0.1286
Epoch   3 Batch  469/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8668, Loss: 0.1117
Epoch   3 Batch  470/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8633, Loss: 0.1186
Epoch   3 Batch  471/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8633, Loss: 0.0930
Epoch   3 Batch  472/1077 - Train Accuracy: 0.8925, Validation Accuracy: 0.8668, Loss: 0.1101
Epoch   3 Batch  473/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8686, Loss: 0.1164
Epoch   3 Batch  474/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8590, Loss: 0.1069
Epoch   3 Batch  475/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8587, Loss: 0.1147
Epoch   3 Batch  476/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.8594, Loss: 0.1006
Epoch   3 Batch  477/1077 - Train Accuracy: 0.9189, Validation Accuracy: 0.8612, Loss: 0.1046
Epoch   3 Batch  478/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8540, Loss: 0.1166
Epoch   3 Batch  479/1077 - Train Accuracy: 0.8801, Validation Accuracy: 0.8509, Loss: 0.1257
Epoch   3 Batch  480/1077 - Train Accuracy: 0.9100, Validation Accuracy: 0.8565, Loss: 0.1181
Epoch   3 Batch  481/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8501, Loss: 0.1225
Epoch   3 Batch  482/1077 - Train Accuracy: 0.8939, Validation Accuracy: 0.8548, Loss: 0.1508
Epoch   3 Batch  483/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8572, Loss: 0.0998
Epoch   3 Batch  484/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8732, Loss: 0.1334
Epoch   3 Batch  485/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8775, Loss: 0.1117
Epoch   3 Batch  486/1077 - Train Accuracy: 0.9239, Validation Accuracy: 0.8743, Loss: 0.1132
Epoch   3 Batch  487/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8700, Loss: 0.0977
Epoch   3 Batch  488/1077 - Train Accuracy: 0.9079, Validation Accuracy: 0.8711, Loss: 0.1243
Epoch   3 Batch  489/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8683, Loss: 0.1034
Epoch   3 Batch  490/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8604, Loss: 0.1225
Epoch   3 Batch  491/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8658, Loss: 0.1157
Epoch   3 Batch  492/1077 - Train Accuracy: 0.8773, Validation Accuracy: 0.8526, Loss: 0.1226
Epoch   3 Batch  493/1077 - Train Accuracy: 0.9111, Validation Accuracy: 0.8473, Loss: 0.0998
Epoch   3 Batch  494/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8555, Loss: 0.0949
Epoch   3 Batch  495/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8572, Loss: 0.1074
Epoch   3 Batch  496/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8519, Loss: 0.1095
Epoch   3 Batch  497/1077 - Train Accuracy: 0.8923, Validation Accuracy: 0.8526, Loss: 0.1139
Epoch   3 Batch  498/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8675, Loss: 0.1064
Epoch   3 Batch  499/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8729, Loss: 0.0955
Epoch   3 Batch  500/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8793, Loss: 0.1084
Epoch   3 Batch  501/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8786, Loss: 0.0996
Epoch   3 Batch  502/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8764, Loss: 0.1049
Epoch   3 Batch  503/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.8714, Loss: 0.0996
Epoch   3 Batch  504/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8761, Loss: 0.1142
Epoch   3 Batch  505/1077 - Train Accuracy: 0.9100, Validation Accuracy: 0.8640, Loss: 0.0933
Epoch   3 Batch  506/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.8601, Loss: 0.1053
Epoch   3 Batch  507/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.8629, Loss: 0.1047
Epoch   3 Batch  508/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8633, Loss: 0.1085
Epoch   3 Batch  509/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8672, Loss: 0.1267
Epoch   3 Batch  510/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8679, Loss: 0.1202
Epoch   3 Batch  511/1077 - Train Accuracy: 0.8882, Validation Accuracy: 0.8615, Loss: 0.1361
Epoch   3 Batch  512/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.8675, Loss: 0.0975
Epoch   3 Batch  513/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8658, Loss: 0.1047
Epoch   3 Batch  514/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8675, Loss: 0.1111
Epoch   3 Batch  515/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8725, Loss: 0.1248
Epoch   3 Batch  516/1077 - Train Accuracy: 0.9193, Validation Accuracy: 0.8778, Loss: 0.1017
Epoch   3 Batch  517/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8810, Loss: 0.1203
Epoch   3 Batch  518/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8857, Loss: 0.1133
Epoch   3 Batch  519/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8899, Loss: 0.1056
Epoch   3 Batch  520/1077 - Train Accuracy: 0.9327, Validation Accuracy: 0.8917, Loss: 0.1145
Epoch   3 Batch  521/1077 - Train Accuracy: 0.8783, Validation Accuracy: 0.8903, Loss: 0.0941
Epoch   3 Batch  522/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.8906, Loss: 0.1277
Epoch   3 Batch  523/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8839, Loss: 0.1238
Epoch   3 Batch  524/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8885, Loss: 0.1129
Epoch   3 Batch  525/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8842, Loss: 0.1097
Epoch   3 Batch  526/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8842, Loss: 0.1046
Epoch   3 Batch  527/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8814, Loss: 0.1185
Epoch   3 Batch  528/1077 - Train Accuracy: 0.8727, Validation Accuracy: 0.8860, Loss: 0.1105
Epoch   3 Batch  529/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8814, Loss: 0.1222
Epoch   3 Batch  530/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8750, Loss: 0.1193
Epoch   3 Batch  531/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8686, Loss: 0.1093
Epoch   3 Batch  532/1077 - Train Accuracy: 0.8551, Validation Accuracy: 0.8597, Loss: 0.1386
Epoch   3 Batch  533/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8555, Loss: 0.1213
Epoch   3 Batch  534/1077 - Train Accuracy: 0.9044, Validation Accuracy: 0.8672, Loss: 0.1064
Epoch   3 Batch  535/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8604, Loss: 0.1128
Epoch   3 Batch  536/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8612, Loss: 0.1282
Epoch   3 Batch  537/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8690, Loss: 0.1070
Epoch   3 Batch  538/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.8604, Loss: 0.0829
Epoch   3 Batch  539/1077 - Train Accuracy: 0.8727, Validation Accuracy: 0.8583, Loss: 0.1360
Epoch   3 Batch  540/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8732, Loss: 0.1032
Epoch   3 Batch  541/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8700, Loss: 0.0925
Epoch   3 Batch  542/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8718, Loss: 0.1039
Epoch   3 Batch  543/1077 - Train Accuracy: 0.8621, Validation Accuracy: 0.8711, Loss: 0.0998
Epoch   3 Batch  544/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.8707, Loss: 0.0819
Epoch   3 Batch  545/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8700, Loss: 0.1220
Epoch   3 Batch  546/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8736, Loss: 0.1097
Epoch   3 Batch  547/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8693, Loss: 0.1012
Epoch   3 Batch  548/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8725, Loss: 0.1247
Epoch   3 Batch  549/1077 - Train Accuracy: 0.8480, Validation Accuracy: 0.8714, Loss: 0.1214
Epoch   3 Batch  550/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8725, Loss: 0.1234
Epoch   3 Batch  551/1077 - Train Accuracy: 0.8613, Validation Accuracy: 0.8746, Loss: 0.1091
Epoch   3 Batch  552/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8459, Loss: 0.1203
Epoch   3 Batch  553/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8420, Loss: 0.1230
Epoch   3 Batch  554/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8430, Loss: 0.1049
Epoch   3 Batch  555/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8484, Loss: 0.1143
Epoch   3 Batch  556/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8530, Loss: 0.0929
Epoch   3 Batch  557/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.8530, Loss: 0.1031
Epoch   3 Batch  558/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8491, Loss: 0.1066
Epoch   3 Batch  559/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8480, Loss: 0.1257
Epoch   3 Batch  560/1077 - Train Accuracy: 0.8715, Validation Accuracy: 0.8523, Loss: 0.1169
Epoch   3 Batch  561/1077 - Train Accuracy: 0.8981, Validation Accuracy: 0.8608, Loss: 0.1083
Epoch   3 Batch  562/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.8587, Loss: 0.1101
Epoch   3 Batch  563/1077 - Train Accuracy: 0.8629, Validation Accuracy: 0.8583, Loss: 0.1226
Epoch   3 Batch  564/1077 - Train Accuracy: 0.9017, Validation Accuracy: 0.8587, Loss: 0.1320
Epoch   3 Batch  565/1077 - Train Accuracy: 0.8776, Validation Accuracy: 0.8697, Loss: 0.1203
Epoch   3 Batch  566/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8729, Loss: 0.1212
Epoch   3 Batch  567/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.8668, Loss: 0.1134
Epoch   3 Batch  568/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8697, Loss: 0.1308
Epoch   3 Batch  569/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8587, Loss: 0.1089
Epoch   3 Batch  570/1077 - Train Accuracy: 0.8618, Validation Accuracy: 0.8580, Loss: 0.1261
Epoch   3 Batch  571/1077 - Train Accuracy: 0.9159, Validation Accuracy: 0.8658, Loss: 0.0888
Epoch   3 Batch  572/1077 - Train Accuracy: 0.8880, Validation Accuracy: 0.8665, Loss: 0.1112
Epoch   3 Batch  573/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8654, Loss: 0.1153
Epoch   3 Batch  574/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8643, Loss: 0.1122
Epoch   3 Batch  575/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8697, Loss: 0.1081
Epoch   3 Batch  576/1077 - Train Accuracy: 0.9268, Validation Accuracy: 0.8764, Loss: 0.1017
Epoch   3 Batch  577/1077 - Train Accuracy: 0.9071, Validation Accuracy: 0.8807, Loss: 0.1133
Epoch   3 Batch  578/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8803, Loss: 0.1093
Epoch   3 Batch  579/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8810, Loss: 0.0934
Epoch   3 Batch  580/1077 - Train Accuracy: 0.8921, Validation Accuracy: 0.8768, Loss: 0.1011
Epoch   3 Batch  581/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8764, Loss: 0.0927
Epoch   3 Batch  582/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.8750, Loss: 0.1091
Epoch   3 Batch  583/1077 - Train Accuracy: 0.8956, Validation Accuracy: 0.8768, Loss: 0.1065
Epoch   3 Batch  584/1077 - Train Accuracy: 0.8798, Validation Accuracy: 0.8754, Loss: 0.1061
Epoch   3 Batch  585/1077 - Train Accuracy: 0.9107, Validation Accuracy: 0.8771, Loss: 0.0881
Epoch   3 Batch  586/1077 - Train Accuracy: 0.8927, Validation Accuracy: 0.8711, Loss: 0.1134
Epoch   3 Batch  587/1077 - Train Accuracy: 0.9085, Validation Accuracy: 0.8704, Loss: 0.1149
Epoch   3 Batch  588/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8580, Loss: 0.1121
Epoch   3 Batch  589/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8587, Loss: 0.1145
Epoch   3 Batch  590/1077 - Train Accuracy: 0.8528, Validation Accuracy: 0.8572, Loss: 0.1231
Epoch   3 Batch  591/1077 - Train Accuracy: 0.9048, Validation Accuracy: 0.8455, Loss: 0.1048
Epoch   3 Batch  592/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8636, Loss: 0.1187
Epoch   3 Batch  593/1077 - Train Accuracy: 0.8690, Validation Accuracy: 0.8746, Loss: 0.1371
Epoch   3 Batch  594/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8686, Loss: 0.1295
Epoch   3 Batch  595/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8679, Loss: 0.1134
Epoch   3 Batch  596/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.8718, Loss: 0.1168
Epoch   3 Batch  597/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8608, Loss: 0.1159
Epoch   3 Batch  598/1077 - Train Accuracy: 0.8903, Validation Accuracy: 0.8683, Loss: 0.1166
Epoch   3 Batch  599/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8778, Loss: 0.1341
Epoch   3 Batch  600/1077 - Train Accuracy: 0.8929, Validation Accuracy: 0.8817, Loss: 0.1260
Epoch   3 Batch  601/1077 - Train Accuracy: 0.9126, Validation Accuracy: 0.8857, Loss: 0.1008
Epoch   3 Batch  602/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8807, Loss: 0.1105
Epoch   3 Batch  603/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8746, Loss: 0.1172
Epoch   3 Batch  604/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8786, Loss: 0.1211
Epoch   3 Batch  605/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8722, Loss: 0.1359
Epoch   3 Batch  606/1077 - Train Accuracy: 0.9252, Validation Accuracy: 0.8764, Loss: 0.1033
Epoch   3 Batch  607/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8817, Loss: 0.1115
Epoch   3 Batch  608/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8920, Loss: 0.1310
Epoch   3 Batch  609/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.8913, Loss: 0.1034
Epoch   3 Batch  610/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8814, Loss: 0.1293
Epoch   3 Batch  611/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8803, Loss: 0.1029
Epoch   3 Batch  612/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8729, Loss: 0.0948
Epoch   3 Batch  613/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8732, Loss: 0.1236
Epoch   3 Batch  614/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8661, Loss: 0.1027
Epoch   3 Batch  615/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8707, Loss: 0.1115
Epoch   3 Batch  616/1077 - Train Accuracy: 0.8927, Validation Accuracy: 0.8668, Loss: 0.1046
Epoch   3 Batch  617/1077 - Train Accuracy: 0.8899, Validation Accuracy: 0.8640, Loss: 0.1079
Epoch   3 Batch  618/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.8707, Loss: 0.0971
Epoch   3 Batch  619/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8647, Loss: 0.0972
Epoch   3 Batch  620/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.8690, Loss: 0.1052
Epoch   3 Batch  621/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.8754, Loss: 0.1138
Epoch   3 Batch  622/1077 - Train Accuracy: 0.9182, Validation Accuracy: 0.8754, Loss: 0.1278
Epoch   3 Batch  623/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8746, Loss: 0.1165
Epoch   3 Batch  624/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8743, Loss: 0.1154
Epoch   3 Batch  625/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8643, Loss: 0.1037
Epoch   3 Batch  626/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8686, Loss: 0.1020
Epoch   3 Batch  627/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8661, Loss: 0.1028
Epoch   3 Batch  628/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8704, Loss: 0.1028
Epoch   3 Batch  629/1077 - Train Accuracy: 0.8849, Validation Accuracy: 0.8757, Loss: 0.1409
Epoch   3 Batch  630/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8739, Loss: 0.1026
Epoch   3 Batch  631/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8786, Loss: 0.1092
Epoch   3 Batch  632/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.8842, Loss: 0.1071
Epoch   3 Batch  633/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8789, Loss: 0.0976
Epoch   3 Batch  634/1077 - Train Accuracy: 0.8858, Validation Accuracy: 0.8835, Loss: 0.0848
Epoch   3 Batch  635/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8860, Loss: 0.1433
Epoch   3 Batch  636/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8793, Loss: 0.1075
Epoch   3 Batch  637/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8718, Loss: 0.1071
Epoch   3 Batch  638/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8725, Loss: 0.1110
Epoch   3 Batch  639/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8786, Loss: 0.1355
Epoch   3 Batch  640/1077 - Train Accuracy: 0.9092, Validation Accuracy: 0.8743, Loss: 0.1183
Epoch   3 Batch  641/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.8636, Loss: 0.0944
Epoch   3 Batch  642/1077 - Train Accuracy: 0.8776, Validation Accuracy: 0.8771, Loss: 0.1094
Epoch   3 Batch  643/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8881, Loss: 0.0938
Epoch   3 Batch  644/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8881, Loss: 0.1082
Epoch   3 Batch  645/1077 - Train Accuracy: 0.8929, Validation Accuracy: 0.8871, Loss: 0.1227
Epoch   3 Batch  646/1077 - Train Accuracy: 0.9185, Validation Accuracy: 0.8885, Loss: 0.1076
Epoch   3 Batch  647/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8874, Loss: 0.1182
Epoch   3 Batch  648/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8853, Loss: 0.0852
Epoch   3 Batch  649/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8906, Loss: 0.1100
Epoch   3 Batch  650/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8867, Loss: 0.1033
Epoch   3 Batch  651/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8935, Loss: 0.1062
Epoch   3 Batch  652/1077 - Train Accuracy: 0.8976, Validation Accuracy: 0.8846, Loss: 0.1006
Epoch   3 Batch  653/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8711, Loss: 0.1086
Epoch   3 Batch  654/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.8661, Loss: 0.0937
Epoch   3 Batch  655/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8597, Loss: 0.1201
Epoch   3 Batch  656/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8643, Loss: 0.1164
Epoch   3 Batch  657/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.8683, Loss: 0.1197
Epoch   3 Batch  658/1077 - Train Accuracy: 0.8888, Validation Accuracy: 0.8658, Loss: 0.0974
Epoch   3 Batch  659/1077 - Train Accuracy: 0.8888, Validation Accuracy: 0.8761, Loss: 0.1098
Epoch   3 Batch  660/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8796, Loss: 0.1144
Epoch   3 Batch  661/1077 - Train Accuracy: 0.9193, Validation Accuracy: 0.8686, Loss: 0.1026
Epoch   3 Batch  662/1077 - Train Accuracy: 0.9185, Validation Accuracy: 0.8633, Loss: 0.0983
Epoch   3 Batch  663/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8686, Loss: 0.0926
Epoch   3 Batch  664/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8601, Loss: 0.1149
Epoch   3 Batch  665/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8654, Loss: 0.1160
Epoch   3 Batch  666/1077 - Train Accuracy: 0.8997, Validation Accuracy: 0.8654, Loss: 0.1164
Epoch   3 Batch  667/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8640, Loss: 0.1232
Epoch   3 Batch  668/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8768, Loss: 0.0903
Epoch   3 Batch  669/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8668, Loss: 0.0973
Epoch   3 Batch  670/1077 - Train Accuracy: 0.8967, Validation Accuracy: 0.8654, Loss: 0.1213
Epoch   3 Batch  671/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8707, Loss: 0.1164
Epoch   3 Batch  672/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8793, Loss: 0.0965
Epoch   3 Batch  673/1077 - Train Accuracy: 0.8772, Validation Accuracy: 0.8665, Loss: 0.1081
Epoch   3 Batch  674/1077 - Train Accuracy: 0.9199, Validation Accuracy: 0.8679, Loss: 0.0992
Epoch   3 Batch  675/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8672, Loss: 0.1253
Epoch   3 Batch  676/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8679, Loss: 0.1023
Epoch   3 Batch  677/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8729, Loss: 0.1249
Epoch   3 Batch  678/1077 - Train Accuracy: 0.9122, Validation Accuracy: 0.8786, Loss: 0.0924
Epoch   3 Batch  679/1077 - Train Accuracy: 0.9005, Validation Accuracy: 0.8690, Loss: 0.1090
Epoch   3 Batch  680/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8707, Loss: 0.1027
Epoch   3 Batch  681/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8711, Loss: 0.1192
Epoch   3 Batch  682/1077 - Train Accuracy: 0.8617, Validation Accuracy: 0.8604, Loss: 0.1092
Epoch   3 Batch  683/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8629, Loss: 0.1077
Epoch   3 Batch  684/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.8626, Loss: 0.0917
Epoch   3 Batch  685/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8654, Loss: 0.1228
Epoch   3 Batch  686/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8661, Loss: 0.1147
Epoch   3 Batch  687/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8707, Loss: 0.1276
Epoch   3 Batch  688/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8743, Loss: 0.1030
Epoch   3 Batch  689/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.8629, Loss: 0.0804
Epoch   3 Batch  690/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8729, Loss: 0.1113
Epoch   3 Batch  691/1077 - Train Accuracy: 0.8947, Validation Accuracy: 0.8743, Loss: 0.1172
Epoch   3 Batch  692/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8690, Loss: 0.1118
Epoch   3 Batch  693/1077 - Train Accuracy: 0.8195, Validation Accuracy: 0.8704, Loss: 0.1326
Epoch   3 Batch  694/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8643, Loss: 0.1123
Epoch   3 Batch  695/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8654, Loss: 0.0988
Epoch   3 Batch  696/1077 - Train Accuracy: 0.8873, Validation Accuracy: 0.8679, Loss: 0.1093
Epoch   3 Batch  697/1077 - Train Accuracy: 0.9336, Validation Accuracy: 0.8683, Loss: 0.1000
Epoch   3 Batch  698/1077 - Train Accuracy: 0.9144, Validation Accuracy: 0.8665, Loss: 0.1119
Epoch   3 Batch  699/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8643, Loss: 0.1048
Epoch   3 Batch  700/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.8704, Loss: 0.0879
Epoch   3 Batch  701/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8583, Loss: 0.1097
Epoch   3 Batch  702/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8608, Loss: 0.0988
Epoch   3 Batch  703/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8722, Loss: 0.1061
Epoch   3 Batch  704/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8775, Loss: 0.1224
Epoch   3 Batch  705/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8750, Loss: 0.1225
Epoch   3 Batch  706/1077 - Train Accuracy: 0.8761, Validation Accuracy: 0.8562, Loss: 0.1551
Epoch   3 Batch  707/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8512, Loss: 0.1190
Epoch   3 Batch  708/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8498, Loss: 0.1243
Epoch   3 Batch  709/1077 - Train Accuracy: 0.8590, Validation Accuracy: 0.8487, Loss: 0.1424
Epoch   3 Batch  710/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8580, Loss: 0.0934
Epoch   3 Batch  711/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8576, Loss: 0.1292
Epoch   3 Batch  712/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8565, Loss: 0.1049
Epoch   3 Batch  713/1077 - Train Accuracy: 0.9134, Validation Accuracy: 0.8633, Loss: 0.0936
Epoch   3 Batch  714/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8672, Loss: 0.1072
Epoch   3 Batch  715/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8903, Loss: 0.1237
Epoch   3 Batch  716/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8903, Loss: 0.0877
Epoch   3 Batch  717/1077 - Train Accuracy: 0.9396, Validation Accuracy: 0.8846, Loss: 0.0994
Epoch   3 Batch  718/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8849, Loss: 0.0951
Epoch   3 Batch  719/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8807, Loss: 0.1231
Epoch   3 Batch  720/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8864, Loss: 0.1354
Epoch   3 Batch  721/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8825, Loss: 0.1167
Epoch   3 Batch  722/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8871, Loss: 0.1017
Epoch   3 Batch  723/1077 - Train Accuracy: 0.9271, Validation Accuracy: 0.8871, Loss: 0.0958
Epoch   3 Batch  724/1077 - Train Accuracy: 0.9108, Validation Accuracy: 0.8920, Loss: 0.1325
Epoch   3 Batch  725/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8917, Loss: 0.0850
Epoch   3 Batch  726/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8899, Loss: 0.1156
Epoch   3 Batch  727/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8849, Loss: 0.1093
Epoch   3 Batch  728/1077 - Train Accuracy: 0.8951, Validation Accuracy: 0.8910, Loss: 0.1178
Epoch   3 Batch  729/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8707, Loss: 0.1380
Epoch   3 Batch  730/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.8612, Loss: 0.1308
Epoch   3 Batch  731/1077 - Train Accuracy: 0.8534, Validation Accuracy: 0.8608, Loss: 0.1028
Epoch   3 Batch  732/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8438, Loss: 0.1199
Epoch   3 Batch  733/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8438, Loss: 0.1279
Epoch   3 Batch  734/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.8484, Loss: 0.1170
Epoch   3 Batch  735/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8548, Loss: 0.1101
Epoch   3 Batch  736/1077 - Train Accuracy: 0.9116, Validation Accuracy: 0.8629, Loss: 0.0976
Epoch   3 Batch  737/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8665, Loss: 0.1167
Epoch   3 Batch  738/1077 - Train Accuracy: 0.9154, Validation Accuracy: 0.8633, Loss: 0.0869
Epoch   3 Batch  739/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8668, Loss: 0.1025
Epoch   3 Batch  740/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8665, Loss: 0.0958
Epoch   3 Batch  741/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8725, Loss: 0.1234
Epoch   3 Batch  742/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8846, Loss: 0.0976
Epoch   3 Batch  743/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8839, Loss: 0.1209
Epoch   3 Batch  744/1077 - Train Accuracy: 0.9189, Validation Accuracy: 0.8800, Loss: 0.1054
Epoch   3 Batch  745/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.8814, Loss: 0.1103
Epoch   3 Batch  746/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8885, Loss: 0.1076
Epoch   3 Batch  747/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8842, Loss: 0.0990
Epoch   3 Batch  748/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8690, Loss: 0.1109
Epoch   3 Batch  749/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8615, Loss: 0.0966
Epoch   3 Batch  750/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8654, Loss: 0.0909
Epoch   3 Batch  751/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.8597, Loss: 0.1113
Epoch   3 Batch  752/1077 - Train Accuracy: 0.8542, Validation Accuracy: 0.8647, Loss: 0.1023
Epoch   3 Batch  753/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8651, Loss: 0.1087
Epoch   3 Batch  754/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8651, Loss: 0.1247
Epoch   3 Batch  755/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8643, Loss: 0.1211
Epoch   3 Batch  756/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.8643, Loss: 0.1108
Epoch   3 Batch  757/1077 - Train Accuracy: 0.8705, Validation Accuracy: 0.8665, Loss: 0.1088
Epoch   3 Batch  758/1077 - Train Accuracy: 0.9096, Validation Accuracy: 0.8643, Loss: 0.0959
Epoch   3 Batch  759/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8665, Loss: 0.0951
Epoch   3 Batch  760/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8722, Loss: 0.1345
Epoch   3 Batch  761/1077 - Train Accuracy: 0.8713, Validation Accuracy: 0.8789, Loss: 0.1104
Epoch   3 Batch  762/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.8800, Loss: 0.1062
Epoch   3 Batch  763/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8928, Loss: 0.0962
Epoch   3 Batch  764/1077 - Train Accuracy: 0.9091, Validation Accuracy: 0.8892, Loss: 0.1229
Epoch   3 Batch  765/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8935, Loss: 0.1051
Epoch   3 Batch  766/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8892, Loss: 0.1120
Epoch   3 Batch  767/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8842, Loss: 0.1100
Epoch   3 Batch  768/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8778, Loss: 0.1201
Epoch   3 Batch  769/1077 - Train Accuracy: 0.9008, Validation Accuracy: 0.8775, Loss: 0.1059
Epoch   3 Batch  770/1077 - Train Accuracy: 0.8791, Validation Accuracy: 0.8665, Loss: 0.0972
Epoch   3 Batch  771/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8920, Loss: 0.1126
Epoch   3 Batch  772/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8977, Loss: 0.0910
Epoch   3 Batch  773/1077 - Train Accuracy: 0.9000, Validation Accuracy: 0.8931, Loss: 0.1201
Epoch   3 Batch  774/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8931, Loss: 0.1180
Epoch   3 Batch  775/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8917, Loss: 0.1223
Epoch   3 Batch  776/1077 - Train Accuracy: 0.8902, Validation Accuracy: 0.8711, Loss: 0.1021
Epoch   3 Batch  777/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8580, Loss: 0.1355
Epoch   3 Batch  778/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.8651, Loss: 0.1054
Epoch   3 Batch  779/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8722, Loss: 0.1231
Epoch   3 Batch  780/1077 - Train Accuracy: 0.8324, Validation Accuracy: 0.8704, Loss: 0.1354
Epoch   3 Batch  781/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8714, Loss: 0.0853
Epoch   3 Batch  782/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8750, Loss: 0.1084
Epoch   3 Batch  783/1077 - Train Accuracy: 0.8854, Validation Accuracy: 0.8697, Loss: 0.1163
Epoch   3 Batch  784/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.8700, Loss: 0.0934
Epoch   3 Batch  785/1077 - Train Accuracy: 0.9364, Validation Accuracy: 0.8750, Loss: 0.1001
Epoch   3 Batch  786/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.8746, Loss: 0.1023
Epoch   3 Batch  787/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8750, Loss: 0.1133
Epoch   3 Batch  788/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8839, Loss: 0.1009
Epoch   3 Batch  789/1077 - Train Accuracy: 0.8919, Validation Accuracy: 0.8892, Loss: 0.1057
Epoch   3 Batch  790/1077 - Train Accuracy: 0.8621, Validation Accuracy: 0.8974, Loss: 0.1084
Epoch   3 Batch  791/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8970, Loss: 0.1449
Epoch   3 Batch  792/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8942, Loss: 0.1089
Epoch   3 Batch  793/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.8977, Loss: 0.1074
Epoch   3 Batch  794/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8970, Loss: 0.0988
Epoch   3 Batch  795/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.9013, Loss: 0.1228
Epoch   3 Batch  796/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.9013, Loss: 0.1139
Epoch   3 Batch  797/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.9066, Loss: 0.0964
Epoch   3 Batch  798/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.9002, Loss: 0.1249
Epoch   3 Batch  799/1077 - Train Accuracy: 0.8727, Validation Accuracy: 0.8906, Loss: 0.1238
Epoch   3 Batch  800/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8906, Loss: 0.1063
Epoch   3 Batch  801/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8796, Loss: 0.1111
Epoch   3 Batch  802/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8817, Loss: 0.1069
Epoch   3 Batch  803/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8867, Loss: 0.1227
Epoch   3 Batch  804/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.8835, Loss: 0.0836
Epoch   3 Batch  805/1077 - Train Accuracy: 0.8613, Validation Accuracy: 0.8832, Loss: 0.1141
Epoch   3 Batch  806/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8768, Loss: 0.1109
Epoch   3 Batch  807/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8633, Loss: 0.0935
Epoch   3 Batch  808/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8633, Loss: 0.1217
Epoch   3 Batch  809/1077 - Train Accuracy: 0.8927, Validation Accuracy: 0.8576, Loss: 0.1439
Epoch   3 Batch  810/1077 - Train Accuracy: 0.9118, Validation Accuracy: 0.8580, Loss: 0.0961
Epoch   3 Batch  811/1077 - Train Accuracy: 0.9170, Validation Accuracy: 0.8626, Loss: 0.1195
Epoch   3 Batch  812/1077 - Train Accuracy: 0.8863, Validation Accuracy: 0.8643, Loss: 0.1150
Epoch   3 Batch  813/1077 - Train Accuracy: 0.8925, Validation Accuracy: 0.8633, Loss: 0.0933
Epoch   3 Batch  814/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8704, Loss: 0.1243
Epoch   3 Batch  815/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8768, Loss: 0.1120
Epoch   3 Batch  816/1077 - Train Accuracy: 0.9346, Validation Accuracy: 0.8825, Loss: 0.1297
Epoch   3 Batch  817/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.8828, Loss: 0.1185
Epoch   3 Batch  818/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8888, Loss: 0.1063
Epoch   3 Batch  819/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8924, Loss: 0.1198
Epoch   3 Batch  820/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.8913, Loss: 0.1011
Epoch   3 Batch  821/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.8988, Loss: 0.1171
Epoch   3 Batch  822/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8935, Loss: 0.1178
Epoch   3 Batch  823/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.8864, Loss: 0.1023
Epoch   3 Batch  824/1077 - Train Accuracy: 0.9085, Validation Accuracy: 0.8810, Loss: 0.0980
Epoch   3 Batch  825/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.8807, Loss: 0.0904
Epoch   3 Batch  826/1077 - Train Accuracy: 0.8597, Validation Accuracy: 0.8814, Loss: 0.0971
Epoch   3 Batch  827/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8906, Loss: 0.1132
Epoch   3 Batch  828/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8853, Loss: 0.0852
Epoch   3 Batch  829/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8924, Loss: 0.1149
Epoch   3 Batch  830/1077 - Train Accuracy: 0.8473, Validation Accuracy: 0.8906, Loss: 0.1285
Epoch   3 Batch  831/1077 - Train Accuracy: 0.8340, Validation Accuracy: 0.8881, Loss: 0.1106
Epoch   3 Batch  832/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.8878, Loss: 0.1048
Epoch   3 Batch  833/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8842, Loss: 0.1031
Epoch   3 Batch  834/1077 - Train Accuracy: 0.8963, Validation Accuracy: 0.8864, Loss: 0.1087
Epoch   3 Batch  835/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8899, Loss: 0.1196
Epoch   3 Batch  836/1077 - Train Accuracy: 0.9046, Validation Accuracy: 0.8977, Loss: 0.1200
Epoch   3 Batch  837/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8935, Loss: 0.1380
Epoch   3 Batch  838/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8906, Loss: 0.1109
Epoch   3 Batch  839/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8920, Loss: 0.1100
Epoch   3 Batch  840/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.8956, Loss: 0.0916
Epoch   3 Batch  841/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8938, Loss: 0.1189
Epoch   3 Batch  842/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8853, Loss: 0.1101
Epoch   3 Batch  843/1077 - Train Accuracy: 0.8932, Validation Accuracy: 0.8835, Loss: 0.0994
Epoch   3 Batch  844/1077 - Train Accuracy: 0.8657, Validation Accuracy: 0.8832, Loss: 0.1028
Epoch   3 Batch  845/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8842, Loss: 0.1051
Epoch   3 Batch  846/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8984, Loss: 0.1228
Epoch   3 Batch  847/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.9077, Loss: 0.1352
Epoch   3 Batch  848/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.9091, Loss: 0.1029
Epoch   3 Batch  849/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8931, Loss: 0.0989
Epoch   3 Batch  850/1077 - Train Accuracy: 0.8828, Validation Accuracy: 0.8899, Loss: 0.1368
Epoch   3 Batch  851/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8960, Loss: 0.1179
Epoch   3 Batch  852/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8963, Loss: 0.1419
Epoch   3 Batch  853/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.9002, Loss: 0.1096
Epoch   3 Batch  854/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8938, Loss: 0.1261
Epoch   3 Batch  855/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8871, Loss: 0.1185
Epoch   3 Batch  856/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8821, Loss: 0.1148
Epoch   3 Batch  857/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8864, Loss: 0.1110
Epoch   3 Batch  858/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8864, Loss: 0.0915
Epoch   3 Batch  859/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8835, Loss: 0.1204
Epoch   3 Batch  860/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8796, Loss: 0.1128
Epoch   3 Batch  861/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8739, Loss: 0.1040
Epoch   3 Batch  862/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8722, Loss: 0.1123
Epoch   3 Batch  863/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8775, Loss: 0.0899
Epoch   3 Batch  864/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8754, Loss: 0.1099
Epoch   3 Batch  865/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.8853, Loss: 0.1142
Epoch   3 Batch  866/1077 - Train Accuracy: 0.9007, Validation Accuracy: 0.8761, Loss: 0.1250
Epoch   3 Batch  867/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8739, Loss: 0.1499
Epoch   3 Batch  868/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8842, Loss: 0.1213
Epoch   3 Batch  869/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8821, Loss: 0.1072
Epoch   3 Batch  870/1077 - Train Accuracy: 0.8758, Validation Accuracy: 0.8711, Loss: 0.1178
Epoch   3 Batch  871/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8761, Loss: 0.1031
Epoch   3 Batch  872/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8881, Loss: 0.1135
Epoch   3 Batch  873/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8796, Loss: 0.1178
Epoch   3 Batch  874/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8821, Loss: 0.1248
Epoch   3 Batch  875/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8828, Loss: 0.1227
Epoch   3 Batch  876/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8839, Loss: 0.1024
Epoch   3 Batch  877/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8931, Loss: 0.0914
Epoch   3 Batch  878/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9006, Loss: 0.1007
Epoch   3 Batch  879/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8981, Loss: 0.0994
Epoch   3 Batch  880/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.8935, Loss: 0.1149
Epoch   3 Batch  881/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8942, Loss: 0.1181
Epoch   3 Batch  882/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8899, Loss: 0.1271
Epoch   3 Batch  883/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8896, Loss: 0.1493
Epoch   3 Batch  884/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8938, Loss: 0.1070
Epoch   3 Batch  885/1077 - Train Accuracy: 0.9087, Validation Accuracy: 0.8885, Loss: 0.0853
Epoch   3 Batch  886/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8920, Loss: 0.1086
Epoch   3 Batch  887/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8963, Loss: 0.1244
Epoch   3 Batch  888/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8920, Loss: 0.0903
Epoch   3 Batch  889/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8881, Loss: 0.1013
Epoch   3 Batch  890/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8825, Loss: 0.1138
Epoch   3 Batch  891/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8729, Loss: 0.0925
Epoch   3 Batch  892/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8729, Loss: 0.0996
Epoch   3 Batch  893/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8718, Loss: 0.1210
Epoch   3 Batch  894/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8821, Loss: 0.1105
Epoch   3 Batch  895/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8817, Loss: 0.1102
Epoch   3 Batch  896/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8807, Loss: 0.1143
Epoch   3 Batch  897/1077 - Train Accuracy: 0.9167, Validation Accuracy: 0.8768, Loss: 0.0914
Epoch   3 Batch  898/1077 - Train Accuracy: 0.8917, Validation Accuracy: 0.8942, Loss: 0.1048
Epoch   3 Batch  899/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.8938, Loss: 0.1359
Epoch   3 Batch  900/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.9045, Loss: 0.1223
Epoch   3 Batch  901/1077 - Train Accuracy: 0.8850, Validation Accuracy: 0.9144, Loss: 0.1419
Epoch   3 Batch  902/1077 - Train Accuracy: 0.8966, Validation Accuracy: 0.9208, Loss: 0.1238
Epoch   3 Batch  903/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.9055, Loss: 0.0956
Epoch   3 Batch  904/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.9091, Loss: 0.0946
Epoch   3 Batch  905/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8967, Loss: 0.0952
Epoch   3 Batch  906/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8963, Loss: 0.1106
Epoch   3 Batch  907/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.8963, Loss: 0.1056
Epoch   3 Batch  908/1077 - Train Accuracy: 0.8699, Validation Accuracy: 0.8874, Loss: 0.1247
Epoch   3 Batch  909/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8885, Loss: 0.1231
Epoch   3 Batch  910/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8846, Loss: 0.1136
Epoch   3 Batch  911/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8977, Loss: 0.1012
Epoch   3 Batch  912/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.8906, Loss: 0.0928
Epoch   3 Batch  913/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8839, Loss: 0.1464
Epoch   3 Batch  914/1077 - Train Accuracy: 0.8994, Validation Accuracy: 0.8917, Loss: 0.1386
Epoch   3 Batch  915/1077 - Train Accuracy: 0.8701, Validation Accuracy: 0.8920, Loss: 0.1090
Epoch   3 Batch  916/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8960, Loss: 0.1252
Epoch   3 Batch  917/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.9027, Loss: 0.0958
Epoch   3 Batch  918/1077 - Train Accuracy: 0.9040, Validation Accuracy: 0.8977, Loss: 0.1108
Epoch   3 Batch  919/1077 - Train Accuracy: 0.9021, Validation Accuracy: 0.8967, Loss: 0.0934
Epoch   3 Batch  920/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8970, Loss: 0.1200
Epoch   3 Batch  921/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8896, Loss: 0.1258
Epoch   3 Batch  922/1077 - Train Accuracy: 0.8899, Validation Accuracy: 0.8881, Loss: 0.1266
Epoch   3 Batch  923/1077 - Train Accuracy: 0.9005, Validation Accuracy: 0.8828, Loss: 0.0788
Epoch   3 Batch  924/1077 - Train Accuracy: 0.8943, Validation Accuracy: 0.8853, Loss: 0.1392
Epoch   3 Batch  925/1077 - Train Accuracy: 0.9048, Validation Accuracy: 0.8896, Loss: 0.1025
Epoch   3 Batch  926/1077 - Train Accuracy: 0.8668, Validation Accuracy: 0.8888, Loss: 0.1071
Epoch   3 Batch  927/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8860, Loss: 0.1303
Epoch   3 Batch  928/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8817, Loss: 0.1151
Epoch   3 Batch  929/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.8849, Loss: 0.1192
Epoch   3 Batch  930/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8800, Loss: 0.1029
Epoch   3 Batch  931/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8853, Loss: 0.0998
Epoch   3 Batch  932/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8803, Loss: 0.1082
Epoch   3 Batch  933/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8935, Loss: 0.1163
Epoch   3 Batch  934/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8977, Loss: 0.0859
Epoch   3 Batch  935/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8896, Loss: 0.1073
Epoch   3 Batch  936/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8860, Loss: 0.1081
Epoch   3 Batch  937/1077 - Train Accuracy: 0.9038, Validation Accuracy: 0.8874, Loss: 0.1263
Epoch   3 Batch  938/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8974, Loss: 0.1409
Epoch   3 Batch  939/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8984, Loss: 0.1405
Epoch   3 Batch  940/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.9031, Loss: 0.0881
Epoch   3 Batch  941/1077 - Train Accuracy: 0.9096, Validation Accuracy: 0.8881, Loss: 0.1018
Epoch   3 Batch  942/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8800, Loss: 0.1137
Epoch   3 Batch  943/1077 - Train Accuracy: 0.8961, Validation Accuracy: 0.8846, Loss: 0.1071
Epoch   3 Batch  944/1077 - Train Accuracy: 0.8627, Validation Accuracy: 0.8842, Loss: 0.0986
Epoch   3 Batch  945/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8874, Loss: 0.0913
Epoch   3 Batch  946/1077 - Train Accuracy: 0.9597, Validation Accuracy: 0.8892, Loss: 0.1090
Epoch   3 Batch  947/1077 - Train Accuracy: 0.8277, Validation Accuracy: 0.8956, Loss: 0.1258
Epoch   3 Batch  948/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8942, Loss: 0.1135
Epoch   3 Batch  949/1077 - Train Accuracy: 0.9167, Validation Accuracy: 0.8906, Loss: 0.0953
Epoch   3 Batch  950/1077 - Train Accuracy: 0.8821, Validation Accuracy: 0.8920, Loss: 0.0971
Epoch   3 Batch  951/1077 - Train Accuracy: 0.8486, Validation Accuracy: 0.8924, Loss: 0.1287
Epoch   3 Batch  952/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.8920, Loss: 0.0944
Epoch   3 Batch  953/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9020, Loss: 0.0879
Epoch   3 Batch  954/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8963, Loss: 0.1078
Epoch   3 Batch  955/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.8984, Loss: 0.1143
Epoch   3 Batch  956/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8885, Loss: 0.1204
Epoch   3 Batch  957/1077 - Train Accuracy: 0.9315, Validation Accuracy: 0.8793, Loss: 0.0919
Epoch   3 Batch  958/1077 - Train Accuracy: 0.8945, Validation Accuracy: 0.8768, Loss: 0.1182
Epoch   3 Batch  959/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8771, Loss: 0.1062
Epoch   3 Batch  960/1077 - Train Accuracy: 0.8977, Validation Accuracy: 0.8604, Loss: 0.1113
Epoch   3 Batch  961/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8622, Loss: 0.0989
Epoch   3 Batch  962/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8633, Loss: 0.1016
Epoch   3 Batch  963/1077 - Train Accuracy: 0.8854, Validation Accuracy: 0.8683, Loss: 0.1505
Epoch   3 Batch  964/1077 - Train Accuracy: 0.9178, Validation Accuracy: 0.8707, Loss: 0.1136
Epoch   3 Batch  965/1077 - Train Accuracy: 0.8791, Validation Accuracy: 0.8771, Loss: 0.1090
Epoch   3 Batch  966/1077 - Train Accuracy: 0.9093, Validation Accuracy: 0.8807, Loss: 0.0961
Epoch   3 Batch  967/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8853, Loss: 0.1262
Epoch   3 Batch  968/1077 - Train Accuracy: 0.8762, Validation Accuracy: 0.8899, Loss: 0.1303
Epoch   3 Batch  969/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8903, Loss: 0.1253
Epoch   3 Batch  970/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8849, Loss: 0.1288
Epoch   3 Batch  971/1077 - Train Accuracy: 0.9029, Validation Accuracy: 0.8849, Loss: 0.1207
Epoch   3 Batch  972/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8874, Loss: 0.1168
Epoch   3 Batch  973/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.8874, Loss: 0.0897
Epoch   3 Batch  974/1077 - Train Accuracy: 0.8816, Validation Accuracy: 0.8881, Loss: 0.0818
Epoch   3 Batch  975/1077 - Train Accuracy: 0.9010, Validation Accuracy: 0.8885, Loss: 0.1051
Epoch   3 Batch  976/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8878, Loss: 0.0899
Epoch   3 Batch  977/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.8789, Loss: 0.0883
Epoch   3 Batch  978/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8842, Loss: 0.1130
Epoch   3 Batch  979/1077 - Train Accuracy: 0.8721, Validation Accuracy: 0.8860, Loss: 0.1160
Epoch   3 Batch  980/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8896, Loss: 0.1213
Epoch   3 Batch  981/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8956, Loss: 0.1051
Epoch   3 Batch  982/1077 - Train Accuracy: 0.8955, Validation Accuracy: 0.8906, Loss: 0.1097
Epoch   3 Batch  983/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8956, Loss: 0.1083
Epoch   3 Batch  984/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8977, Loss: 0.1167
Epoch   3 Batch  985/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.9023, Loss: 0.0959
Epoch   3 Batch  986/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.9052, Loss: 0.1309
Epoch   3 Batch  987/1077 - Train Accuracy: 0.8739, Validation Accuracy: 0.8995, Loss: 0.1053
Epoch   3 Batch  988/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8945, Loss: 0.1068
Epoch   3 Batch  989/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8892, Loss: 0.1152
Epoch   3 Batch  990/1077 - Train Accuracy: 0.8865, Validation Accuracy: 0.8853, Loss: 0.1275
Epoch   3 Batch  991/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8853, Loss: 0.1123
Epoch   3 Batch  992/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8984, Loss: 0.1099
Epoch   3 Batch  993/1077 - Train Accuracy: 0.8996, Validation Accuracy: 0.8995, Loss: 0.0907
Epoch   3 Batch  994/1077 - Train Accuracy: 0.9277, Validation Accuracy: 0.9091, Loss: 0.0971
Epoch   3 Batch  995/1077 - Train Accuracy: 0.9170, Validation Accuracy: 0.9002, Loss: 0.1183
Epoch   3 Batch  996/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.9038, Loss: 0.1239
Epoch   3 Batch  997/1077 - Train Accuracy: 0.8857, Validation Accuracy: 0.8999, Loss: 0.1009
Epoch   3 Batch  998/1077 - Train Accuracy: 0.8781, Validation Accuracy: 0.8999, Loss: 0.1027
Epoch   3 Batch  999/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8878, Loss: 0.1212
Epoch   3 Batch 1000/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8821, Loss: 0.1028
Epoch   3 Batch 1001/1077 - Train Accuracy: 0.9226, Validation Accuracy: 0.8874, Loss: 0.0948
Epoch   3 Batch 1002/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.8778, Loss: 0.0864
Epoch   3 Batch 1003/1077 - Train Accuracy: 0.9038, Validation Accuracy: 0.8793, Loss: 0.1193
Epoch   3 Batch 1004/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.8810, Loss: 0.1124
Epoch   3 Batch 1005/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8803, Loss: 0.1023
Epoch   3 Batch 1006/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8761, Loss: 0.0835
Epoch   3 Batch 1007/1077 - Train Accuracy: 0.9342, Validation Accuracy: 0.8722, Loss: 0.0978
Epoch   3 Batch 1008/1077 - Train Accuracy: 0.9039, Validation Accuracy: 0.8746, Loss: 0.1180
Epoch   3 Batch 1009/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.8729, Loss: 0.0871
Epoch   3 Batch 1010/1077 - Train Accuracy: 0.9305, Validation Accuracy: 0.8732, Loss: 0.1025
Epoch   3 Batch 1011/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8686, Loss: 0.0982
Epoch   3 Batch 1012/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.8665, Loss: 0.0701
Epoch   3 Batch 1013/1077 - Train Accuracy: 0.9315, Validation Accuracy: 0.8683, Loss: 0.0749
Epoch   3 Batch 1014/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8814, Loss: 0.1090
Epoch   3 Batch 1015/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8693, Loss: 0.1220
Epoch   3 Batch 1016/1077 - Train Accuracy: 0.8601, Validation Accuracy: 0.8743, Loss: 0.1074
Epoch   3 Batch 1017/1077 - Train Accuracy: 0.9116, Validation Accuracy: 0.8665, Loss: 0.1185
Epoch   3 Batch 1018/1077 - Train Accuracy: 0.8694, Validation Accuracy: 0.8771, Loss: 0.1033
Epoch   3 Batch 1019/1077 - Train Accuracy: 0.8923, Validation Accuracy: 0.8757, Loss: 0.1413
Epoch   3 Batch 1020/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.8771, Loss: 0.0984
Epoch   3 Batch 1021/1077 - Train Accuracy: 0.8806, Validation Accuracy: 0.8700, Loss: 0.1004
Epoch   3 Batch 1022/1077 - Train Accuracy: 0.9170, Validation Accuracy: 0.8658, Loss: 0.1021
Epoch   3 Batch 1023/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8604, Loss: 0.1034
Epoch   3 Batch 1024/1077 - Train Accuracy: 0.8738, Validation Accuracy: 0.8693, Loss: 0.1293
Epoch   3 Batch 1025/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8743, Loss: 0.1047
Epoch   3 Batch 1026/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.8796, Loss: 0.1203
Epoch   3 Batch 1027/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8810, Loss: 0.1055
Epoch   3 Batch 1028/1077 - Train Accuracy: 0.8720, Validation Accuracy: 0.8810, Loss: 0.0874
Epoch   3 Batch 1029/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.8857, Loss: 0.0962
Epoch   3 Batch 1030/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8860, Loss: 0.1223
Epoch   3 Batch 1031/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8817, Loss: 0.1084
Epoch   3 Batch 1032/1077 - Train Accuracy: 0.8832, Validation Accuracy: 0.8722, Loss: 0.1135
Epoch   3 Batch 1033/1077 - Train Accuracy: 0.8850, Validation Accuracy: 0.8714, Loss: 0.1297
Epoch   3 Batch 1034/1077 - Train Accuracy: 0.8633, Validation Accuracy: 0.8686, Loss: 0.1053
Epoch   3 Batch 1035/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.8736, Loss: 0.0693
Epoch   3 Batch 1036/1077 - Train Accuracy: 0.9122, Validation Accuracy: 0.8739, Loss: 0.1198
Epoch   3 Batch 1037/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8736, Loss: 0.1013
Epoch   3 Batch 1038/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8714, Loss: 0.1242
Epoch   3 Batch 1039/1077 - Train Accuracy: 0.9033, Validation Accuracy: 0.8679, Loss: 0.1152
Epoch   3 Batch 1040/1077 - Train Accuracy: 0.8935, Validation Accuracy: 0.8789, Loss: 0.1282
Epoch   3 Batch 1041/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8832, Loss: 0.1033
Epoch   3 Batch 1042/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8888, Loss: 0.1016
Epoch   3 Batch 1043/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8942, Loss: 0.1201
Epoch   3 Batch 1044/1077 - Train Accuracy: 0.8621, Validation Accuracy: 0.8991, Loss: 0.1282
Epoch   3 Batch 1045/1077 - Train Accuracy: 0.9145, Validation Accuracy: 0.8913, Loss: 0.1053
Epoch   3 Batch 1046/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8963, Loss: 0.0946
Epoch   3 Batch 1047/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8938, Loss: 0.1035
Epoch   3 Batch 1048/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8793, Loss: 0.0932
Epoch   3 Batch 1049/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8693, Loss: 0.1056
Epoch   3 Batch 1050/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8786, Loss: 0.0965
Epoch   3 Batch 1051/1077 - Train Accuracy: 0.9089, Validation Accuracy: 0.8771, Loss: 0.1079
Epoch   3 Batch 1052/1077 - Train Accuracy: 0.8903, Validation Accuracy: 0.8647, Loss: 0.1089
Epoch   3 Batch 1053/1077 - Train Accuracy: 0.9118, Validation Accuracy: 0.8700, Loss: 0.1118
Epoch   3 Batch 1054/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.8665, Loss: 0.1079
Epoch   3 Batch 1055/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8636, Loss: 0.1120
Epoch   3 Batch 1056/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8555, Loss: 0.1123
Epoch   3 Batch 1057/1077 - Train Accuracy: 0.9067, Validation Accuracy: 0.8544, Loss: 0.1257
Epoch   3 Batch 1058/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8654, Loss: 0.1108
Epoch   3 Batch 1059/1077 - Train Accuracy: 0.8507, Validation Accuracy: 0.8782, Loss: 0.1380
Epoch   3 Batch 1060/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8828, Loss: 0.1109
Epoch   3 Batch 1061/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8817, Loss: 0.1339
Epoch   3 Batch 1062/1077 - Train Accuracy: 0.8742, Validation Accuracy: 0.8803, Loss: 0.0998
Epoch   3 Batch 1063/1077 - Train Accuracy: 0.8730, Validation Accuracy: 0.8821, Loss: 0.1153
Epoch   3 Batch 1064/1077 - Train Accuracy: 0.9273, Validation Accuracy: 0.8697, Loss: 0.1128
Epoch   3 Batch 1065/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8587, Loss: 0.1039
Epoch   3 Batch 1066/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8768, Loss: 0.1074
Epoch   3 Batch 1067/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8874, Loss: 0.1118
Epoch   3 Batch 1068/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.8707, Loss: 0.0907
Epoch   3 Batch 1069/1077 - Train Accuracy: 0.9033, Validation Accuracy: 0.8739, Loss: 0.0739
Epoch   3 Batch 1070/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8757, Loss: 0.1011
Epoch   3 Batch 1071/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8867, Loss: 0.0947
Epoch   3 Batch 1072/1077 - Train Accuracy: 0.9159, Validation Accuracy: 0.8743, Loss: 0.1026
Epoch   3 Batch 1073/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8839, Loss: 0.1336
Epoch   3 Batch 1074/1077 - Train Accuracy: 0.9178, Validation Accuracy: 0.8935, Loss: 0.1356
Epoch   3 Batch 1075/1077 - Train Accuracy: 0.9173, Validation Accuracy: 0.9063, Loss: 0.1019
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">vocab_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [59, 222, 54, 50, 103, 197, 29]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [40, 17, 241, 333, 290, 237, 304, 94, 1]
  French Words: il a vu un vieux camion noir . &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
